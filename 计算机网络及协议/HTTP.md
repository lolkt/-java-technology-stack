## HTTP是什么

- HTTP 是什么
  - 超文本传输协议
  - HTTP 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范
- HTTP 不是什么
  - 因为 HTTP 是一个协议，是一种计算机间通信的规范，所以它不存在“单独的实体”。
  - HTTP 不是一个孤立的协议。
    - 在互联网世界里，HTTP 通常跑在 TCP/IP 协议栈之上，依靠 IP 协议实现寻址和路由、TCP协议实现可靠数据传输、DNS 协议实现域名查找、SSL/TLS 协议实现安全通信。
    - 此外，还有一些协议依赖于 HTTP，例如 WebSocket、HTTPDNS 等。这些协议相互交织，构成了一个协议网，而 HTTP 则处于中心地位。
- CDN
  - CDN 也是现在互联网中的一项重要基础设施，除了基本的网络加速外，还提供负载均衡、安全防护、边缘计算、跨运营商网络等功能，能够成倍地“放大”源站服务器的服务能力，很多云服务商都把 CDN 作为产品的一部分



## 与HTTP相关的各种协议

- TCP/IP
  - TCP/IP 协议实际上是一系列网络通信协议的统称，其中最核心的两个协议是TCP和IP，其他的还有 UDP、ICMP、ARP 等等，共同构成了一个复杂但有层次的协议栈。
  - HTTP 是一个"传输协议"，但它不关心路由、寻址、数据完整性等传输细节，而要求这些工作都由下层来处理。因为互联网上最流行的是 TCP/IP 协议，而它刚好满足 HTTP 的要求，所以互联网上的 HTTP 协议就运行在了 TCP/IP 上，HTTP 也就可以更准确地称为“HTTP over TCP/IP”。
- DNS
  - 想要使用 TCP/IP 协议来通信仍然要使用 IP 地址，所以需要把域名做一个转换，“映射”到它的真实 IP，这就是所谓的“域名解析”。
  - HTTP 协议中并没有明确要求必须使用 DNS，但实际上为了方便访问互联网上的 Web 服务器，通常都会使用 DNS 来定位或标记主机名，间接地把 DNS 与 HTTP 绑在了一起。
- URI/URL
  - URI（Uniform Resource Identifier），中文名称是 统一资源标识符
  - URL（Uniform Resource Locator）， 统一资源定位符
  - URI 主要有三个基本的部分构成
    - http://nginx.org/en/download.html
    - 协议名：即访问该资源应当使用的协议，在这里是“http”
    - 主机名：即互联网上主机的标记，可以是域名或 IP 地址，在这里是“nginx.org”
    - 路径：即资源在主机上的位置，使用“/”分隔多级目录，在这里是“/en/download.html”
- HTTPS
  - “HTTP over SSL/TLS，也就是运行在 SSL/TLS 协议上的 HTTP。
  - SSL/TLS是负责加密通信的安全协议，建立在 TCP/IP 之上，所以也是个可靠的传输协议，可以被用作 HTTP 的下层。
  - SSL 的全称是“Secure Socket Layer”，由网景公司发明，当发展到 3.0 时被标准化，改名为 TLS，即“Transport Layer Security”，但由于历史的原因还是有很多人称之为SSL/TLS，或者直接简称为 SSL。
- 代理
  - 代理（Proxy）是 HTTP 协议中请求方和应答方中间的一个环节，作为“中转站”，既可以转发客户端的请求，也可以转发服务器的应答。
  - 功能
    - 负载均衡
    - 内容缓存
    - 安全防护
    - 数据处理







## 常说的“四层”和“七层”到底是什么

- TCP/IP 网络分层模型

  - 第一层：链接层
  - 第二层：网际层
  - 第三层：传输层
  - 第四层：应用层

- OSI 网络分层模型

  - OSI，全称是“开放式系统互联通信参考模型”

    - 第一层：物理层，网络的物理形式，例如电缆、光纤、网卡、集线器等等；

    2. 第二层：数据链路层
    3. 第三层：网络层
    4. 第四层：传输层
    5. 第五层：会话层
    6. 第六层：表示层
    7. 第七层：应用层

  7. TCP/IP 是一个纯软件的栈，没有网络应有的最根基的电缆、网卡等物理设备的位置。而 OSI 则补足了这个缺失，在理论层面上描述网络更加完整。

- 两个分层模型的映射关系

  - 第五、六、七层：统一对应到 TCP/IP 的应用层。
  - 所谓的“四层负载均衡”就是指工作在传输层上，基于 TCP/IP 协议的特性，例如 IP 地址、端口号等实现对后端服务器的负载均衡。
  - 所谓的“七层负载均衡”就是指工作在应用层上，看到的是 HTTP 协议，解析 HTTP 报文里的 URI、主机名、资源类型等数据，再用适当的策略转发给后端服务器。

- TCP/IP 协议栈的工作方式

  - HTTP 协议的传输过程就是这样通过协议栈逐层向下，每一层都添加本层的专有数据，层层打包，然后通过下层发送出去。

![OSI七层协议模型、TCP/IP四层模型学习笔记](https://s4.51cto.com/images/blog/201806/19/eb5a8f1811f634f1cc1fe5684ecdb7eb.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)

![OSI七层协议模型、TCP/IP四层模型学习笔记](https://s4.51cto.com/images/blog/201806/19/d754f1060a2390637b4a013c1925079b.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)

![OSI七层协议模型、TCP/IP四层模型学习笔记](https://s4.51cto.com/images/blog/201806/19/27f893d336d5ac31f5e2495d6ec4b57f.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)



## 域名

- 域名的解析

  - DNS

    - 访问根域名服务器，它会告诉你“com”顶级域名服务器的地址；

    2. 访问“com”顶级域名服务器，它再告诉你“apple.com”域名服务器的地址；
    3. 最后访问“apple.com”域名服务器，就得到了“www.apple.com”的地址。

  - 在核心 DNS 系统之外，还有两种手段用来减轻域名解析的压力，并且能够更快地获取结果，基本思路就是“缓存”。

    - 其次，操作系统里也会对 DNS 解析结果做缓存，如果你之前访问过“www.apple.com”，那么下一次在浏览器里再输入这个网址的时候就不会再跑到DNS 那里去问了，直接在操作系统里就可以拿到 IP 地址。
    - 另外，操作系统里还有一个特殊的“主机映射”文件/hosts，通常是一个可编辑的文本，如果操作系统在缓存里找不到 DNS记录，就会找这个文件。



## 键入网址再按下回车，后面究竟发生了什么

- 使用 IP 地址访问 Web 服务器

  - 浏览器从地址栏的输入中获得服务器的 IP 地址和端口号；

  2. 浏览器用 TCP 的三次握手与服务器建立连接；
  3. 浏览器向服务器发送拼好的报文；
  4. 服务器收到报文后处理请求，同样拼好报文再发给浏览器；
  5. 浏览器解析报文，渲染输出页面。

- 使用域名访问 Web 服务器

  - Wireshark 抓包过程，你会发现，好像没有什么不同，浏览器上同样显示出了欢迎界面，抓到的包也同样是 11 个：先是三次握手，然后是两次 HTTP 传输
  - 发起域名解析动作，通过访问一系列的域名解析服务器，试图把这个域名翻译成 TCP/IP 协议里的 IP 地址。
  - 在域名解析的过程中会有多级的缓存，浏览器首先看一下自己的缓存里有没有，如果没有就向操作系统的缓存要，还没有就检查本机域名解析文件 hosts

- 真实的网络世界

  - 假设你要访问的是 Apple 网站，显然你是不知道它的真实 IP 地址的，在浏览器里只能使用
    域名“www.apple.com”访问，那么接下来要做的必然是域名解析。这就要用 DNS 协议开始从操作系统、本地 DNS、根 DNS、顶级 DNS、权威 DNS 的层层解析，当然这中间有缓存，可能不会费太多时间就能拿到结果。
  - CDN，它也会在 DNS 的解析过程中“插上一脚”。DNS 解析可能会给出 CDN 服务器的 IP 地址，这样你拿到的就会是 CDN 服务器而不是目标网站的实际地址。CDN 会缓存网站的大部分资源。
  - 由 PHP、Java 等后台服务动态生成的页面属于“动态资源”，CDN 无法缓存，只能从目标网站获取。于是你发出的 HTTP 请求就要开始在互联网上的“漫长跋涉”，经过无数的路由器、网关、代理，最后到达目的地。
  - 目标网站的服务器对外表现的是一个 IP 地址，但为了能够扛住高并发，在内部也是一套复杂的架构。通常在入口是负载均衡设备，例如四层的 LVS 或者七层的 Nginx，在后面是许多的服务器，构成一个更强更稳定的集群
  - 负载均衡设备会先访问系统里的缓存服务器，通常有 memory 级缓存 Redis 和 disk 级缓存 Varnish，它们的作用与 CDN 类似，不过是工作在内部网络里，把最频繁访问的数据缓存几秒钟或几分钟，减轻后端应用服务器的压力
  - 如果缓存服务器里也没有，那么负载均衡设备就要把请求转发给应用服务器了。这里就是各种开发框架大显神通的地方了，例如 Java 的 Tomcat/Netty/Jetty，Python 的 Django，还有 PHP、Node.js、Golang 等等。它们又会再访问后面的 MySQL、PostgreSQL、MongoDB 等数据库服务，实现用户登录、商品查询、购物下单、扣款支付等业务操作，然后把执行的结果返回给负载均衡设备，同时也可能给缓存服务器里也放一份。
  - 应用服务器的输出到了负载均衡设备这里，请求的处理就算是完成了，就要按照原路再走回去，还是要经过许多的路由器、网关、代理。如果这个资源允许缓存，那么经过 CDN 的时候它也会做缓存，这样下次同样的请求就不会到达源站了。
  - 最后网站的响应数据回到了你的设备，它可能是 HTML、JSON、图片或者其他格式的数据，需要由浏览器解析处理才能显示出来，如果数据里面还有超链接，指向别的资源，那么就又要重走一遍整个流程，直到所有的资源都下载完





## HTTP报文是什么样子的

- HTTP 协议的核心部分是它传输的报文内容

  - 它在实际要传输的数据之前附加了一个 20 字节的头部数据，存储 TCP 协议必须的额外信息，例如发送方的端口号、接收方的端口号、序号、标志位等等。

- HTTP 协议的请求报文和响应报文

  - 三大部分组成
    - 起始行（start line）：描述请求或响应的基本信息
    - 头部字段集合（header）：使用 key-value 形式更详细地说明报文；
      - HTTP 协议规定报文必须有 header，但可以没有 body，而且在 header 之后必须要有一个“空行”，也就是“CRLF”，十六进制的“0D0A”。
    - 消息正文（entity）：实际传输的数据，它不一定是纯文本，可以是图片、视频等二进制数据。
    - 这其中前两部分起始行和头部字段经常又合称为“请求头”或“响应头”，消息正文又称为“实体”（“body”）

- 请求行

  > 由三部分构成
  >
  > GET / HTTP/1.1
  >
  > “GET”是请求方法，“/”是请求目标，“HTTP/1.1”是版本号

- 状态行

  - > 响应报文里的起始行，在这里它不叫“响应行”，而是叫“状态行”（status line），意思是服务器响应的状态。
    >
    > HTTP/1.1 200 OK
    > 浏览器你好，我已经处理完了你的请求，这个报文使用的协议版本号是 1.1，状态码是 200，一切OK。”

- 常用头字段

  - 请求行或状态行再加上头部字段集合就构成了 HTTP 报文里完整的请求头或响应头
  - 基本上可以分为四大类
    - 通用字段：在请求头和响应头里都可以出现
    - 请求字段：仅能出现在请求头里，进一步说明请求信息或者额外的附加条件
    - 响应字段：仅能出现在响应头里，补充说明响应报文的信息
    - 实体字段：它实际上属于通用字段，但专门描述 body 的额外信息。

  

  

  

## 响应状态码

- RFC 标准把状态码分成了五类

  - > ​	1××：提示信息，表示目前是协议处理的中间状态，还需要后续的操作；
    > ​	2××：成功，报文已经收到并被正确处理；
    > ​	3××：重定向，资源位置发生变动，需要客户端重新发送请求；
    > ​	4××：客户端错误，请求报文有误，服务器无法处理；
    > ​	5××：服务器错误，服务器在处理请求时内部发生了错误

- 2××

  - “200 OK”
    - 如果是非 HEAD请求，通常在响应头后都会有 body 数据
  - “204 No Content”
    - 另一个很常见的成功状态码，它的含义与“200 OK”基本相同，但响应头后没有 body 数据。
  - “206 Partial Content”
  - 是 HTTP 分块下载或断点续传的基础，在客户端发送“范围请求”、要求获取资源的部分数据时出现，它与 200 一样，也是服务器成功处理了请求，但 body 里的数据不是资源的全部，而是其中的一部分。
  - 状态码 206 通常还会伴随着头字段“Content-Range”，表示响应报文里 body 数据的具体范围，供客户端确认，例如“Content-Range: bytes 0-99/2000”，意思是此次获取的是总计 2000 个字节的前 100 个字节。

- 3××

  - “301 Moved Permanently”
    - 俗称“永久重定向”，含义是此次请求的资源已经不存在了，需要改用改用新的 URI再次访问
  - “302 Moved Temporarily”
    - 俗称“临时重定向”，意思是请求的资源还在，但需要暂时用另一个 URI 来访问。
  - “304 Not Modified”
    - 表示资源未修改，用于缓存控制。它不具有通常的跳转含义，但可以理解成“重定向已到缓存的文件”（即“缓存重定向”）。
  - 303 See Other
    - 类似 302，但要求重定向后的请求改为GET 方法，访问一个结果页面，避免 POST/PUT 重复操作
  - 307 Temporary Redirect
    - 类似 302，但重定向后请求里的方法和实体不允许变动，含义比 302 更明确
  - 308 Permanent Redirect	
    - 类似 307，不允许重定向后的请求变动，但它是 301“永久重定向”的含义
    - 请求方法和主体不会被更改，`301`但有时可能会被错误地更改为[`GET`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/GET)方法。

- 4××

  - “400 Bad Request”
    - 通用的错误码，表示请求报文有错误，但具体是数据格式错误、缺少请求头还是 URI 超长它没有明确说，只是一个笼统的错误，客户端看到 400
      只会是“一头雾水”“不知所措”。所以，在开发 Web 应用时应当尽量避免给客户端返回 400，而是要用其他更有明确含义的状态码。
  - “403 Forbidden”	
    - 实际上不是客户端的请求出错，而是表示服务器禁止访问资源。原因可能多种多样，例如信息敏感、法律禁止等
  - “404 Not Found”	
    - 资源在本服务器上未找到
  - 405 Method Not Allowed
    - 不允许使用某些方法操作资源，例如不允许 POST 只能 GET
  - 406 Not Acceptable
    - 资源无法满足客户端请求的条件，例如请求中文但只有英文
  - 408 Request Timeout
    - 请求超时

- 5××

  - “501 Not Implemented”
    - 表示客户端请求的功能还不支持
  - “502 Bad Gateway”
    - 通常是服务器作为网关或者代理时返回的错误码，表示服务器自身工作正常，访问后端服务器时发生了错误，但具体的错误原因也是不知道的
  - “503 Service Unavailable”
    - 表示服务器当前很忙，暂时无法响应服务，我们上网时有时候遇到的“网络服务正忙，请稍后重试”的提示信息就是状态码 503
    - 503 是一个“临时”的状态，很可能过几秒钟后服务器就不那么忙了，可以继续提供服务，所以 503 响应报文里通常还会有一个“Retry-After”字段，指示客户端可以在多久以后再次尝试发送请求。



## HTTP有哪些特点

- 灵活可扩展
  - HTTP 协议随着互联网的发展一同成长起来了。在这个过程中，HTTP 协议逐渐增加了请求方法、版本号、状态码、头字段等特性。而 body 也不再限于文本形式的 TXT 或HTML，而是能够传输图片、音频视频等任意数据，这些都是源于它的“灵活可扩展”的特点
- 可靠传输
  - 因为 HTTP 协议是基于 TCP/IP 的，而 TCP 本身是一个“可靠”的传输协议，所以 HTTP 自然也就继承了这个特性，能够在请求方和应答方之间“可靠”地传输数据。
  - 不过我们必须正确地理解“可靠”的含义，HTTP 并不能 100% 保证数据一定能够发送到另一端，在网络繁忙、连接质量差等恶劣的环境下，也有可能收发失败。“可靠”只是向使用者提供了一个“承诺”，会在下层用多种手段“尽量”保证数据的完整送达。
- 应用层协议
  - HTTP 凭借着可携带任意头字段和实体数据的报文结构，以及连接控制、缓存代理等方便易用的特性，一出现就“技压群雄”，迅速成为了应用层里的“明星”协议。只要不太苛求性能，HTTP 几乎可以传递一切东西，满足各种需求，称得上是一个“万能”的协议。
- 请求 - 应答
  - 请求 - 应答模式也明确了 HTTP 协议里通信双方的定位，永远是请求方先发起连接和请求，是主动的，而应答方只有在收到请求后才能答复，是被动的，如果没有请求时不会有任何动作。
- 无状态
  - “状态”其实就是客户端或者服务器里保存的一些数据或者标志，记录了通信过程中的一些变化信息。
  - TCP 协议是有状态的，一开始处于 CLOSED 状态，连接成功后是ESTABLISHED 状态，断开连接后是 FIN-WAIT 状态，最后又是 CLOSED 状态。
  - HTTP，客户端和服务器永远是处在一种“无知”的状态。建立连接前两者互不知情，每次收发的报文也都是互相独立的，没有任何的联系。收发文也不会对客户端或服务器产生任何影响，连接后也不会要求保存任何信息。







## HTTP有哪些优点？又有哪些缺点

- 无状态
  - 因为服务器没有“记忆能力”，所以就不需要额外的资源来记录状态信息，不仅实现上会简单一些，而且还能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务。
  - 而且，“无状态”也表示服务器都是相同的，没有“状态”的差异，所以可以很容易地组成集群，让负载均衡把请求转发到任意一台服务器
  - 既然服务器没有“记忆能力”，它就无法支持需要连续多个步骤的“事务”操作。例如电商购物，首先要登录，然后添加购物车，再下单、结算、支付，这一系列操作都需要知道用户的身份才行，但“无状态”服务器是不知道这些请求是相互关联的，每次都得问一遍身份信息，不仅麻烦，而且还增加了不必要的数据传输量。
- 明文
  - “明文”意思就是协议里的报文（准确地说是 header 部分）不使用二进制数据，而是用简单可阅读的文本形式。
- 不安全
  - 在“身份认证”和“完整性校验”这两方面 HTTP 也是欠缺的
  - 为了解决 HTTP 不安全的缺点，所以就出现了 HTTPS
- 性能
  - 现在互联网的特点是移动和高并发，不能保证稳定的连接质量，所以在 TCP 层面上 HTTP 协议有时候就会表现的不够好
  - “请求 - 应答”模式则加剧了 HTTP 的性能问题，这就是著名的“队头阻塞”（Head-of-line blocking），当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一并被阻塞，会导致客户端迟迟收不到数据
  - 不过现在已经有了终极解决方案：HTTP/2 和 HTTP/3







## HTTP的实体数据

- 数据类型与编码

  - 在 TCP/IP 协议栈里，传输数据基本上都是“header+body”的格式。但 TCP、UDP 因为是传输层的协议，它们不会关心 body 数据是什么，只要把数据发送到对方就算是完成了任务。
  - 而 HTTP 协议则不同，它是应用层的协议，数据到达之后工作只能说是完成了一半，还必须要告诉上层应用这是什么数据才行，否则上层应用就会“不知所措”。
    - “MIME type” 数据类型
    - “Encoding type” 编码类型

- 数据类型使用的头字段

  - HTTP 协议为此定义了两个 Accept 请求头字段和两个Content 实体头字段，用于客户端和服务器进行“内容协商”。也就是说，客户端用 Accept 头告诉服务器希望接收什么样的数据，而服务器用 Content 头告诉客户端实际发送了什么样的数据。

- 语言类型与字符集

  - 这实际上就是“国际化”的问题。
  - en-US 表示美式英语，en-GB 表示英式英语，而 zh-CN 就表示我们最常使用的汉语
    所以后来就出现了 Unicode 和 UTF-8，把世界上所有的语言都容纳在一种编码方案里，	
  - utf-8只是编码方案，Unicode是字符集

- 语言类型使用的头字段

  - Accept-Language字段标记了客户端可理解的自然语言，也允许用“,”做分隔符列出多个类型

  - 相应的，服务器应该在响应报文里用头字段ContentLanguage告诉客户端实体数据使用的

    实际语言类型

  - 字符集在 HTTP 里使用的请求头字段是Accept-Charset，但响应头里却没有对应的 Content-Charset，而是在Content-Type字段的数据类型后面用“charset=xxx”来表示，这点需要特别注意。

- 内容协商的结果

  - 内容协商的过程是不透明的，每个 Web 服务器使用的算法都不一样。但有的时候，服务器会在响应头里多加一个Vary字段，记录服务器在内容协商时参考的请求头字段，给出一点信息
  - Vary 字段可以认为是响应报文的一个特殊的“版本标记”。每当 Accept 等请求头变化时，Vary 也会随着响应报文一起变化。也就是说，同一个 URI 可能会有多个不同的“版本”，主要用在传输链路中间的代理服务器实现缓存服务

- 假设你要使用 POST 方法向服务器提交一些 JSON 格式的数据，里面包含有中文，请求头应该是什么样子的呢

  - > content-type: application/json; 
    >
    > content-language:zh-CN

    - content-type是实体字段，所以请求和响应里都可以用，作用是指明body数据的类型。如果要发post请求，就需要带上它
    - 在这里不能用accept字段，因为是post，所以要用content-language来指明body的语言类型，在content-type里用charset指明编码类型。

  - accept 表达的是你想要的。而你发送 post请求时，你发送的数据是给服务器的，这时候就需要像 服务器会用 content-type 标明它给你的数据类型一样，你也需要用 content- 来表明你给别人的数据的一些属性





## HTTP传输大文件的方法

- 分块传输
  - 这种“化整为零”的思路在 HTTP 协议里就
    是“chunked”分块传输编码，在响应报文里用头字段“Transfer-Encoding: chunked”来表示，意思是报文里的 body 部分不是一次性发过来的，而是分成了许多的块（chunk）逐个发送。
  - “Transfer-Encoding: chunked”和“Content-Length”这两个字段是互斥的，也就是说响应报文里这两个字段不能同时出现，一个响应报文的传输要么是长度已知，要么是长度未知（chunked），这一点你一定要记住。
- 范围请求
  - 允许客户端在请求头里使用专用字段来表示只获取文件的一部分，相当于是客户端的“化整为零”。
  - “Accept-Ranges: bytes=x-y”明确告知客户端：“我是支持范围请求的
  - 服务器收到 Range 字段后，需要做四件事。
    - 第一，它必须检查范围是否合法
    - 第二，如果范围正确，服务器就可以根据 Range 头计算偏移量，读取文件的片段了，返回状态码“206 Partial Content”
    - 第三，服务器要添加一个响应头字段Content-Range
    - 最后剩下的就是发送数据了
  - 有了范围请求之后，HTTP 处理大文件就更加轻松了，看视频时可以根据时间点计算出文件的 Range，不用下载整个文件，直接精确获取片段所在的数据内容。不仅看视频的拖拽进度需要范围请求，常用的下载工具里的多段下载、断点续传也是基于它实现的
    - 先发个 HEAD，看服务器是否支持范围请求，同时获取文件的大小；
    - 开 N 个线程，每个线程使用 Range 字段划分出各自负责下载的片段，发请求传输数据；
    - 下载意外中断也不怕，不必重头再来一遍，只要根据上次的下载记录，用 Range 请求剩下的那一部分就可以了。
- 多段数据
  - 刚才说的范围请求一次只获取一个片段，其实它还支持在Range 头里使用多个“x-y”，一次性获取多个片段数据
  - 这种情况需要使用一种特殊的 MIME 类型：“multipart/byteranges”，表示报文的 body 是由多段字节序列组成的，并且还要用一个参数“boundary=xxx”给出段之间的分隔标记。





## HTTP的连接管理

- 短连接
  - HTTP 协议底层的数据传输基于 TCP/IP，每次发送请求前需要先与服务器建立连接，收到响应报文后会立即关闭连接
- 长连接
  - 既然 TCP 的连接和关闭非常耗时间，那么就把这个时间成本由原来的一个“请求 - 应答”均摊到多个“请求 - 应答”上。
- 连接相关的头字段
  - 我们也可以在请求头里明确地要求使用长连接机制，使用的字段是Connection，值是“keep-alive”。
  - 在客户端，可以在请求头里加上“Connection: close”字段，告诉服务器：“这次通信后就关闭连接”。
- 队头阻塞
  - “队头阻塞”与短连接和长连接无关，而是由 HTTP 基本的“请求 - 应答”模型所导致的。
- 性能优化
  - 在 HTTP 里就是“并发连接”（concurrent connections），也就是同时对一个域名发起多个长连接，用数量来解决质量的问题。
  - “域名分片”（domain sharding）技术，还是用数量来解决质量的思路。
- tcp握手1个rtt，挥手2个rtt
  - 一个来回就是1rtt，三次握手准确来说是1.5个rtt，四次挥手是两个来回，所以是2rtt







## HTTP的重定向和跳转

- 重定向的过程
  - 第一个请求返回的响应报文
    - 这里出现了一个新的头字段“Location: /index.html”，它就是 301/302 重定向跳转的秘密所在。
    - “Location”字段属于响应字段，必须出现在响应报文里。但只有配合 301/302 状态码才有意义，它标记了服务器要求重定向的 URI
    - 浏览器收到 301/302 报文，会检查响应头里有没
      有“Location”。如果有，就从字段值里提取出 URI，发出新的 HTTP 请求，相当于自动替我们点击了这个链接
- 重定向状态码
  - 303 See Other
    - 类似 302，但要求重定向后的请求改为GET 方法，访问一个结果页面，避免 POST/PUT 重复操作
  - 307 Temporary Redirect
    - 类似 302，但重定向后请求里的方法和实体不允许变动，含义比 302 更明确
  - 308 Permanent Redirect	
    - 类似 307，不允许重定向后的请求变动，但它是 301“永久重定向”的含义
    - 请求方法和主体不会被更改，`301`但有时可能会被错误地更改为[`GET`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/GET)方法。
- 重定向的应用场景
  - 一个最常见的原因就是“资源不可用”，需要用另一个新的URI 来代替。
  - 另一个原因就是“避免重复”，让多个网址都跳转到一个URI，增加访问入口的同时还不会增加额外的工作量。
  - 决定要实行重定向后接下来要考虑的就是“永久”和“临时”的问题了，也就是选择 301 还是 302。
- 重定向的相关问题
  - 第一个问题是“性能损耗”。很明显，重定向的机制决定了一个跳转会有两次请求 - 应答，比正常的访问多了一次。
  - 第二个问题是“循环跳转”。所以 HTTP 协议特别规定，浏览器必须具有检测“循环跳转”的能力







## HTTP的缓存控制

- 服务器的缓存控制
  - 服务器标记资源有效期使用的头字段是“Cache-Control”，里面的值“maxage=30”就是资源的有效时间，相当于告诉浏览器，“这个页面只能缓存 30 秒，之后就算是过期，不能用
  - 这里的 max-age 是“生存时间”，时间的计算起点是响应报文的创建时刻（即 Date 字段，也就是离开服务器的时刻），而不是客户端收到报文的时刻，也就是说包含了在链路传输过程中所有节点所停留的时间。
  - “max-age”是 HTTP 缓存控制最常用的属性，此外在响应报文里还可以用其他的属性来更精确地指示浏览器应该如何使用缓存
    - no_store：不允许缓存，用于某些变化非常频繁的数据，例如秒杀页面；
    - no_cache：实际的意思并不是不允许缓存，而是可以缓存，但在使用之前必须要去服务器验证是否过期，是否有最新的版本；
    - must-revalidate：它的意思是如果缓存不过期就可以继续使用，但过期了如果还想用就必须去服务器验证
- 客户端的缓存控制
  - 其实不止服务器可以发“Cache-Control”头，浏览器也可以发“Cache-Control”，也就是说请求 - 应答的双方都可以用这个字段进行缓存控制，互相协商缓存的使用策略。
  - 当你点“刷新”按钮的时候，浏览器会在请求头里加一个“Cache-Control: maxage=0”。
  - Ctrl+F5 的“强制刷新”又是什么样的呢？
    - 它其实是发了一个“Cache-Control: no-cache”，含义和“max-age=0”基本一样，就看后台的服务器怎么理解，通常两者的效果是相同的。
  - 重定向跳转功能，也可以发现浏览器使用了缓存
  - 在“前进”“后退”“跳转”这些重定向动作中浏览器不会“夹带私货”，只用最基本的请求头，没有“Cache-Control”，所以就会检查缓存，直接利用之前的资源，不再进行网络通信
- 条件请求
  - 浏览器可以用两个连续的请求组成“验证动作”：先是一个 HEAD，获取资源的修改时间等元信息，然后与缓存数据比较，如果没有改动就使用缓存，节省网络流量，否则就再发一个 GET 请求，获取最新的版本。但这样的两个请求网络成本太高了，所以 HTTP 协议就定义了一系列“If”开头的“条件请求”字段，专门用来检查验证资源是否过期
  - 条件请求一共有 5 个头字段，我们最常用的是“if-Modified-Since”和“If-NoneMatch”这两个
    - 需要第一次的响应报文预先提供“Last-modified”和“ETag”，然后第二次请求时就可以带上缓存里的原值，验证资源是否是最新的。
    - 如果资源没有变，服务器就回应一个“304 Not Modified”，表示缓存依然有效，浏览器就可以更新一下有效期，然后放心大胆地使用缓存了。
    - 刷新页面时浏览器就会同时发送缓存控制头“max-age=0”和条件请求头“If-None-Match”，如果缓存有效服务器就会返回 304
- 即使有“Last-modified”和“ETag”，强制刷新（Ctrl+F5）也能够从服务器获取最新数据（返回 200 而不是 304）
  - 强制刷新，请求头里有Pragma: no-cache和Cache-Control: no-cache，没有If-Modified-Since/If-None-Match，这个Pragma: no-cache的意思是禁用缓存







## HTTP的代理服务

- 代理的作用

  - 代理最基本的一个功能是负载均衡。
    - 代理中常用的负载均衡算法比如轮询、一致性哈希等等，这些算法的目标都是尽量把外部的流量合理地分散到多台源服务器，提高系统的整体资源利用率和性能
  - 在负载均衡的同时，代理服务还可以执行更多的功能
    - 健康检查	
    - 安全防护：保护被代理的后端服务器，限制 IP 地址或流量，抵御网络攻击和过载；	
    - 加密卸载：对外网使用 SSL/TLS 加密通信认证，而在安全的内网不加密，消除加解密成本	
    - 数据过滤：拦截上下行的数据，任意指定策略修改请求或者响应；
    - 内容缓存：暂存、复用服务器响应
  - 代理会增加链路长度，在代理上做一些复杂的处理。会很耗费性能，增加响应时间。代理会成为性能瓶颈，有单点问题

- 代理相关头字段

  - 代理服务器需要用字段“Via”标明代理的身份
    - Via 字段只解决了客户端和源服务器判断是否存在代理的问题，还不能知道对方的真实信息。
  - 最常用的两个头字段是“X-Forwarded-For”和“X-Real-IP”
    - “X-Forwarded-For”的字面意思是“为谁而转发”，形式上和“Via”差不多，也是每经过一个代理节点就会在字段里追加一个信息。但“Via”追加的是代理主机名（或者域名），而“X-Forwarded-For”追加的是请求方的 IP 地址
    - “X-Real-IP”是另一种获取客户端真实 IP 的手段，它的作用很简单，就是记录客户端 IP地址，没有中间的代理信息，相当于是“X-Forwarded-For”的简化版。如果客户端和源服务器之间只有一个代理，那么这两个字段的值就是相同的

- 代理协议

  - 通过“X-Forwarded-For”操作代理信息必须要解析 HTTP 报文头，这对于代理来说成本比较高

  - 另一个问题是“X-Forwarded-For”头必须要修改原始报文，而有些情况下是不允许甚至不可能的（比如使用 HTTPS 通信被加密）。

  - 所以就出现了一个专门的“代理协议”（The PROXY protocol），它由知名的代理软件HAProxy 所定义，也是一个“事实标准”，被广泛采用

    - > “代理协议”有 v1 和 v2 两个版本，v1 和 HTTP 差不多，也是明文，而 v2 是二进制格式。今天只介绍比较好理解的 v1，它在 HTTP 报文前增加了一行 ASCII 码文本，相当于又多了一个头。
      >
      > 这一行文本其实非常简单，开头必须是“PROXY”五个大写字母，然后是“TCP4”或者“TCP6”，表示客户端的 IP 地址类型，再后面是请求方地址、应答方地址、请求方端口号、应答方端口号，最后用一个回车换行（\r\n）结束。
      >
      > 1 PROXY TCP4 1.1.1.1 2.2.2.2 55555 80\r\n
      > 2 GET / HTTP/1.1\r\n
      > 3 Host: www.xxx.com\r\n
      > 4 \r\n
      >
      > 服务器看到这样的报文，只要解析第一行就可以拿到客户端地址，不需要再去理会后面的HTTP 数据，省了很多事情
      >
      > 不过代理协议并不支持“X-Forwarded-For”的链式地址形式，所以拿到客户端地址后再如何处理就需要代理服务器与后端自行约定。







## HTTP的缓存代理

- 源服务器的缓存控制

  - 服务器端的“Cache-Control”属性：max-age、no_store、no_cache 和 must-revalidate这 4 种缓存属性可以约束客户端，也可以约束代理。
  - 首先，我们要区分客户端上的缓存和代理上的缓存，可以使用两个新属性“private”和“public
    - “private”表示缓存只能在客户端保存，是用户“私有”的，不能放在代理上与别人共享。而“public”的意思就是缓存完全开放，谁都可以存，谁都可以用。、
  - 其次，缓存失效后的重新验证也要区分开（即使用条件请求“Lastmodified”和“ETag”），
    - “must-revalidate”是只要过期就必须回源服务器验证，而新的“proxy-revalidate”只要求代理的缓存过期后必须验证，客户端不必回源，只验证到代理这个环节就行了。
  - 还有一个代理专用的属性“no-transform”。
    - 代理有时候会对缓存下来的数据做一些优化，比如把图片生成 png、webp 等几种格式，方便今后的请求处理，而“notransform”就会禁止这样做，不许“偷偷摸摸搞小动作”。
  - 源服务器在设置完“Cache-Control”后必须要为报文加上“Lastmodified”或“ETag”字段。否则，客户端和代理后面就无法使用条件请求来验证缓存是否有效，也就不会有 304 缓存重定向。

- 客户端的缓存控制

  - 关于缓存的生存时间，多了两个新属性“max-stale”和“min-fresh”。
  - “max-stale”的意思是如果代理上的缓存过期了也可以接受，但不能过期太多，超过 x 秒也会不要。“min-fresh”的意思是缓存必须有效，而且必须在 x 秒后依然有效。
  - 比如，草莓上贴着标签“max-age=5”，现在已经在冰柜里存了 7 天。如果有请求“max-stale=2”，意思是过期两天也能接受，所以刚好能卖出去。
  - 但要是“min-fresh=1”，这是绝对不允许过期的，就不会买走。这时如果有另外一个菠萝是“max-age=10”，那么“7+1<10”，在一天之后还是新鲜的，所以就能卖出去。
  - 有的时候客户端还会发出一个特别的“only-if-cached”属性，表示只接受代理缓存的数据，不接受源服务器的响应。如果代理上没有缓存或者缓存过期，就应该给客户端返回一个504（Gateway Timeout）


## HTTP问题

- 与服务器建立的连接是否会在一个HTTP请求后断开？什么情况下断开？

  - **在 HTTP/1.0 中，一个服务器在发送完一个 HTTP 响应后，会断开 TCP 链接。但是这样每次请求都会重新建立和断开 TCP 连接，代价过大。**所以虽然标准中没有设定，某些服务器对 Connection: keep-alive 的 Header 进行了支持。意思是说，完成这个 HTTP 请求之后，不要断开 HTTP 请求使用的 TCP 连接。这样的好处是连接可以被重新使用，之后发送 HTTP 请求的时候不需要重新建立 TCP 连接，以及如果维持连接，那么 SSL 的开销也可以避免。
  - **持久连接：**既然维持 TCP 连接好处这么多，HTTP/1.1 就把 Connection 头写进标准，并且默认开启持久连接，除非请求中写明 Connection: close，那么浏览器和服务器之间是会维持一段时间的 TCP 连接，不会一个请求结束就断掉。
  - **所以第一个问题的答案是：**默认情况下建立 TCP 连接不会断开，只有在请求报头中声明 Connection: close 才会在请求完成后关闭连接。

- 一个 TCP 连接可以对应几个 HTTP 请求

  - 如果维持连接，一个 TCP 连接是可以发送多个 HTTP 请求的。

- 一个 TCP 连接中 HTTP 请求发送可以一起发送么

  - **HTTP/1.1 存在一个问题：**单个 TCP 连接在同一时刻只能处理一个请求。

    **意思是说：**两个请求的生命周期不能重叠，任意两个 HTTP 请求从开始到结束的时间在同一个 TCP 连接里不能重叠。

    虽然 HTTP/1.1 规范中规定了 [Pipelining](https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%3A%2F%2Ftools.ietf.org%2Fhtml%2Frfc2616%23section-8.1.2.2) 来试图解决这个问题，但是这个功能在浏览器中默认是关闭的。

  - 但是，HTTP2 提供了 Multiplexing 多路传输特性，可以在一个 TCP 连接中同时完成多个 HTTP 请求。

- 为什么有的时候刷新页面不需要重新建立 SSL 连接

  - TCP 连接有的时候会被浏览器和服务端维持一段时间。TCP 不需要重新建立，SSL 自然也会用之前的。

- 浏览器对同一 Host 建立 TCP 连接到数量有没有限制

  - 假设我们还处在 HTTP/1.1 时代，那个时候没有多路传输，当浏览器拿到一个有几十张图片的网页该怎么办呢？
    - **Chrome 最多允许对同一个 Host 建立六个 TCP 连接。不同的浏览器有一些区别**
  - **收到的 HTML 如果包含几十个图片标签，这些图片是以什么方式、什么顺序、建立了多少连接、使用什么协议被下载下来的呢**
    - 如果图片都是 HTTPS 连接并且在同一个域名下，那么浏览器在 SSL 握手之后会和服务器商量能不能用 HTTP2，如果能的话就使用 Multiplexing 功能在这个连接上进行多路传输。不过也未必会所有挂在这个域名的资源都会使用一个 TCP 连接去获取，但是可以确定的是 Multiplexing 很可能会被用到。如果发现用不了 HTTP2 呢？或者用不了 HTTPS（现实中的
    - HTTP2 都是在 HTTPS 上实现的，所以也就是只能使用 HTTP/1.1）。那浏览器就会在一个 HOST 上建立多个 TCP 连接，连接数量的最大限制取决于浏览器设置，这些连接会在空闲的时候被浏览器用来发送新的请求，如果所有的连接都正在发送请求呢？那其他的请求就只能等等了。



## HTTPS是什么？SSL/TLS又是什么

- 为什么要有 HTTPS？
  - 由于 HTTP 天生“明文”的特点，整个传输过程完全透明，任何人都能够在链路中截获、修改或者伪造请求 / 响应报文，数据不具有可信性。
- 什么是安全？
  - 通常认为，如果通信过程具备了四个特性，就可以认为是“安全”的，这四个特性是：机密性、完整性，身份认证和不可否认。
    - 机密性是指对数据的“保密”，只能由可信的人访问
    - 完整性是指数据在传输过程中没有被窜改
    - 身份认证是指确认对方的真实身份
    - 不可否认是指不能否认已经发生过的行为
- 什么是 HTTPS？
  - 它为 HTTP 增加了刚才所说的四大安全特性
  - HTTPS 其实是一个“非常简单”的协议，新的协议名“https”，默认端口号 443，至于请求 - 应答模式、报文结构、请求方法、URI、头字段、连接管理等等都完全沿用 HTTP，没有任何新的东西。
  - 如果用 Wireshark 抓包，也会发现与HTTP 不一样，不再是简单可见的明文，多了“Client Hello”“Server Hello”等新的数据包
  - 秘密就在于 HTTPS 名字里的“S”，它把 HTTP 下层的传输协议由 TCP/IP 换成了SSL/TLS，由“HTTP over TCP/IP”变成了“HTTP over SSL/TLS”
- SSL/TLS
  - SSL 即安全套接层（Secure Sockets Layer），在 OSI 模型中处于第 5 层（会话层）
  - TLS 由记录协议、握手协议、警告协议、变更密码规范协议、扩展协议等几个子协议组成，综合使用了对称加密、非对称加密、身份认证等许多密码学前沿技术。
  - TLS 的密码套件命名非常规范，格式很固定。
    基本的形式是“密钥交换算法 + 签名算法 + 对称加密算法 + 摘要算法”
    - “ECDHE-RSA-AES256-GCM-SHA384”。
    - “握手时使用 ECDHE 算法进行密钥交换，用 RSA 签名和身份认证，握手后的通信使用AES 对称算法，密钥长度 256 位，分组模式是 GCM，摘要算法 SHA384 用于消息认证和产生随机数。”
  - 机密性由对称加密AES保证，完整性由SHA384摘要算法保证，身份认证和不可否认由RSA非对称加密保证





## 对称加密与非对称加密

- 对称加密
  - 加密和解密时使用的密钥都是同一个
  - 对称算法还有一个“分组模式”的概念，它可以让算法用固定长度的密钥加密任意长度的明文，把小秘密（即密钥）转化为大秘密（即密文）。
    - 比如，AES128-GCM，意思是密钥长度为 128 位的 AES 算法，使用的分组模式是 GCM；
- 非对称加密
  - 对称加密看上去好像完美地实现了机密性，但其中有一个很大的问题：如何把密钥安全地传递给对方，术语叫“密钥交换”。
  - 所以，就出现了非对称加密（也叫公钥加密算法）。
  - 公钥和私钥有个特别的“单向”性，虽然都可以用来加密解密，但公钥加密后只能用私钥解密，反过来，私钥加密后也只能用公钥解密。
  - 非对称加密可以解决“密钥交换”的问题。网站秘密保管私钥，在网上任意分发公钥，你想要登录网站只要用公钥加密就行了，密文只能由私钥持有者才能解密。
- 在 TLS 里使用混合加密方式
  - 在通信刚开始的时候使用非对称算法，比如 RSA、ECDHE，首先解决密钥交换的问题。
  - 然后用随机数产生对称算法使用的“会话密钥”（session key），再用公钥加密。因为会话密钥很短，通常只有 16 字节或 32 字节，所以慢一点也无所谓。
  - 对方拿到密文后用私钥解密，取出会话密钥。这样，双方就实现了对称密钥的安全交换，后续就不再使用非对称加密，全都使用对称加密。





## 数字签名与证书

- 摘要算法
  - 实现完整性的手段主要是摘要算法（Digest Algorithm），也就是常说的散列函数、哈希函数（Hash Function）
  - 摘要算法实际上是把数据从一个“大空间”映射到了“小空间”，所以就存在“冲突”（collision，也叫碰撞）的可能性
  - 因为摘要算法对输入具有“单向性”和“雪崩效应”，输入的微小不同会导致输出的剧烈变化，所以也被 TLS 用来生成伪随机数
  - 摘要算法保证了“数字摘要”和原文是完全等价的。所以，我们只要在原文后附上它的摘要，就能够保证数据的完整性。
    - 不过摘要算法不具有机密性，如果明文传输，那么黑客可以修改消息后把摘要也一起改了，网站还是鉴别不出完整性。
    - 所以，真正的完整性必须要建立在机密性之上，在混合加密系统里用会话密钥加密消息和摘要，这样黑客无法得知明文，也就没有办法动手脚了
    - 这有个术语，叫哈希消息认证码（HMAC）
- 数字签名
  - 加密算法结合摘要算法，我们的通信过程可以说是比较安全了。但这里还有漏洞，就是通信的两个端点（endpoint）。
    - 非对称加密里的“私钥”，使用私钥再加上摘要算法，就能够实现“数字签名”，同时实现“身份认证”和“不可否认”。
  - 数字签名的原理其实很简单，就是把公钥私钥的用法反过来，之前是公钥加密、私钥解密，现在是私钥加密、公钥解密
  - 只要你和网站互相交换公钥，就可以用“签名”和“验签”来确认消息的真实性，因为私钥保密，黑客不能伪造签名，就能够保证通信双方的身份。
    - 比如，你用自己的私钥签名一个消息“我是小明”。网站收到后用你的公钥验签，确认身份
    - 没问题，于是也用它的私钥签名消息“我是某宝”。
    - 你收到后再用它的公钥验一下，也没问题，这样你和网站就都知道对方不是假冒的，后面就可以用混合加密进行安全通信了。
- 数字证书和 CA
  - 怎么来判断这个公钥就是你或者某宝的公钥呢？
  - 必须引入“外力”，找一个公认的可信第三方，让它作为“信任的起点，递归的终点”，构建起公钥的信任链。这个“第三方”就是我们常说的CA（Certificate Authority，证书认证机构）
  - CA 对公钥的签名认证也是有格式的，不是简单地把公钥绑定在持有者身份上就完事了，还要包含序列号、用途、颁发者、有效时间等等，把这些打成一个包再签名，完整地证明公钥关联的各种信息，形成“数字证书”（Certificate）。





## TLS1.2连接过程

- TLS 协议的组成

  - TLS 包含几个子协议，你也可以理解为它是由几个不同职责的模块组成
  - 记录协议（Record Protocol）规定了 TLS 收发数据的基本单位：记录（record）。
  - 警报协议（Alert Protocol）的职责是向对方发出警报信息，有点像是 HTTP 协议里的状态码。
  - 握手协议（Handshake Protocol）是 TLS 里最复杂的子协议，要比 TCP 的 SYN/ACK 复杂的多，浏览器和服务器会在握手过程中协商 TLS 版本号、随机数、密码套件等信息，然后交换证书和密钥参数，最终双方协商得到会话密钥，用于后续的混合加密系统。
  - 变更密码规范协议（Change Cipher Spec Protocol），它非常简单，就是一个“通知”，告诉对方，后续的数据都将使用加密保护。那么反过来，在它之前，数据都是明文的。

- TLS 的握手过程

  - ECDHE 握手过程
    - 在 TCP 建立连接之后，浏览器会首先发一个“Client Hello”消息
      - 里面有客户端的版本号、支持的密码套件，还有一个随机数（Client Random），用于后续生成会话密钥。
    - 服务器收到“Client Hello”后，会返回一个“Server Hello”消息
      - 把版本号对一下，也给出一个随机数（Server Random），然后从客户端的列表里选一个作为本次通信使用的密码套件
      - 然后，服务器为了证明自己的身份，就把证书也发给了客户端（Server Certificate）。
      - 因为服务器选择了 ECDHE算法，所以它会在证书后发送“Server Key Exchange”消息，里面是椭圆曲线的公钥（Server Params），用来实现密钥交换算法，再加上自己的私钥签名认证。
      - 之后是“Server Hello Done”消息，服务器说：“我的信息就是这些，打招呼完毕。”
    - 这样第一个消息往返就结束了（两个 TCP 包），结果是客户端和服务器通过明文共享了三个信息：Client Random、Server Random 和 Server Params。
    - 客户端这时也拿到了服务器的证书，开始走证书链逐级验证，确认证书的真实性，再用证书公钥验证签名，就确认了服务器的身份
    - 然后，客户端按照密码套件的要求，也生成一个椭圆曲线的公钥（Client Params），用“Client Key Exchange”消息发给服务器。
      - 现在客户端和服务器手里都拿到了密钥交换算法的两个参数（Client Params、Server Params），就用 ECDHE 算法一阵算，算出了一个新的东西，叫“Pre-Master”，其实也是一个随机数。
      - 现在客户端和服务器手里有了三个随机数：Client Random、Server Random 和 Pre-Master。用这三个作为原始材料，就可以生成用于加密会话的主密钥，叫“Master Secret”。而黑客因为拿不到“Pre-Master”，所以也就得不到主密钥。
      - 他们不信任客户端或服务器伪随机数的可靠性，为了保证真正的“完全随机”“不可预测”，把三个不可靠的随机数混合起来
    - 有了主密钥和派生的会话密钥，握手就快结束了。客户端发一个“Change Cipher Spec”，然后再发一个“Finished”消息，把之前所有发送的数据做个摘要，再加密一下，让服务器做个验证。意思就是告诉服务器：后面都改用对称算法加密通信了
    - 服务器也是同样的操作，发“Change Cipher Spec”和“Finished”消息，双方都验证加密解密 OK，握手正式结束，后面就收发被加密的 HTTP 请求和响应了。
  - RSA 握手过程
    - 这与传统的握手有两点不同
      - 第一个，使用 ECDHE 实现密钥交换，而不是 RSA，所以会在服务器端发出“Server Key Exchange”消息。
      - 第二个，因为使用了 ECDHE，客户端可以不用等到服务器发回“Finished”确认握手完毕，立即就发出 HTTP 报文，省去了一个消息往返的时间浪费。这个叫“TLS False Start”，意思就是“抢跑”
    - 大体的流程没有变，只是“Pre-Master”不再需要用算法生成，而是客户端直接生成随机数，然后用服务器的公钥加密，通过“Client Key Exchange”消息发给服务器。服务器再用私钥解密，这样双方也实现了共享三个随机数，就可以生成主密钥。

  





## TLS1.3特性

- TLS1.3 的三个主要改进目标：兼容、安全与性能
- 最大化兼容性
  - 在记录头的 Version 字段被兼容性“固定”的情况下，只要是 TLS1.3 协议，握手的“Hello”消息后面就必有“supported_versions”扩展，它标记了 TLS 的版本号，使用它就能区分新旧协议。
- 强化安全
  - TLS1.3 里只保留了 AES、ChaCha20 对称加密算法，分组模式只能用 AEAD 的 GCM、CCM 和 Poly1305，摘要算法只能用 SHA256、SHA384，密钥交换算法只有 ECDHE 和 DHE
- 提升性能
  - HTTPS 建立连接时除了要做 TCP 握手，还要做 TLS 握手，在 1.2 中会多花两个消息往返（2-RTT），可能导致几十毫秒甚至上百毫秒的延迟，在移动网络中延迟还会更严重。
  - TLS1.3压缩了以前的“Hello”协商过程，删除了“Key Exchange”消息，把握手时间减少到了“1-RTT”，效率提高了一倍
  - 其实具体的做法还是利用了扩展。客户端在“Client Hello”消息里直接用“supported_groups”带上支持的曲线，用“key_share”带上曲线对应的客户端公钥参数，用“signature_algorithms”带上签名算法。
    - 服务器收到后在这些扩展里选定一个曲线和参数，再用“key_share”扩展返回服务器这边的公钥参数，就实现了双方的密钥交换，后面的流程就和 1.2 基本一样了
    - 这时只交换了两条消息，客户端和服务器就拿到了四个共享信息：Client Random和Server Random、Client Params和Server Params，两边就可以各自用 ECDHE 算出“Pre-Master”，再用 HKDF 生成主密钥“Master Secret”
  - 在算出主密钥后，服务器立刻发出“Change Cipher Spec”消息，比 TLS1.2 提早进入加密通信，后面的证书等就都是加密的了，减少了握手时的明文信息泄露。
    - 这里 TLS1.3 还有一个安全强化措施，多了个“Certificate Verify”消息，用服务器的私钥把前面的曲线、套件、参数等握手数据加了签名，作用和“Finished”消息差不多。但由于是私钥签名，所以强化了身份认证和和防窜改。
  - 这两个“Hello”消息之后，客户端验证服务器证书，再发“Finished”消息，就正式完成了握手，开始收发 HTTP 报文

## HTTP/2特性

- HTTP 有两个主要的缺点：安全不足和性能不高。
- 兼容 HTTP/1
  - 因为必须要保持功能上的兼容，所以 HTTP/2 把 HTTP 分解成了“语义”和“语法”两个部分，“语义”层不做改动，与 HTTP/1 完全一致。比如请求方法、URI、状态码、头字段等概念都保留不变，
  - 特别要说的是，与 HTTPS 不同，HTTP/2 没有在 URI 里引入新的协议名，仍然用“http”表示明文协议，用“https”表示加密协议
  - 在“语义”保持稳定之后，HTTP/2 在“语法”层做了“天翻地覆”的改造，完全变更了HTTP 报文的传输格式。
- 头部压缩
  - 由于报文 Header 一般会携带“User Agent”“Cookie”“Accept”“Server”等许多固定的头字段，多达几百字节甚至上千字节，但 Body 却经常只有几十字节（比如 GET 请求、204/301/304 响应），成千上万的请求响应报文里有很多字段值都是重复的，非常浪费，“长尾效应”导致大量带宽消耗在了这些冗余度极高的数据上。
  - HTTP/2 并没有使用传统的压缩算法，而是开发了专门的“HPACK”算法，在客户端和服务器两端建立“字典”，用索引号表示重复的字符串，还釆用哈夫曼编码来压缩整数和字符串，可以达到 50%~90% 的高压缩率。
- 二进制格式
  - 报文不再使用肉眼可见的ASCII 码，而是向下层的 TCP/IP 协议“靠拢”，全面采用二进制格式。这样虽然对人不友好，但却大大方便了计算机的解析。
  - 二进制里只有“0”和“1”，可以严格规定字段大小、顺序、标志位等格式
  - 它把 TCP 协议的部分特性挪到了应用层，把原来的“Header+Body”的消息“打散”为数个小片的二进制“帧”（Frame），用“HEADERS”帧存放头数据、“DATA”帧存放实体数据。
- 虚拟的“流”
  - HTTP/2 为此定义了一个“流”（Stream）的概念，它是二进制帧的双向传输序列，同一个消息往返的帧会分配一个唯一的流 ID。
  - 你可以想象把它成是一个虚拟的“数据流”，在里面流动的是一串有先后顺序的数据帧，这些数据帧按照次序组装起来就是 HTTP/1 里的请求报文和响应报文。
  - 因为“流”是虚拟的，实际上并不存在，所以 HTTP/2 就可以在一个 TCP 连接上用“流”同时发送多个“碎片化”的消息，这就是常说的“多路复用”（ Multiplexing）——多个往返通信都复用一个连接来处理。
  - HTTP/1里的请求都是排队处理的，所以有队头阻塞。HTTP/2的请求是乱序的，彼此不依赖，所以没有队头阻塞。
  - HTTP/2 还在一定程度上改变了传统的“请求 - 应答”工作模式，服务器不再是完全被动地响应请求，也可以新建“流”主动向客户端发送消息
- 强化安全
  - 互联网上通常所能见到的 HTTP/2 都是使用“https”协议名，跑在 TLS 上面。
  - 为了区分“加密”和“明文”这两个不同的版本，HTTP/2 协议定义了两个字符串标识符：“h2”表示加密的 HTTP/2，“h2c”表示明文的 HTTP/2，多出的那个字母“c”的意思是“clear text”。







## HTTP/2内核

- 头部压缩
  - 因为语义上它与 HTTP/1 兼容，所以报文还是由“Header+Body”构成的，但在请求发送前，必须要用“HPACK”算法来压缩头部数据。
    - 与 gzip、zlib 等压缩算法不同，它是一个“有状态”的算法，需要客户端和服务器各自维护一份“索引表”，也可以说是“字典”，压缩和解压缩就是查表和更新表的操作。
  - 为了方便管理和压缩，HTTP/2 废除了原有的起始行概念，把起始行里面的请求方法、URI、状态码等统一转换成了头字段的形式，并且给这些“不是头字段的头字段”起了个特别的名字——“伪头字段”
    - 为了与“真头字段”区分开来，这些“伪头字段”会在名字前加一个“:”，比如“:authority”    “:method”     “:status”，分别表示的是域名、请求方法和状态码。
- 二进制帧
  - 头部数据压缩之后，HTTP/2 就要把报文拆成二进制的帧准备发送。
  - HTTP/2 的帧结构有点类似 TCP 的段或者 TLS 里的记录，但报头很小，只有 9 字节，非常节省（可以对比一下 TCP 头，它最少是 20 个字节）。
    - 帧开头是 3 个字节的长度（但不包括头的 9 个字节），默认上限是 2^14，最大是 2^24，也就是说 HTTP/2 的帧通常不超过 16K，最大是 16M。
    - 长度后面的一个字节是帧类型，大致可以分成数据帧和控制帧两类
    - 第 5 个字节是非常重要的帧标志信息，可以保存 8 个标志位，携带简单的控制信息。
    - 流标识符，也就是帧所属的“流”，接收方使用它就可以从乱序的帧里识别出具有相同流 ID 的帧序列，按顺序组装起来就实现了虚拟的“流”。
- 流与多路复用
  - 在 HTTP/2 连接上，虽然帧是乱序收发的，但只要它们都拥有相同的流 ID，就都属于一个流，而且在这个流里帧不是无序的，而是有着严格的先后顺序。
  - 流是可并发的，一个 HTTP/2 连接上可以同时发出多个流传输数据，也就是并发多请求，实现“多路复用”；
    - HTTP/2 在一个连接上使用多个流收发数据，那么它本身默认就会是长连接，所以永远不需要“Connection”头字段（keepalive 或 close）
  - 流可以设置优先级，让服务器优先处理
  - 流 ID 不能重用，只能顺序递增，客户端发起的 ID 是奇数，服务器端发起的 ID 是偶数；
  - 第 0 号流比较特殊，不能关闭，也不能发送数据帧，只能发送控制帧，用于流量控制。
  - 在流上发送“RST_STREAM”帧可以随时终止流，取消接收或发送；
- 流状态转换
  - 流很重要，也很复杂。为了更好地描述运行机制，HTTP/2 借鉴了 TCP，根据帧的标志位实现流状态转换。当然，这些状态也是虚拟的，只是为了辅助理解。
  - 对应到一个标准的 HTTP“请求 - 应答”
    - 最开始的时候流都是“空闲”（idle）状态
    - 当客户端发送 HEADERS 帧后，有了流 ID，流就进入了“打开”状态，两端都可以收发数据，然后客户端发送一个带“END_STREAM”标志位的帧，流就进入了“半关闭”状态。
      - 这个“半关闭”状态很重要，意味着客户端的请求数据已经发送完了，需要接受响应数据，而服务器端也知道请求数据接收完毕，之后就要内部处理，再发送响应数据。
    - 响应数据发完了之后，也要带上“END_STREAM”标志位，表示数据发送完毕，这样流两端就都进入了“关闭”状态，流就结束了。
    - 刚才也说过，流 ID 不能重用，所以流的生命周期就是 HTTP/1 里的一次完整的“请求 - 应答”，流关闭就是一次通信结束。
    - 下一次再发请求就要开一个新流（而不是新连接），流 ID 不断增加，直到到达上限，发送“GOAWAY”帧开一个新的 TCP 连接，流 ID 就又可以重头计数。







## HTTP/3

- HTTP/2 的“队头阻塞”
  - HTTP/2 虽然使用“帧”“流”“多路复用”，没有了“队头阻塞”，但这些手段都是在应用层里，而在下层，也就是 TCP 协议里，还是会发生“队头阻塞”。
  - 让我们从协议栈的角度来仔细看一下。在 HTTP/2 把多个“请求 - 响应”分解成流，交给TCP 后，TCP 会再拆成更小的包依次发送（其实在 TCP 里应该叫 segment，也就是“段”）。
  - TCP 为了保证可靠传输，有个特别的“丢包重传”机制，丢失的包必须要等待重新传输确认，其他的包即使已经收到了，也只能放在缓冲区里，上层的应用拿不出来，只能“干着急”。
  - 由于这种“队头阻塞”是 TCP 协议固有的，所以 HTTP/2 即使设计出再多的“花样”也无法解决。
- QUIC协议
  - 是一个传输层的协议，和 TCP 是平级的
  - “HTTP over QUIC”就是 HTTP 协议的下一个大版本，HTTP/3。它在 HTTP/2 的基础上又实现了质的飞跃，真正“完美”地解决了“队头阻塞”问题。
  - HTTP/3 有一个关键的改变，那就是它把下层的 TCP“抽掉”了，换成了 UDP。因为 UDP 是无序的，包之间没有依赖关系，所以就从根本上解决了“队头阻塞”
  - QUIC 就选定了 UDP，在它之上把 TCP 的那一套连接管理、拥塞窗口、流量控制等“搬”了过来，“去其糟粕，取其精华”，打造出了一个全新的可靠传输协议，可以认为是“新时代的 TCP”。
- QUIC 的特点
  - QUIC 基于 UDP，而 UDP 是“无连接”的，根本就不需要“握手”和“挥手”，所以天生就要比 TCP 快。
  - 就像 TCP 在 IP 的基础上实现了可靠传输一样，QUIC 也基于 UDP 实现了可靠传输，保证数据一定能够抵达目的地。它还引入了类似 HTTP/2 的“流”和“多路复用”，单个“流”是有序的，可能会因为丢包而阻塞，但其他“流”不会受到影响。
  - QUIC 并不是建立在 TLS 之上，而是内部“包含”了 TLS。它使用自己的帧“接管”了TLS 里的“记录”，握手消息、警报消息都不使用 TLS 记录，直接封装成 QUIC 的帧发送，省掉了一次开销。
- QUIC 内部细节
  - QUIC 的基本数据传输单位是包（packet）和帧（frame），一个包由多个帧组成，包面向的是“连接”，帧面向的是“流”。
  - QUIC 的帧里有多种类型，PING、ACK 等帧用于管理连接，而 STREAM 帧专门用来实现流。
  - QUIC 使用不透明的“连接 ID”来标记通信的两个端点，客户端和服务器可以自行选择一组 ID 来标记自己，这样就解除了 TCP 里连接对“IP 地址 + 端口”（即常说的四元组）的强绑定，支持“连接迁移”
- HTTP/3 协议
  - 因为 QUIC 本身就已经支持了加密、流和多路复用，所以 HTTP/3 的工作减轻了很多，把流控制都交给 QUIC 去做。调用的不再是 TLS 的安全接口，也不是 Socket API，而是专门的 QUIC 函数。不过这个“QUIC 函数”还没有形成标准，必须要绑定到某一个具体的实现库。
  - HTTP/3 里仍然使用流来发送“请求 - 响应”，但它自身不需要像 HTTP/2 那样再去定义流，而是直接使用 QUIC 的流，相当于做了一个“概念映射”。
  - 由于流管理被“下放”到了 QUIC，所以 HTTP/3 里帧的结构也变简单了。
    - 帧头只有两个字段：类型和长度
    - HTTP/3 里的帧仍然分成数据帧和控制帧两类，HEADERS 帧和 DATA 帧传输数据，但其他一些帧因为在下层的 QUIC 里有了替代，所以在 HTTP/3 里就都消失了，比如RST_STREAM、WINDOW_UPDATE、PING 等。
    - 头部压缩算法在 HTTP/3 里升级成了“QPACK”，使用方式上也做了改变。虽然也分成静态表和动态表，但在流上发送 HEADERS 帧时不能更新字段，只能引用，索引表的更新需要在专门的单向流上发送指令来管理，解决了 HPACK 的“队头阻塞”问题。




