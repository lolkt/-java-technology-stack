## RPC的通信流程

- RPC 的作用就是体现在这样两个方面
  - 屏蔽远程调用跟本地调用的区别，让我们感觉就是调用项目内的方法；
  - 隐藏底层网络通信的复杂性，让我们更专注于业务逻辑
- 那一个完整的 RPC 会涉及到哪些步骤
  -  RPC 是一个远程调用，那肯定就需要通过网络来传输数据，并且 RPC 常用于业务系统之间的数据交互，需要保证其可靠性，所以 RPC 一般默认采用 TCP 来传输。我们常用的 HTTP 协议也是建立在 TCP 之上的。 
  - 网络传输的数据必须是二进制数据，但调用方请求的出入参数都是对象。对象是肯定没法直 接在网络中传输的，需要提前把它转成可传输的二进制，并且要求转换算法是可逆的，这个过程我们一般叫做“序列化”。
  - 服务提供方从 TCP 通道里面收到二进制数据，那如何知道一个请求的数据到哪里结束，是一个什么类型的请求呢？
    - 把数据格式的约定内容叫做“协议”。
    - 大多数的协议会分成两部分，分别是数据头和消息体。
  - 反序列化
  - 服务提供方再根据反序列化出来的请求对象找到对应的实现类，完成真正的方法调用，然后 把执行结果序列化后，回写到对应的 TCP 通道里面。调用方获取到应答的数据包后，再反序列化成应答对象，这样调用方就完成了一次 RPC 调用。
- 有什么办法来简化 API，屏蔽掉 RPC 细节，让使用方只需要关注业务接口，像调用本地一样来调用远程呢
  - 由服务提供者给出业务接口声明，在调用方的程序里面，RPC 框架根据调用的服务接口提前生成动态代理实现类，并通过依赖注入等技术注入到声明了该接口的相关业务逻辑里面。 该代理实现类会拦截所有的方法调用，在提供的方法处理逻辑里面完成一整套的远程调用， 并把远程调用结果返回给调用方，这样调用方在调用远程方法的时候就获得了像调用本地接口一样的体验









## **协议：怎么设计可扩展且向后兼容的协议**

- HTTP 协议跟 RPC 协议有一个共性就是都属于应用层协议。 

  - RPC 不直接用 HTTP 协议的一个原因是无法实现请求跟响应关联，每次请求都需要重新建立连接，响应完成后再关闭连接，所以我们要设计私有协议。
    - rpc为了吞吐量，会异步并发发送请求，等待应答，所以需要知道哪个应答对应那个请求 
    - 调用方需要维护消息ID列表，然后和返回结果中的消息ID做匹配
  - 在 RPC 里面，协议的作用就类似于文字中的符号，作为应用拆解请求消息的边界，保证二进制数据经过网络传输后，还能被正确地还原语义
  - 举个具体例子，调用方发送 AB、CD、EF 3 个消息，如果没有边界的话，接收端就可能收到 ABCDEF 或者ABC、DEF 这样的消息，这就会导致接收的语义跟发送的时候不一致了。
  - 所以呢，为了避免语义不一致的事情发生，我们就需要在发送请求的时候设定一个边界，然 后在收到请求的时候按照这个设定的边界进行数据分割。这个边界语义的表达，就是我们所说的协议。 

- 相对于 HTTP 的用处，RPC 更多的是负责应用间的通信，所以性能要求相对更高

  - 在协议里面需要放哪些内容

    - 在协议头里面，我们除了会放协议长度、序列化方式，还会放一些像协议标示、消息 ID、消息类型这样的参数，而协议体一般只放请求接口方法、请求的业务参数值和一些扩展属性。

  - 为了保证能平滑地升级改造前后的协议，我们有必要设计一种支持可扩展的协议

    - 整体协议就变成了三部分内容：固定部分、协议头内容、协议体内容，前两部分我们还是可以统称为“协议头”

      







## **序列化：对象怎么在网络中传输**

- 序列化过程就是在读取对象数据的时候，不断加入一些特殊分隔符，这些特殊分隔符用于在反序列化过程中截断用。
- Protobuf
  - 混合语言数据标准，是一种轻便、高效的结构化数据存储格式，可以用于结构化数据序列化
  - 优点
    - 序列化后体积相比 JSON、Hessian 小很多； 
    - IDL 能清晰地描述语义，所以足以帮助并保证应用程序之间的类型不会丢失，无需类似XML 解析器； 
    - 序列化反序列化速度很快，不需要通过反射获取类型； 
    - 消息格式升级和兼容性不错，可以做到向后兼容
- RPC 框架中如何选择序列化
  - 性能和效率
  - 空间开销
  - 序列化协议的通用性和兼容性
  - 安全性
- RPC 框架在使用时要注意哪些问题
  - 对象构造得过于复杂
  - 对象过于庞大
  - 使用序列化框架不支持的类作为入参类
  - 对象有复杂的继承关系







##  网络通信：RPC框架在网络通信上更倾向于哪种网络IO模型

- 常见的网络IO模型
  - 阻塞 IO（blocking IO）
    - 首先，应用进程发起 IO 系统调用后，应用进程被阻塞，转到内核空间处理。之后，内核开始等待数据，等待到数据之后，再将内核中的数据拷贝到用户内存中，整个 IO 处理完毕后返回进程。最后应用的进程解除阻塞状态，运行业务逻辑。 
  - IO 多路复用（IO multiplexing）
    - 多个网络连接的 IO 可以注册到一个复用器（select）上，当用户进程调用了 select，那么整个进程会被阻塞。同时，内核会“监视”所有 select 负责的 socket，当任何一个 socket 中的数据准备好了，select 就会返回。这个时候用户进程再调用 read 操作，将数据从内核中拷贝到用户进程。
    - 最大的优势在于，用户可以在一个线程内同时处理多个 socket 的 IO 请求。

- 为什么说阻塞 IO 和IO多路复用最为常用？

  - 实际在网络 IO 的应用上，需要的是系统内核的支持以及编程语言的支持。

- RPC框架在网络通信上倾向选择哪种网络IO模型

  - IO 多路复用更适合高并发的场景
  - RPC 调用在大多数的情况下，是一个高并发调用的场景

- 零拷贝

  - 应用进程的每一次写操作，都会把数据写到用户空间的缓冲区中，再由 CPU 将数据拷贝到系统内核的缓冲区中，之后再由 DMA 将这份数据拷贝到网卡中，最后由网卡发送出去。 这里我们可以看到，一次写操作数据要拷贝两次才能通过网卡发送出去，而用户进程的读操作则是将整个流程反过来，数据同样会拷贝两次才能让应用程序读取到数据
    - 每一次拷贝，都需要 CPU 进行一次上下文切换（由用户进程切换到系统内核，或由系统内核切换到用户进程）
  - 所谓的零拷贝，就是取消用户空间与内核空间之间的数据拷贝操作
    - 零拷贝有两种解决方式，分别是 mmap+write 方式和 sendfile 方式，其核心原理都是通过虚拟内存来解决的

  





## 动态代理：面向接口编程，屏蔽RPC处理流程

- RPC 会自动给接口生成一个代理类，当我们在项目中注入接口的时候，运行过程中实际绑定的是这个接口生成的代理类。在生成的代理类里面，加入远程调用逻辑
- 通过 Javassist 生成字节码，不 需要通过反射完成方法调用，所以性能肯定是更胜一筹的





## **设计一个灵活的**RPC框架

- RPC 框架就包含了两大核心体系——核心功能体系与插件体系
  - 入口层
    - 动态代理
    - 链路追踪
    - 过滤链
  - 集群层
    - 服务发现
    - 连接管理
    - 负载均衡
    - 路由
    - 容错
    - 配置管理
  - 协议层
    - 协议
    - 序列化
    - 解压缩
  - 传输层
    - TCP传输
    - HTTP传输







## 服务发现：到底是要CP还是AP

- 服务发现的作用就是 实时感知集群 IP 的变化，实现接口跟服务集群节点 IP 的映射。
- 基于消息总线的最终一致性的注册中心
  - 注册数据可以全量缓存在每个注册中心内存中，通过消息总线来同步数据。当有一个注册中心节点接收到服务节点注册时，会 产生一个消息推送给消息总线，再通过消息总线通知给其它注册中心节点更新数据并进行服务下发，从而达到注册中心间数据最终一致性
  - 当有服务上线，注册中心节点收到注册请求，服务列表数据发生变化，会生成一个消息，推送给消息总线，每个消息都有整体递增的版本。
  - 消息总线会主动推送消息到各个注册中心，同时注册中心也会定时拉取消息。对于获取 到消息的在消息回放模块里面回放，只接受大于本地版本号的消息，小于本地版本号的消息直接丢弃，从而实现最终一致性
  - 消费者订阅可以从注册中心内存拿到指定接口的全部服务实例，并缓存到消费者的内存里面。
  - 采用推拉模式，消费者可以及时地拿到服务实例增量变化情况，并和内存中的缓存数据 进行合并。





## **健康检测：这个节点都挂了，为啥还要疯狂发请求**

- **让调用方实时感知到节点的状态变化**
  - 业内常用的检测方法就是用心跳机制
  - “连续”心跳失败次数必须到达某一个阈值，比如 3 次
- 节点的心跳日志只是间歇性失败，也就是时好时坏
  - 第一，像前面说的那样，调用方跟服务节点之间网络状况瞬息万变，出现网络波动的时候会导致误判。第二，在负载高情况，服务端来不及处理心跳请求，由于心跳时间很短，会导致调用方很快触发连续心跳失败而造成断开连接
  - 调用方每个接口的调用频次不一样，有的接口可能 1 秒内调用上百次，有的接口可能半个小时才会调用一次，所以我们不能把简单的把总失败的次数当作判断条件。
  - 服务的接口响应时间也是不一样的，有的接口可能 1ms，有的接口可能是 10s，所以我们也不能把 TPS 至来当作判断条件。 
- **可用率**
  - 某一个时间窗口内接口调用成功次数的百分比（成功次数 / 总调用次数）。当可用率低于某个比例就认为这个节点存在问题
- 误判：检测程序所在的机器和目标机器之间的网络可能还会出现故障
  - 把检测程序部署在多个机器里面，分布在不同的机架，甚至不同的机房。因为网络同时故障的概率非常低，所以只要任意一个检测程序实例访问目标机器正常，就可以说明该目标机器正常。





## **路由策略：怎么让请求按照设定的规则发到不同的节点上**

- 灰度发布功能作为 RPC 路由功能的一个典型应用场景，我们可以通过路由功能完成像定点调用、黑白名单等一些高级服务治理功能。在 RPC 里面，不管是哪种路由策略，其核心思想都是一样的，就是让请求按照我们设定的规则发送到目标节点上，从而实现流量隔离的效果。 
- 路由本质是节点分组、隔离流量
-  用路由策略实现过灰度发布、定点调用、并行开发的时候，隔离出不同联调环境等功能







## **负载均衡：节点负载差距这么大，为什么收到的流量还一样**

- 当我们的一个服务节点无法支撑现有的访问量时，我们会部署多个节点，组成一个集群，然后通过负载均衡，将请求分发给这个集群下的每个服务节点，从而达到多个服务节点共同分担请求压力的目的。 

- 传统负载均衡面临这样几个问题
  - 搭建负载均衡设备或 TCP/IP 四层代理，需要额外成本；
  - 请求流量都经过负载均衡设备，多经过一次网络传输，会额外浪费一些性能；
  - 负载均衡添加节点和摘除节点，一般都要手动添加
  - 我们在服务治理的时候，针对不同接口服务、服务的不同分组，我们的负载均衡策略是需要可配的，如果大家都经过这一个负载均衡设备，就不容易根据不同的场景来配置不同的负载均衡策略了。

- RPC 的负载均衡完全由 RPC 框架自身实现，RPC 的服务调用者会与“注册中心”下发的所 有服务节点建立长连接，在每次发起 RPC 调用时，服务调用者都会通过配置的负载均衡插件，自主选择一个服务节点，发起 RPC 调用请求。
- 如何设计自适应的负载均衡
  - 可以采用一种根据指标打分的策略
  - 然后我们可以配合随机权重的负载均衡策略去控制，通过最终的指标分数修改服务节点最终的权重。

- 以 Dubbo 为例，常用的负载均衡方法有：
  - 基于权重随机算法
  - 基于最少活跃调用数算法
  - 基于 hash 一致性
  - 基于加权轮询算法
- 路由策略使用的场景是流量隔离，比如在灰度验证过程。负载均衡使用的场景则是请求智能调度，尽可能保证选择一个最合适的节点来调用





## **异常重试：在约定时间内安全可靠地重试**

- 在使用 RPC 框架的时候，我们要确保被调用的服务的业务逻辑是幂等的，这样我们才能考虑根据事件情况开启 RPC 框架的异常重试功能
- 如何在约定时间内安全可靠地重试
  - 解决这个问题最直接的方式就是，在每次重试后都重置一下请求的超时时间。
  - 在所有发起重试、负载均衡选择节点的时候，去掉重试之前出现过问题的那个节点，以保证重试的成功率
  - RPC 框架是不会知道哪些业务异常能够去进行异常重试的，我们可以加个重试异常的白名单，用户可以将允许重试的异常加入到这个白名单中。
- 在整个 RPC 调用的流程中，异常重试发生在动态代理发起invoke，紧接着的一步的环节





## **优雅关闭：如何避免服务停机带来的业务损失**

- 在关闭的时候，设置一个请求“挡板”，挡板的作用就是告诉调用方，我已经开始进入关闭流程了，我不能再处理你这个请求了。 	
  - 当服务提供方正在关闭，如果这之后还收到了新的业务请求，服务提供方直接返回一个特定的异常给调用方（比如 ShutdownException）。这个异常就是告诉调用方“我已经收到这个请求了，但是我正在关闭，并没有处理这个请求”， 然后调用方收到这个异常响应后，RPC 框架把这个节点从健康列表挪出，并把请求自动重 试到其他节点，因为这个请求是没有被服务提供方处理过，所以可以安全地重试到其他节 点，这样就可以实现对业务无损。
- 怎么捕获到关闭事件呢
  - 通过捕获操作系统的进程信号来获取
  - 在 Java 语言里面，对应的是Runtime.addShutdownHook 方法，可以注册关闭的钩子。
  - 服务对象在关闭过程中，会拒绝新的请求，同时根据引用计数器等待正在处理的请求全部结束之后才会真正关闭。但考虑到有些业务请求可能处理时间长，或者存在被挂住的情况，为了避免一直等待造成应用无法正常退出，我们可以在整个 ShutdownHook 里面，加上超时时间控制，当超过了指定时间没有结束，则强制退出应用。超时时间我建议可以设定成 10s，基本可以确保请求都处理完了。







## **优雅启动：如何避免流量打到没有启动完成的节点**

- 启动预热
  - 简单来说，就是让刚启动的服务提供方应用不承担全部的流量，而是让它被调用的次数随着时间的移动慢慢增加，最终让流量缓和地增加到跟已经运行一段时间后的水平一样。
  - 调用方通过服务发现，除了可以拿到 IP 列表，还可以拿到对应的启动时间。我们需要把这个时间作用在负载均衡上，通过一种基于权重的负载均衡，但是这个权重是由服务提供方设置的，属于一个固定状态。现在我们要让这个权重变成动态的，并且是随着时间的推移慢慢增加到服务提供方设定的固定值
- 延迟暴露
  - 在应用启动加载、解析 Bean 的时候，如果遇到了 RPC 服务的 Bean，只先把这个 Bean 注册到 Spring-BeanFactory 里面去，而并不把这个 Bean 对应的接口注册到注册中心，只有等应用启动完成后，才把接口注册到注册中心用于服务发现，从而实现让服务调用方延迟获取到服务提供方地址。
  - 但其实这样做，我们还是没有实现最开始的目标。因为这时候应用虽然启动完成了，但并没有执行相关的业务代码，所以 JVM 内 存里面还是冷的。如果这时候大量请求过来，还是会导致整个应用在高负载模式下运行，从 而导致不能及时地返回请求结果。而且在实际业务中，一个服务的内部业务逻辑一般会依赖 其它资源的，比如缓存数据。如果我们能在服务正式提供服务前，先完成缓存的初始化操作，而不是等请求来了之后才去加载，我们就可以降低重启后第一次请求出错的概率。 
  - 我们可以在服务提供方应 用启动后，接口注册到注册中心前，预留一个 Hook 过程，让用户可以实现可扩展的 Hook 逻辑。用户可以在 Hook 里面模拟调用逻辑，从而使 JVM 指令能够预热起来，并且 用户也可以在 Hook 里面事先预加载一些资源，只有等所有的资源都加载完成后，最后才 把接口注册到注册中心。







## **熔断限流：业务如何实现自我保护**

- 我们可以提供一个专门的限流服务，让每个节点都依赖一个限流服务，当请求流量打过来时，服务节点触发限流逻辑，调用这个限流服务来判断是否到达了限流阈值。
  - 这种限流方式可以让整个服务集群的限流变得更加精确，但也由于依赖了一个限流服务，它 在性能和耗时上与单机的限流方式相比是有很大劣势的。
- 在一个服务作为调用端调用另外一个服务时，为了防止被调用的服务出现问题而影 响到作为调用端的这个服务，这个服务也需要进行自我保护。而最有效的自我保护方式就是熔断。
  - 在 RPC 调用的流程中，动态代理是 RPC 调用的第一个关口。在发出请求时先经过熔断器，如果状态是闭合则正常发出请求，如果状态是打开则执行熔断器的失败策略

- 服务的自我保护：
  1：压测——进行性能优化及容量规划
  2：限流——防止服务端被流量高峰压垮
  3：降级——优先保证核心服务高可用
  4：熔断——防止当前服务被下游慢服务拖垮
  5：自动扩缩容——可以扛住流量洪峰，需要资源冗余





## **业务分组：如何隔离流量**

- 说起突发流量，限流固然是一种手段，但其实面对复杂的业务以及高并发场景时，我们还 有别的手段，可以最大限度地保障业务无损，那就是隔离流量。
- 为了实现分组隔离逻辑，我们需要重新改造下服务发现的逻辑，调用方去获取服务节点的时候除了要带着接口名，还需要另外加一个分组参数
  - 一个规则可以供你参考，就是按照应用重要级别划分。









## 异步RPC：压榨单机吞吐量

- 调用端如何异步
  - 说到异步，我们最常用的方式就是返回 Future 对象的 Future 方式，或者入参为 Callback对象的回调方式
  - 对于调用端来说，向服务端发送请求消息与接收服务端发送过来的响应消息，这两个处理过程是两个完全独立的过程，这两个过程甚至在大多数情况下都不在一个线程中进行
    - 调用端发送的每条消息都一个唯一的消息标识，实际上调用端向服务端发送请求消息之前会先创建一个 Future，并会存储这个消息标识与这个 Future的映射，动态代理所获得的返回值最终就是从这个 Future 中获取的；
    - 当收到服务端响应的消息时，调用端会根据响应消息的唯一标识，通过之前存储的映射找到对应的 Future，将结果注入给那个 Future，再进行一系列的处理逻辑，最后动态代理从 Future 中获得到正确的返回值。
- 服务端如何异步
  - 对二进制包的处理是在 IO 线程中，而解码与反 序列化的过程也往往在 IO 线程中处理，那服务端的业务逻辑呢？也应该在 IO 线程中处理吗？原则上是不应该的，业务逻辑应该交给专门的业务线程池处理，以防止由于业务逻辑处 理得过慢而影响到网络 IO 的处理。
  - 业务线程池的线程数一般只会配置到 200，因为在大多数情况下线程数配置到 200 还不够用就说明业务逻辑该优化了。
  - 服务端执行完业务逻辑之后，要对返回值进行序列化并且编码，将消息响应给调用端，但如果是异步处理，业务逻辑触发异步之后方法就执行完了，来不及将真正的结果进行序列化并编码之后响应给调用端
    - 这时我们就需要 RPC 框架提供一种回调方式，让业务逻辑可以异步处理，处理完之后调用RPC 框架的回调接口，将最终的结果通过回调的方式响应给调用端。
  - 其实我们可以让 RPC 框架支持 CompletableFuture，实现 RPC 调用在调用端与服务端之间完全异步。
    - 服务调用方发起 RPC 调用，直接拿到返回值 CompletableFuture 对象，之后就不需要 任何额外的与 RPC 框架相关的操作了（如我刚才讲解 Future 方式时需要通过请求上下文获取 Future 的操作），直接就可以进行异步处理
    - 在服务端的业务逻辑中创建一个返回值 CompletableFuture 对象，之后服务端真正的业务逻辑完全可以在一个线程池中异步处理，业务逻辑完成之后再调用这个CompletableFuture 对象的 complete 方法，完成异步通知
    - 调用端在收到服务端发送过来的响应之后，RPC 框架再自动地调用调用端拿到的那个返回值 CompletableFuture 对象的 complete 方法，这样一次异步调用就完成了。 
- 异步对于服务提供方来说，rpc线程所要处理的事情就变少了







## **动态分组：超高效实现秒级扩缩容**

- 给每个分组分配相应的机器数量
  - 先通过压测去评估下服务提供方单台机器所能承受的 QPS，然后再计算出每个分组里面的所有调用方的调用总量。有了这两个值之后，我们就能很容易地计算出这个分组所需要的机器数。 
- 某个分组的调用方流量突增，而这个分组所预留的空间也不能满足当前流量的需求，但是其它分组的服务提供方有足够的富余能力。
  - 但这些富余的能力，又被我们的分组进行了强制的隔离，我们又不能抛弃分组功能
  - 我们只要把注册中心里面的部分实例的别名改成我们想要的别名，然后通过服务发现进而影响到不同调用方能够调用的服务提供方实例集合。 
- 在服务治理的过程中，我们通常会给服务进行逻辑分组，但之后某个分组可能会遇到突发流 量调用的问题，在本讲我给出了一个动态分组的方案。但是动态分组的过程中，我们只是把注册中心的数据改了，而服务提供方提供真实的分组名并没有改变，这时候用动态分组名的调用方调用过来的请求可能就会报错，因为服务提供方会验证调用方过来的分组名跟自身的 是否一样。针对这个问题，你能想到什么解决方案？ 
  - 请求头里面带上真实分组信息







## 如何在没有接口的情况下进行RPC调用

- 让调用端在没有接口 API 的情况下发起 RPC 调用的需求，列举两个非常典型的场景例
  - 我们要搭建一个统一的测试平台，可以让各个业务方在测试平台中通过输入接口、 分组名、方法名以及参数值，在线测试自己发布的 RPC 服务。这时我们就有一个问题要解决，我们搭建统一的测试平台实际上是作为各个 RPC 服务的调用端，而在 RPC 框架的使 用中，调用端是需要依赖服务提供方提供的接口 API 的，而统一测试平台不可能依赖所有服务提供方的接口 API。我们不能因为每有一个新的服务发布，就去修改平台的代码以及重新上线。这时我们就需要让调用端在没有服务提供方提供接口的情况下，仍然可以正常地发起 RPC 调用。
  - 我们要搭建一个轻量级的服务网关，可以让各个业务方用 HTTP 的方式，通过服 务网关调用其它服务。这时就有与场景一相同的问题，服务网关要作为所有 RPC 服务的调用端，是不能依赖所有服务提供方的接口 API 的，也需要调用端在没有服务提供方提供接口的情况下，仍然可以正常地发起 RPC 调用。
- RPC 框架要实现这个功能，我们可以使用泛化调用
  - 我们可以定义一个统一的接口（GenericService），调用端在创建 GenericService 代理时指定真正需要调用的接口的接口名以及分组名，而 GenericService 接口的 $invoke 方法的入参就是方法名以及参数信息
- 在没有服务提供方提供接口 API 的情况下，我们可以用泛化调用的方式实现 RPC 调用，但是如果没有服务提供方提供接口 API，我们就没法得到入参以及返回值的 Class 类，也就不能对入参对象进行正常的序列化。这时我们会面临两个问题
  - 调用端不能对入参对象进行正常的序列化，那调用端、服务端在接收到请求消息后，入参对象又该如何序列化与反序列化呢？ 
    - 在 RPC 框架的整体架构中就包括了序列化插件，我们可以为泛化调用提供专属的序列化插件，通过这个插件，解决泛化调用中的序列化与反序列化问题。
  - 调用端的入参对象（params）与返回值应该是什么类型呢？
    - 在服务提供方提供的接口 API 中，被调用的方法的入参类型是一个对象，那么使用泛化调 用功能的调用端，可以使用 Map 类型的对象，之后通过泛化调用专属的序列化方式对这个 Map 对象进行序列化，服务端收到消息后，再通过泛化调用专属的序列化方式将其反序列成对象。





































