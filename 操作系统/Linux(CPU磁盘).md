## 平均负载

- 每次发现系统变慢时，我们通常做的第一件事，就是执行 top 或者 uptime 命令

  - 过去 1 分钟、5 分钟、15 分钟的平均负载（LoadAverage）
  - 简单来说，平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数，它和 CPU 使用率并没有直接关系。
    - 所谓可运行状态的进程，是指正在使用 CPU 或者正在等待 CPU 的进程，也就是我们常用ps 命令看到的，处于 R 状态（Running 或Runnable）的进程。
    - 不可中断状态的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如最常见的是等待硬件设备的 I/O 响应，也就是我们在 ps 命令中看到的 D 状态（Uninterruptible Sleep，也称为 Disk Sleep）的进程。
      - 不可中断状态实际上是系统对进程和硬件设备的一种保护机制

- 平均负载为多少时合理

  - 当平均负载比 CPU 个数还大的时候，系统已经出现了过载。
  - 假设我们在一个单 CPU 系统上看到平均负载为 1.73，0.60，7.98，那么说明在过去 1 分钟内，系统有 73% 的超载，而在 15 分钟内，有 698% 的超载，从整体趋势来看，系统的负载在降低。
  - 在实际生产环境中，当平均负载高于 CPU 数量 70% 的时候需要我们重点关注

- 平均负载与 CPU 使用率

  - CPU 使用率，是单位时间内 CPU 繁忙情况的统计，跟平均负载并不一定完全对应
  - 平均负载它不仅包括了正在使用 CPU 的进程，还包括等待 CPU 和等待I/O 的进程。
    - CPU 密集型进程，使用大量 CPU 会导致平均负载升高，此时这两者是一致的；
    - I/O 密集型进程，等待 I/O 也会导致平均负载升高，但 CPU 使用率不一定很高；

- 工具

  - stress 是一个 Linux 系统压力测试工具，这里我们用作异常进程模拟平均负载升高的场景。

    - > 模拟一个 CPU 使用率 100% 的场景    stress --cpu 1 --timeout 600
      >
      > 模拟 I/O 压力，即不停地执行 sync     stress -i 1 --timeout 600
      >
      > 模拟8 个进程                                    stress -c 8 --timeout 600

  - mpstat 是一个常用的多核 CPU 性能分析工具，用来实时查看每个 CPU 的性能指标，以及所有 CPU 的平均指标

  - pidstat 是一个常用的进程性能分析工具，用来实时查看进程的 CPU、内存、I/O 以及上下文切换等性能指标。

    - > -w 参数表示输出进程切换指标，
      >
      > -u 参数则表示输出 CPU 使用指标
      >
      > -d 所有进程的 I/O 使用情况
      >
      > -t 参数表示输出线程的指标。
      >
      > -p 指定进程号



## 用户态和内核态

- 用户态：只能受限的访问内存，且不允许访问外围设备，占用cpu的能力被剥夺，cpu资源可以被其他程序获取。

- 内核态：cpu可以访问内存的所有数据，包括外围设备，例如硬盘，网卡，cpu也可以将自己从一个程序切换到另一个程序。

- 为什么要有用户态和内核态？

  - 由于需要限制不同的程序之间的访问能力, 防止他们获取别的程序的内存数据, 或者获取外围设备的数据, 并发送到网络, CPU划分出两个权限等级 -- 用户态和内核态。

- **用户态与内核态的切换**

  所有用户程序都是运行在用户态的, 但是有时候程序确实需要做一些内核态的事情, 例如从硬盘读取数据, 或者从键盘获取输入等. 而唯一可以做这些事情的就是操作系统, 所以此时程序就需要先操作系统请求以程序的名义来执行这些操作.

  这时需要一个这样的机制: 用户态程序切换到内核态, 但是不能控制在内核态中执行的指令

  这种机制叫系统调用, 在CPU中的实现称之为**陷阱指令**(Trap Instruction)

  他们的**工作流程**如下:

  1. 用户态程序将一些数据值放在寄存器中, 或者使用参数创建一个堆栈(stack frame), 以此表明需要操作系统提供的服务.
  2. 用户态程序执行陷阱指令
  3. CPU切换到内核态, 并跳到位于内存指定位置的指令, 这些指令是操作系统的一部分, 他们具有内存保护, 不可被用户态程序访问
  4. 这些指令称之为陷阱(trap)或者系统调用处理器(system call handler). 他们会读取程序放入内存的数据参数, 并执行程序请求的服务
  5. 系统调用完成后, 操作系统会重置CPU为用户态并返回系统调用的结果

  当一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态（或简称为内核态）。此时处理器处于特权级最高的（0级）内核代码中执行。当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。每个进程都有自己的内核栈。当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）。即此时处理器在特权级最低的（3级）用户代码中运行。当正在执行用户程序而突然被中断程序中断时，此时用户程序也可以象征性地称为处于进程的内核态。因为中断处理程序将使用当前进程的内核栈。这与处于内核态的进程的状态有些类似。 

  内核态与用户态是操作系统的两种运行级别,跟intel cpu没有必然的联系, intel cpu提供**Ring0-Ring3三种级别的运行模式**，Ring0级别最高，Ring3最低。Linux使用了Ring3级别运行用户态，Ring0作为 内核态，没有使用Ring1和Ring2。Ring3状态不能访问Ring0的地址空间，包括代码和数据。Linux进程的4GB地址空间，3G-4G部 分大家是共享的，是内核态的地址空间，这里存放在整个内核的代码和所有的内核模块，以及内核所维护的数据。用户运行一个程序，该程序所创建的进程开始是运 行在用户态的，如果要执行文件操作，网络数据发送等操作，必须通过write，send等系统调用，这些系统调用会调用内核中的代码来完成操作，这时，必 须切换到Ring0，然后进入3GB-4GB中的内核地址空间去执行这些代码完成操作，完成后，切换回Ring3，回到用户态。这样，用户态的程序就不能 随意操作内核地址空间，具有一定的安全保护作用。
  至于说保护模式，是说通过内存页表操作等机制，保证进程间的地址空间不会互相冲突，一个进程的操作不会修改另一个进程的地址空间中的数据。

   

   

  1. **用户态和内核态的概念区别**

  究竟什么是用户态，什么是内核态，这两个基本概念以前一直理解得不是很清楚，根本原因个人觉得是在于因为大部分时候我们在写程序时关注的重点和着眼的角度放在了实现的功能和**代码**的逻辑性上，先看一个例子：

  ```c++
  void testfork(){
  	if(0 = = fork()){
  		printf(“create new process success!\n”);
  	}
  	printf(“testfork ok\n”);
  }
  
  ```

  这段代码很简单，从功能的角度来看，就是实际执行了一个fork()，生成一个新的进程，从逻辑的角度看，就是判断了如果fork()返回的是0则打印相关语句，然后函数最后再打印一句表示执行完整个testfork()函数。代码的执行逻辑和功能上看就是如此简单，一共四行代码，从上到下一句一句执行而已，完全看不出来哪里有体现出用户态和进程态的概念。

  如果说前面两种是静态观察的角度看的话，我们还可以从动态的角度来看这段代码，即它被转换成CPU执行的指令后加载执行的过程，这时这段程序就是一个动态执行的指令序列。而究竟加载了哪些代码，如何加载就是和操作系统密切相关了。

   

  2）**特权级**

  熟悉Unix/Linux系统的人都知道，**fork的工作实际上是以系统调用的方式完成相应功能的**，具体的工作是由sys_fork负责实施。其实无论是不是Unix或者Linux，对于任何操作系统来说，创建一个新的进程都是属于核心功能，因为它要做很多底层细致地工作，消耗系统的物理资源，比如分配物理内存，从父进程拷贝相关信息，拷贝设置页目录页表等等，这些显然不能随便让哪个程序就能去做，于是就自然引出特权级别的概念，显然，最关键性的权力必须由高特权级的程序来执行，这样才可以做到集中管理，减少有限资源的访问和使用冲突。

  **特权级显然是非常有效的管理和控制程序执行的手段**，因此在硬件上对特权级做了很多支持，就Intel x86架构的CPU来说一共有0~3四个特权级，0级最高，3级最低，硬件上在执行每条指令时都会对指令所具有的特权级做相应的检查，相关的概念有CPL、DPL和RPL，这里不再过多阐述。硬件已经提供了一套特权级使用的相关机制，软件自然就是好好利用的问题，这属于操作系统要做的事情，对于Unix/Linux来说，只使用了0级特权级和3级特权级。也就是说在Unix/Linux系统中，一条工作在0级特权级的指令具有了CPU能提供的最高权力，而一条工作在3级特权级的指令具有CPU提供的最低或者说最基本权力。

   

  3）用户态和内核态

  **现在我们从特权级的调度来理解用户态和内核态就比较好理解了**，当程序运行在3级特权级上时，就可以称之为运行在用户态，因为这是最低特权级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态；反之，当程序运行在0级特权级上时，就可以称之为运行在内核态。

  **虽然用户态下和内核态下工作的程序有很多差别，但最重要的差别就在于特权级的不同，即权力的不同。**运行在用户态下的程序不能直接访问操作系统内核数据结构和程序，比如上面例子中的testfork()就不能直接调用sys_fork()，因为前者是工作在用户态，属于用户态程序，而sys_fork()是工作在内核态，属于内核态程序。

  当我们在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态，比如testfork()最初运行在用户态进程下，当它调用fork()最终触发sys_fork()的执行时，就切换到了内核态。

   

  2. 用户态和内核态的转换

  1）用户态切换到内核态的3种方式

  a. 系统调用

  这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。

  b. 异常

  当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

  c. 外围设备的中断

  当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

   

  这3种方式是系统在运行时由用户态转到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。

   

  2）具体的切换操作

  **从触发方式上看，可以认为存在前述3种不同的类型，但是从最终实际完成由用户态到内核态的切换操作上来说，涉及的关键步骤是完全一致的，没有任何区别，都相当于执行了一个中断响应的过程**，因为系统调用实际上最终是中断机制实现的，而异常和中断的处理机制基本上也是一致的，关于它们的具体区别这里不再赘述。关于中断处理机制的细节和步骤这里也不做过多分析，涉及到由用户态切换到内核态的步骤主要包括：

  [1] 从当前进程的描述符中提取其内核栈的ss0及esp0信息。

  [2] 使用ss0和esp0指向的内核栈将当前进程的cs,eip,eflags,ss,esp信息保存起来，这个

  过程也完成了由用户栈到内核栈的切换过程，同时保存了被暂停执行的程序的下一

  条指令。

  [3] 将先前由中断向量检索得到的中断处理程序的cs,eip信息装入相应的寄存器，开始

  执行中断处理程序，这时就转到了内核态的程序执行了。





## CPU 上下文切换

- 概述

  - Linux 是一个多任务操作系统，它支持远大于 CPU 数量的任务同时运行。当然，这些任务实际上并不是真的在同时运行，而是因为系统在很短的时间内，将 CPU 轮流分配给它们，造成多任务同时运行的错觉。
  - 根据任务的不同，CPU 的上下文切换就可以分为几个不同的场景，也就是进程上下文切换、线程上下文切换以及中断上下文切换。

- CPU 上下文切换

  - 而在每个任务运行前，CPU 都需要知道任务从哪里加载、又从哪里开始运行，也就是说，需要系统事先帮它设置好 CPU 寄存器和程序计数器（Program Counter，PC）
    - CPU 寄存器，是 CPU 内置的容量小、但速度极快的内存
    - 程序计数器，则是用来存储CPU 正在执行的指令位置、或者即将执行的下一条指令位置。
    - 它们都是 CPU 在运行任何任务前，必须的依赖环境，因此也被叫做 CPU 上下文。
  - CPU 上下文切换，就是先把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务

- 进程上下文切换

  - 从用户态到内核态的转变，需要通过系统调用来完成
  - 系统调用的过程有没有发生 CPU 上下文的切换呢
    - CPU 寄存器里原来用户态的指令位置，需要先保存起来。
    - 接着，为了执行内核态代码，CPU 寄存器需要更新为内核态指令的新位置。最后才是跳转到内核态运行内核任务。
    - 而系统调用结束后，CPU 寄存器需要恢复原来保存的用户态，然后再切换到用户空间，继续运行进程。所以，一次系统调用的过程，其实是发生了两次 CPU 上下文切换。
  - 进程上下文切换跟系统调用又有什么区别
    - 进程上下文切换，是指从一个进程切换到另一个进程运行
    - 而系统调用过程中一直是同一个进程在运行。
    - 进程是由内核来管理和调度的，进程的切换只能发生在内核态
    - 进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态。
  - 进程在什么时候才会被调度到 CPU 上运行呢
    - 其一，为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行。
    - 其二，进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行。
    - 其三，当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度。
    - 其四，当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行。
    - 最后一个，发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。

- 线程上下文切换

  - 线程与进程最大的区别在于，线程是调度的基本单位，而进程则是资源拥有的基本单位
    - 说白了，所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源
    - 线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的
  - 线程的上下文切换其实就可以分为两种情况
    - 第一种， 前后两个线程属于不同进程。
    - 第二种，前后两个线程属于同一个进程。

- 中断上下文切换

  - 为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。而在打断其他进程时，就需要将进程当前的状态保存下来，这样在中断结束后，进程仍然可以从原来的状态恢复运行。
  - 跟进程上下文不同，中断上下文切换并不涉及到进程的用户态。
    - 即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。
    - 中断上下文，其实只包括内核态中断服务程序执行所必需的状态，包括 CPU 寄存器、内核堆栈、硬件中断参数等

- 怎么查看系统的上下文切换情况

  - vmstat 是一个常用的系统性能分析工具，主要用来分析系统的内存使用情况，也常用来分析 CPU 上下文切换和中断的次数。

    - r（Running or Runnable）是就绪队列的长度，也就是正在运行和等待 CPU 的进程数。
    - b（Blocked）则是处于不可中断睡眠状态的进程数。
    - in（interrupt）则是每秒中断的次数。
    - cs（context switch）是每秒上下文切换的次数。

  - vmstat 只给出了系统总体的上下文切换情况，要想查看每个进程的详细情况，就需要使用我们前面提到过的 pidstat 了。给它加上 -w 选项，你就可以查看每个进程上下文切换的情况了。

    - cswch ，表示每秒自愿上下文切换（voluntary context switches）的次数
      - 自愿上下文切换，是指进程无法获取所需资源，导致的上下文切换。比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换。
    - nvcswch ，表示每秒非自愿上下文切换（non voluntary context switches）的次数。
      - 非自愿上下文切换，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。比如说，大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换。

  - sysbench 是一个多线程的基准测试工具，一般用来评估不同系统参数下的数据库负载情况。当然，在这次案例中，我们只把它当成一个异常进程来看，作用是模拟上下文切换过多的问题

  - > 以 10 个线程运行 5 分钟的基准测试，模拟多线程切换的问题
    >
    > $ sysbench --threads=10 --max-time=300 threads run

  - 中断只发生在内核态，而 pidstat 只是一个进程的性能分析工具，并不提供任何关于中断的详细信息，怎样才能知道中断发生的类型呢

    - /proc 实际上是 Linux 的一个虚拟文件系统，用于内核空间与用户空间之间的通信。

    - > -d 参数表示高亮显示变化的区域
      > $ watch -d cat /proc/interrupts

    - 变化速度最快的是重调度中断（RES）

      - 这个中断类型表示，唤醒空闲状态的 CPU 来调度新的任务运行。
      - 这是多处理器系统（SMP）中，调度器用来分散任务到不同 CPU 的机制，通常也被称为处理器间中断



## 某个应用的CPU使用率达到100%

- CPU 使用率

  - 单位时间内 CPU 使用情况的统计，以百分比的方式展示

  - Linux 通过 /proc 虚拟文件系统，向用户空间提供了系统内部状态的信息，而 /proc/stat提供的就是系统的 CPU 和任务统计信息

  - 跟系统的指标类似，Linux也给每个进程提供了运行情况的统计信息，也就是 /proc/[pid]/stat。

  - 事实上，为了计算 CPU 使用率，性能工具一般都会取间隔一段时间（比如 3 秒）的两次值，作差后，再计算出这段时间内的平均 CPU 使用率

  - $$
    平均CPU使用率=1-\frac{空闲时间_{new}-空闲时间_{old}}{总CPU时间_{new}-总CPU时间_{old}}
    $$

  - 对比一下 top 和 ps 这两个工具报告的 CPU 使用率，默认的结果很可能不一样，因为 top 默认使用 3 秒时间间隔，而 ps 使用的却是进程的整个生命周期。

  - top命令，每个进程都有一个 %CPU 列，表示进程的CPU 使用率。它是用户态和内核态 CPU 使用率的总和

- pidstat

  - 用户态 CPU 使用率 （%usr）；
  - 内核态 CPU 使用率（%system）；
  - 运行虚拟机 CPU 使用率（%guest）；
  - 等待 CPU 使用率（%wait）；
  - 以及总的 CPU 使用率（%CPU）。

- CPU 使用率过高怎么办

  - 哪种工具适合在第一时间分析进程的 CPU 问题呢？我的推荐是 perf
    - 它以性能事件采样为基础，不仅可以分析系统的各种事件和内核性能，还可以用来分析指定应用程序的性能问题。
  - 第一种常见用法是 perf top，类似于 top，它能够实时显示占用 CPU 时钟最多的函数或者指令，因此可以用来查找热点函数
    - 表格式样的数据
    - 第一列 Overhead ，是该符号的性能事件在所有采样中的比例，用百分比来表示
    - 第二列 Shared ，是该函数或指令所在的动态共享对象（Dynamic Shared Object），如内核、进程名、动态链接库名、内核模块名等。
    - 第三列 Object ，是动态共享对象的类型。比如 [.] 表示用户空间的可执行程序、或者动态链接库，而 [k] 则表示内核空间
    - 最后一列 Symbol 是符号名，也就是函数名。当函数名未知时，用十六进制的地址来表示。
  - 第二种常见用法，也就是 perf record 和 perf report
    - 在实际使用中，我们还经常为 perf top 和 perf record 加上 -g 参数，开启调用关系的采样，方便我们根据调用链来分析性能问题。

  



## 系统的 CPU 使用率很高

- 测试

  - > 并发 100 个请求测试 Nginx 性能，总共测试 1000 个请求
    >
    > 请求时长为 10 分钟（-t 600）                       
    >
    > 2 $ ab -c 100 -n 1000  -t 600 http://192.168.0.10:10000/

- 明明用户 CPU 使用率已经高达 80%，但我却怎么都找不到是哪个进程的问题。

  - 这次从头开始看 top 的每行输出，Tasks 这一行看起来有点奇怪，就绪队列中居然有6 个 Running 状态的进程（6 running），是不是有点多呢？
  - 再仔细看进程列表，这次主要看 Running（R） 状态的进程。你有没有发现， Nginx 和所有的 php-fpm 都处于 Sleep（S）状态，而真正处于 Running（R）状态的，却是几个stress 进程。
  - ps aux | grep 24344  还是没有输出。现在终于发现问题，原来这个进程已经不存在了
  - pstree 就可以用树状形式显示所有进程之间的关系
    - pstree | grep stress
    - 从这里可以看到，stress 是被应用调用的子进程，并且进程数量不止一个（这里是 3个）。找到父进程后，我们能进入 app 的内部分析了。
    - 找到了，果然是 源码中直接调用了 stress 命令。
    - stress 会通过 write() 和 unlink() 对 I/O 进程进行压测，看来，这应该就是系统 CPU 使用率升高的根源了。
  - 是不是真的有大量的 stress 进程。该用什么工具或指标呢？
    - perf ，它可以用来分析 CPU 性能事件

- execsnoop

  - 在这个案例中，我们使用了 top、pidstat、pstree 等工具分析了系统 CPU 使用率高的问题，并发现 CPU 升高是短时进程 stress 导致的，但是整个分析过程还是比较复杂的。
  - execsnoop 就是一个专为短时进程设计的工具。它通过 ftrace 实时监控进程的 exec() 行为，并输出短时进程的基本信息，包括进程 PID、父进程 PID、命令行参数以及执行的结果
  - 用 execsnoop 监控上述案例，就可以直接得到 stress 进程的父进程 PID 以及它的命令行参数，并可以发现大量的 stress 进程在不停启动

- **碰到常规问题无法解释的 CPU 使用率情况时，首先要想到有可能是短时应用导致的问题，比如有可能是下面这两种情况**

  - 第一，应用里直接调用了其他二进制程序，这些程序通常运行时间比较短，通过 top 等工具也不容易发现。
  - 第二，应用本身在不停地崩溃重启，而启动过程的资源初始化，很可能会占用相当多的CPU
  - 对于这类进程，我们可以用 pstree 或者execsnoop 找到它们的父进程，再从父进程所在的应用入手，排查问题的根源。







## 系统中出现大量不可中断进程和僵尸进程

- 当 iowait 升高时，进程很可能因为得不到硬件的响应，而长时间处于不可中断状态。

- R、D、Z、S、I 等几个状态

  - R 是 Running 或 Runnable 的缩写，表示进程在 CPU 的就绪队列中，正在运行或者正在等待运行
  - D 是 Disk Sleep 的缩写，也就是不可中断状态睡眠（Uninterruptible Sleep），一般表示进程正在跟硬件交互，并且交互过程不允许被其他进程或中断打断
  - Z 是 Zombie 的缩写。它表示僵尸进程，也就是进程实际上已经结束了，但是父进程还没有回收它的资源（比如进程的描述符、PID 等）。
    - 这是多进程应用很容易碰到的问题。正常情况下，当一个进程创建了子进程后，它应该通过系统调用 wait() 或者 waitpid() 等待子进程结束，回收子进程的资源；而子进程在结束时，会向它的父进程发送 SIGCHLD 信号，所以，父进程还可以注册SIGCHLD 信号的处理函数，异步回收资源。
    - 如果父进程没这么做，或是子进程执行太快，父进程还没来得及处理子进程状态，子进程就已经提前退出，那这时的子进程就会变成僵尸进程。
  - S 是 Interruptible Sleep 的缩写，也就是可中断状态睡眠，表示进程因为等待某个事件而被系统挂起。当进程等待的事件发生时，它会被唤醒并进入 R 状态。
  - I 是 Idle 的缩写，也就是空闲状态，用在不可中断睡眠的内核线程上。
    - 硬件交互导致的不可中断进程用 D 表示，但对某些内核线程来说，它们有可能实际上并没有任何负载，用 Idle 正是为了区分这种情况。

- iowait 分析

  - dstat ，可以同时查看 CPU 和 I/O 这两种资源的使用情况，便于对比分析。
  - 进程想要访问磁盘，就必须使用系统调用，所以接下来，重点就是找出 app 进程的系统调用了。
    - strace 正是最常用的跟踪进程系统调用的工具
      - 这儿出现了一个奇怪的错误，strace 命令居然失败了，并且命令报出的错误是没有权限
      - 因为进程已经变成了 Z 状态，也就是僵尸进程。
    - 你可以用 perf top 看看有没有新发现
      - 罪魁祸首是进程内部进行了磁盘的直接 I/O

- 僵尸进程

  - 找出父进程，然后在父进程里解决

    - > 1 # -a 表示输出命令行选项
      > 2 # p 表示 PID
      > 3 # s 表示指定进程的父进程
      > 4 $ pstree -aps 3084

- iowait 高不一定代表 I/O 有性能瓶颈。当系统中只有 I/O 类型的进程在运行时，iowait 也会很高，但实际上，磁盘的读写远没有达到性能瓶颈的程度。

  - 因此，碰到 iowait 升高时，需要先用 dstat、pidstat 等工具，确认是不是磁盘 I/O 的问题，然后再找是哪些进程导致了 I/O。
  - 等待 I/O 的进程一般是不可中断状态，所以用 ps 命令找到的 D 状态（即不可中断状态）的进程，多为可疑进程。
  - 这种情况下，我们用了 perf 工具，来分析系统的 CPU 时钟事件，最终发现是直接 I/O 导致的问题。这时，再检查源码中对应位置的问题，就很轻松了。





## 缺页中断

缺页中断（英语：Page fault，又名硬错误、硬中断、分页错误、寻页缺失、缺页中断、页故障等）指的是当软件试图访问已映射在[虚拟](https://baike.baidu.com/item/虚拟)[地址空间](https://baike.baidu.com/item/地址空间)中，但是目前并未被加载在[物理内存](https://baike.baidu.com/item/物理内存)中的一个[分页](https://baike.baidu.com/item/分页)时，由[中央处理器](https://baike.baidu.com/item/中央处理器)的内存管理单元所发出的[中断](https://baike.baidu.com/item/中断)。

通常情况下，用于处理此中断的程序是[操作系统](https://baike.baidu.com/item/操作系统)的一部分。如果操作系统判断此次访问是有效的，那么操作系统会尝试将相关的分页从硬盘上的[虚拟内存](https://baike.baidu.com/item/虚拟内存)文件中调入内存。而如果访问是不被允许的，那么操作系统通常会结束相关的[进程](https://baike.baidu.com/item/进程)。

虽然其名为“页缺失”错误，但实际上这并不一定是一种错误。而且这一机制对于利用[虚拟内存](https://baike.baidu.com/item/虚拟内存)来增加程序可用内存空间的操作系统（比如[Microsoft Windows](https://baike.baidu.com/item/Microsoft Windows)和各种[类Unix系统](https://baike.baidu.com/item/类Unix系统)）中都是常见且有必要的。

**软性**

软性页缺失指页缺失发生时，相关的页已经被加载进内存，但是没有向MMU注册的情况。操作系统只需要在MMU中注册相关页对应的物理地址即可。

发生这种情况的可能性之一，是一块物理内存被两个或多个程序[共享](https://baike.baidu.com/item/共享)，操作系统已经为其中的一个装载并注册了相应的页，但是没有为另一个程序注册。

可能性之二，是该页已被从CPU的[工作集](https://baike.baidu.com/item/工作集)中移除，但是尚未被交换到[磁盘](https://baike.baidu.com/item/磁盘)上。比如[OpenVMS](https://baike.baidu.com/item/OpenVMS)这样的使用次级页缓存的系统，就有可能会在工作集过大的情况下，将某页从工作集中去除，但是不写入硬盘也不擦除（比如说这一页被读出硬盘后没被修改过），只是放入空闲页表。除非有其他程序需要，导致这一页被分配出去了，不然这一页的内容不会被修改。当原程序再次需要该页内的数据时，如果这一页确实没有被分配出去，那么系统只需要重新为该页在MMU内注册映射即可。

 

**硬性**

与软性页缺失相反，硬性页缺失是指相关的页在页缺失发生时未被加载进内存的情况。这时操作系统需要：

1. 寻找到一个空闲的页。或者把另外一个使用中的页写到磁盘上（如果其在最后一次写入后发生了变化的话），并注销在MMU内的记录
2. 将数据读入被选定的页
3. 向MMU注册该页

硬性页缺失导致的性能损失是很大的。以一块7200[rpm](https://baike.baidu.com/item/rpm)的主流[机械硬盘](https://baike.baidu.com/item/机械硬盘)为例，其平均寻道时间为8.5毫秒，读入内存需要0.05毫秒。相对的，[DDR3内存](https://baike.baidu.com/item/DDR3内存)的访问延迟通常在数十到100纳秒之间，性能差距可能会达到8万到22万倍。

另外，有些操作系统会将程序的一部分延迟到需要使用的时候再加载入内存执行，以此来提升性能。这一特性也是通过捕获硬性页缺失达到的。

当硬性页缺失过于频繁的发生时，称发生系统颠簸。



**中断**

是指计算机在执行程序的过程中，当出现异常情况或特殊请求时，计算机停止现行程序的运行，转向对这些异常情况或特殊请求的处理，处理结束后再返回现行程序的间断处，继续执行原程序。

**缺页中断的次数**

中断次数=进程的物理块数×页面置换次数。

**缺页中断的顺序**

缺页中断发生时的事件顺序如下：

1) 硬件陷入内核，在内核[堆栈](https://baike.baidu.com/item/堆栈)中保存[程序计数器](https://baike.baidu.com/item/程序计数器)。大多数机器将当前指令的各种状态信息保存在特殊的CPU[寄存器](https://baike.baidu.com/item/寄存器)中。

2) 启动一个汇编代码例程保存[通用寄存器](https://baike.baidu.com/item/通用寄存器)和其他易失的信息，以免被操作系统破坏。这个例程将操作系统作为一个函数来调用。

3) 当操作系统发现一个缺页中断时，尝试发现需要哪个虚拟页面。通常一个硬件寄存器包含了这一信息，如果没有的话，操作系统必须检索程序计数器，取出这条指令，用软件分析这条指令，看看它在缺页中断时正在做什么。

4) 一旦知道了发生缺页中断的[虚拟地址](https://baike.baidu.com/item/虚拟地址)，操作系统检查这个地址是否有效，并检查存取与保护是否一致。如果不一致，向进程发出一个信号或杀掉该进程。如果地址有效且没有保护错误发生，系统则检查是否有空闲[页框](https://baike.baidu.com/item/页框)。如果没有空闲页框，执行[页面置换算法](https://baike.baidu.com/item/页面置换算法)寻找一个页面来淘汰。

5) 如果选择的页框“脏”了，安排该页写回磁盘，并发生一次[上下文切换](https://baike.baidu.com/item/上下文切换)，挂起产生缺页中断的进程，让其他进程运行直至磁盘传输结束。无论如何，该页框被标记为忙，以免因为其他原因而被其他进程占用。

6) 一旦页框“干净”后（无论是立刻还是在写回磁盘后），操作系统查找所需页面在磁盘上的地址，通过磁盘操作将其装入。该页面被装入后，产生缺页中断的进程仍然被挂起，并且如果有其他可运行的用户进程，则选择另一个用户进程运行。

7) 当磁盘中断发生时，表明该页已经被装入，[页表](https://baike.baidu.com/item/页表)已经更新可以反映它的位置，[页框](https://baike.baidu.com/item/页框)也被标记为正常状态。

8) 恢复发生缺页[中断指令](https://baike.baidu.com/item/中断指令)以前的状态，[程序计数器](https://baike.baidu.com/item/程序计数器)重新指向这条指令。

9) 调度引发缺页中断的进程，操作系统返回调用它的汇编语言例程。

10) 该例程恢复寄存器和其他状态信息 [1] 

### **缺页中断**

　　在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存时，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。 
　　缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤： 

　　1. 保护CPU现场 
　　2. 分析中断原因 
　　3. 转入缺页中断处理程序进行处理 
　　4. 恢复CPU现场，继续执行 
　　但是缺页中断时由于所要访问的页面不存在与内存时，有硬件所产生的一种特殊的中断，因此，与一般的中断存在区别： 
　　 1. 在指令执行期间产生和处理缺页中断信号 
　　 2. 一条指令在执行期间，可能产生多次缺页中断 
　　 3. 缺页中断返回时，执行产生中断的那一条指令，而一般的中断返回时，执行下一条指令





## Linux软中断

- 进程的不可中断状态是系统的一种保护机制，可以保证硬件的交互过程不被意外打断。所以，短时间的不可中断状态是很正常的。

- 软中断

  - 为了解决中断处理程序执行过长和中断丢失的问题，Linux 将中断处理过程分成了两个阶段，也就是上半部和下半部
  - 网卡接收数据包的例子
    - 网卡接收到数据包后，会通过硬件中断的方式，通知内核有新的数据到了。这时，内核就应该调用中断处理程序来响应它。
    - 上半部直接处理硬件请求，也就是我们常说的硬中断，特点是快速执行；
    - 而下半部则是由内核触发，也就是我们常说的软中断，特点是延迟执行。
      - 进程在recv阻塞期间，计算机收到了对端传送的数据（步骤①）。数据经由网卡传送到内存（步骤②），然后网卡通过中断信号通知cpu有数据到达，cpu执行中断程序（步骤③）。此处的中断程序主要有两项功能，先将网络数据写入到对应socket的接收缓冲区里面（步骤④），再唤醒进程A（步骤⑤），重新将进程A放入工作队列中。
      - 其一，操作系统如何知道网络数据对应于哪个socket？
        - 因为一个socket对应着一个端口号，而网络数据包中包含了ip和端口的信息，内核可以通过端口号找到对应的socket。当然，为了提高处理速度，操作系统会维护端口号到socket的索引结构，以快速读取。
      - 其二，如何同时监视多个socket的数据？
        - 多路复用
        - 假如能够预先传入一个socket列表，**如果列表中的socket都没有数据，挂起进程，直到有一个socket收到数据，唤醒进程**。这种方法很直接，也是select的设计思想。
        - **但是简单的方法往往有缺点，主要是：**
          - 其一，每次调用select都需要将进程加入到所有监视socket的等待队列，每次唤醒都需要从每个队列中移除。这里涉及了两次遍历，而且每次都要将整个fds列表传递给内核，有一定的开销。正是因为遍历操作开销大，出于效率的考量，才会规定select的最大监视数量，默认只能监视1024个socket。
          - 其二，进程被唤醒后，程序并不知道哪些socket收到数据，还需要遍历一次。
          - 那么，有没有减少遍历的方法？有没有保存就绪socket的方法？这两个问题便是epoll技术要解决的。
  - 实际上，上半部会打断 CPU 正在执行的任务，然后立即执行中断处理程序。而下半部以内核线程的方式执行，并且每个 CPU 都对应一个软中断内核线程，名字为 “ksoftirqd/CPU编号”，比如说， 0 号 CPU 对应的软中断内核线程的名字就是 ksoftirqd/0。

- 查看软中断和内核线程

  - Linux 中的软中断包括网络收发、定时、调度、RCU 锁等各种类型，可以通过查看/proc/softirqs 来观察软中断的运行情况。

  - > /proc/softirqs 提供了软中断的运行情况；
    > /proc/interrupts 提供了硬中断的运行情况。

  - 每个 CPU 都对应一个软中断内核线程，这个软中断内核线程就叫做 ksoftirqd/CPU 编号

    - > $ ps aux | grep softirq
      > 这些线程的名字外面都有中括号，这说明 ps 无法获取它们的命令行参数。一般来说，ps 的输出中，名字括在中括号里的，一般都是内核线程。





## 系统的软中断CPU使用率升高（SYN泛洪）

- sar、 hping3 和 tcpdump

  - sar 是一个系统活动报告工具，既可以实时查看系统的当前活动，又可以配置保存和报告历史统计数据

    - sar 可以用来查看系统的网络收发情况，还有一个好处是，不仅可以观察网络收发的吞吐量（BPS，每秒收发的字节数），还可以观察网络收发的 PPS，即每秒收发的网络帧数。

    - > 1 # -n DEV 表示显示网络收发的报告，间隔 1 秒输出一组数据
      > 2 $ sar -n DEV 1

  - hping3 是一个可以构造 TCP/IP 协议数据包的工具，可以对系统进行安全审计、防火墙测试等。

    - 运行 hping3 命令，来模拟 Nginx 的客户端请求

    - > 1 # -S 参数表示设置 TCP 协议的 SYN（同步序列号），-p 表示目的端口为 80
      > 2 # -i u100 表示每隔 100 微秒发送一个网络帧
      > 3 # 注：如果你在实践过程中现象不明显，可以尝试把 100 调小，比如调成 10 甚至 1
      > 4 $ hping3 -S -p 80 -i u100 192.168.0.30

  - tcpdump 是一个常用的网络抓包工具，常用来分析各种网络问题。

    - > 1 # -i eth0 只抓取 eth0 网卡，-n 不解析协议名和主机名
      > 2 # tcp port 80 表示只抓取 tcp 协议并且端口号为 80 的网络帧
      > 3 $ tcpdump -i eth0 -n tcp port 80

- $ watch -d cat /proc/softirqs

  - TIMER（定时中断）、NET_RX（网络接收）、NET_TX（网络发送）、SCHED（内核调度）、RCU（RCU 锁）等这几个软中断都在不停变化
  - NET_RX，也就是网络数据包接收软中断的变化速率最快。
  - 而其他几种类型的软中断，是保证 Linux 调度、时钟和临界区保护这些正常工作所必需的，所以它们有一定的变化倒是正常的。

- 到这里，我们已经做了全套的性能诊断和分析。从系统的软中断使用率高这个现象出发，通过观察 /proc/softirqs 文件的变化情况，判断出软中断类型是网络接收中断；再通过 sar和 tcpdump ，确认这是一个 SYN FLOOD 问题。

  - SYN FLOOD 问题最简单的解决方法，就是从交换机或者硬件防火墙中封掉来源 IP，这样SYN FLOOD 网络帧就不会发送到服务器中。





## 如何迅速分析出系统CPU的瓶颈在哪里

- CPU 性能指标
  - 最容易想到的应该是 CPU 使用率
    - CPU 使用率描述了非空闲时间占总 CPU 时间的百分比，根据 CPU 上运行任务的不同，又被分为用户 CPU、系统 CPU、等待 I/O CPU、软中断和硬中断等。
  - 平均负载（Load Average）
  - 进程上下文切换
    - 无法获取资源而导致的自愿上下文切换；
    - 被系统强制调度导致的非自愿上下文切换。
  - 还有一个指标，CPU 缓存的命中率
- 性能工具
  - 平均负载的案例。我们先用 uptime， 查看了系统的平均负载；而在平均负载升高后，又用 mpstat 和 pidstat ，分别观察了每个 CPU 和每个进程 CPU 的使用情况，进而找出了导致平均负载升高的进程，也就是我们的压测工具stress。
  - 第二个，上下文切换的案例。我们先用 vmstat ，查看了系统的上下文切换次数和中断次数；然后通过 pidstat ，观察了进程的自愿上下文切换和非自愿上下文切换情况；最后通过pidstat ，观察了线程的上下文切换情况，找出了上下文切换次数增多的根源，也就是我们的基准测试工具 sysbench。
  - 第三个，进程 CPU 使用率升高的案例。我们先用 top ，查看了系统和进程的 CPU 使用情况，发现 CPU 使用率升高的进程是 php-fpm；再用 perf top ，观察 php-fpm 的调用链，最终找出 CPU 升高的根源，也就是库函数 sqrt() 。
  - 第四个，系统的 CPU 使用率升高的案例。我们先用 top 观察到了系统 CPU 升高，但通过top 和 pidstat ，却找不出高 CPU 使用率的进程。于是，我们重新审视 top 的输出，又从CPU 使用率不高但处于 Running 状态的进程入手，找出了可疑之处，最终通过 perfrecord 和 perf report ，发现原来是短时进程在捣鬼。
  - 第五个，不可中断进程和僵尸进程的案例。我们先用 top 观察到了 iowait 升高的问题，并发现了大量的不可中断进程和僵尸进程；接着我们用 dstat 发现是这是由磁盘读导致的，于是又通过 pidstat 找出了相关的进程。但我们用 strace 查看进程系统调用却失败了，最终还是用 perf 分析进程调用链，才发现根源在于磁盘直接 I/O 。
  - 最后一个，软中断的案例。我们通过 top 观察到，系统的软中断 CPU 使用率升高；接着查看 /proc/softirqs， 找到了几种变化速率较快的软中断；然后通过 sar 命令，发现是网络小包的问题，最后再用 tcpdump ，找出网络帧的类型和来源，确定是一个 SYN FLOOD攻击导致的。
- **性能指标和性能工具**
  - 第一个维度，从 CPU 的性能指标出发。也就是说，当你要查看某个性能指标时，要清楚知道哪些工具可以做到。
    - ![img](https://upload-images.jianshu.io/upload_images/11462765-6d4f67c35d53bf18.png?imageMogr2/auto-orient/strip|imageView2/2/w/640/format/webp)
  - 第二个维度，从工具出发。也就是当你已经安装了某个工具后，要知道这个工具能提供哪些指标。
    - ![img](https://img2020.cnblogs.com/blog/1896874/202008/1896874-20200811153535333-1039704810.png)
  - 为了缩小排查范围，我通常会先运行几个支持指标较多的工具，如 top、vmstat 和pidstat
    - ![img](https://img2020.cnblogs.com/blog/1896874/202008/1896874-20200811160025574-1858608292.png)
  - **第一个例子，pidstat 输出的进程用户 CPU 使用率升高**，会导致 top 输出的用户 CPU 使用率升高。所以，当发现 top 输出的用户 CPU 使用率有问题时，可以跟 pidstat 的输出做对比，观察是否是某个进程导致的问题。
    - 而找出导致性能问题的进程后，就要用进程分析工具来分析进程的行为，比如使用 strace 分析系统调用情况，以及使用 perf 分析调用链中各级函数的执行情况。
  - **第二个例子，top 输出的平均负载升高**，可以跟 vmstat 输出的运行状态和不可中断状态的进程数做对比，观察是哪种进程导致的负载升高。
  - **最后一个例子，当发现 top 输出的软中断 CPU 使用率升高时**，可以查看 /proc/softirqs 文件中各种类型软中断的变化情况，确定到底是哪种软中断出的问题。比如，发现是网络接收中断导致的问题，那就可以继续用网络分析工具 sar 和 tcpdump 来分析。



## **CPU** **性能优化的几个思路**

- **怎么评估性能优化的效果**

  - 应用程序的维度，我们可以用**吞吐量和请求延迟**来评估应用程序的性能。 
  - 系统资源的维度，我们可以用 **CPU 使用率**来评估系统的 CPU 使用情况。 
  - 还是以刚刚的 Web 应用为例，对应上面提到的几个指标，我们可以选择 ab 等工具，测试Web 应用的并发请求数和响应延迟。而测试的同时，还可以用 vmstat、pidstat 等性能工具，观察系统和进程的 CPU 使用率。这样，我们就同时获得了应用程序和系统资源这两个 维度的指标数值。

- **CPU** **优化**

  - **应用程序优化**

    - 比如减少循环的层次、减少递归、减少动态内存分配等等。
    - **编译器优化**
    - **算法优化**
    - **异步处理**
    - **多线程代替多进程**
    - **善用缓存**

  - **系统优化**

    - 从系统的角度来说，优化 CPU 的运行，一方面要充分利用 CPU 缓存的本地性，加速缓存访问；另一方面，就是要控制进程的 CPU 使用情况，减少进程间的相互影响。 
    - **CPU 绑定**：把进程绑定到一个或者多个 CPU 上，可以提高 CPU 缓存的命中率，减少跨 CPU 调度带来的上下文切换问题。 
    - **CPU 独占**：跟 CPU 绑定类似，进一步将 CPU 分组，并通过 CPU 亲和性机制为其分配 进程。这样，这些 CPU 就由指定的进程独占，换句话说，不允许其他进程再来使用这些 CPU。 
    - **优先级调整**：使用 nice 调整进程的优先级，正值调低优先级，负值调高优先级。优先级 的数值含义前面我们提到过，忘了的话及时复习一下。在这里，适当降低非核心应用的优 先级，增高核心应用的优先级，可以确保核心应用得到优先处理。 
    - **为进程设置资源限制**：使用 Linux cgroups 来设置进程的 CPU 使用上限，可以防止由于 某个应用自身的问题，而耗尽系统资源。 
    - **NUMA（Non-Uniform Memory Access）优化**：支持 NUMA 的处理器会被划分为 多个 node，每个 node 都有自己的本地内存空间。NUMA 优化，其实就是让 CPU 尽可能只访问本地内存。 
    - **中断负载均衡**：无论是软中断还是硬中断，它们的中断处理程序都可能会耗费大量的CPU。开启 irqbalance 服务或者配置 smp_affinity，就可以把中断处理过程自动负载均 衡到多个 CPU 上。

    



## Linux 文件系统是怎么工作的

- 概述

  - 磁盘为系统提供了最基本的持久化存储
  - 文件系统则在磁盘的基础上，提供了一个用来管理文件的树状结构

- 索引节点和目录项

  - 为了方便管理，Linux 文件系统为每个文件都分配两个数据结构，索引节点（index node）和目录项（directory entry）。它们主要用来记录文件的元信息和目录结构。
  - 换句话说，索引节点是每个文件的唯一标志，而目录项维护的正是文件系统的树状结构。
    - 索引节点，简称为 inode，用来记录文件的元数据，比如 inode 编号、文件大小、访问权限、修改日期、数据的位置等。索引节点和文件一一对应，它跟文件内容一样，都会被持久化存储到磁盘中。所以记住，索引节点同样占用磁盘空间。
    - 目录项，简称为 dentry，用来记录文件的名字、索引节点指针以及与其他目录项的关联关系。多个关联的目录项，就构成了文件系统的目录结构。不过，不同于索引节点，目录项是由内核维护的一个内存数据结构，所以通常也被叫做目录项缓存。
  - 实际上，磁盘读写的最小单位是扇区，然而扇区只有 512B 大小，如果每次都读写这么小的单位，效率一定很低。所以，文件系统又把连续的扇区组成了逻辑块，然后每次都以逻辑块为最小单元，来管理数据。常见的逻辑块大小为 4KB，也就是由连续的 8 个扇区组成。

- 磁盘在执行文件系统格式化时，会被分成三个存储区域，超级块、索引节点区和数据块区

  - 超级块，存储整个文件系统的状态。
  - 索引节点区，用来存储索引节点。
  - 数据块区，则用来存储文件数据。

- 虚拟文件系统

  - 为了支持各种不同的文件系统，Linux 内核在用户进程和文件系统的中间，又引入了一个抽象层，也就是虚拟文件系统 VFS（Virtual File System）。
    - 用户进程和内核中的其他子系统，只需要跟 VFS 提供的统一接口进行交互就可以了，而不需要再关心底层各种文件系统的实现细节。
  - 这些文件系统，要先挂载到 VFS 目录树中的某个子目录（称为挂载点），然后才能访问其中的文件。
    - 基于磁盘的文件系统为例，在安装系统时，要先挂载一个根目录（/），在根目录下再把其他文件系统（比如其他的磁盘分区、/proc 文件系统、/sys 文件系统、NFS 等）挂载进来。

- 文件系统 I/O

  - 文件读写方式的各种差异，导致 I/O 的分类多种多样。
    - 缓冲 I/O，是指利用标准库缓存来加速文件的访问，而标准库内部再通过系统调度访问文件。
    - 非缓冲 I/O，是指直接通过系统调用来访问文件，不再经过标准库缓存。
    - 无论缓冲 I/O 还是非缓冲 I/O，它们最终还是要经过系统调用来访问文件。我们知道，系统调用后，还会通过页缓存，来减少磁盘的 I/O 操作。
  - 第一种，根据是否利用标准库缓存，可以把文件 I/O 分为缓冲 I/O 与非缓冲 I/O。
  - 第二，根据是否利用操作系统的页缓存，可以把文件 I/O 分为直接 I/O 与非直接 I/O。
    - 直接 I/O，是指跳过操作系统的页缓存，直接跟文件系统交互来访问文件。
    - 非直接 I/O 正好相反，文件读写时，先要经过系统的页缓存，然后再由内核或额外的系统调用，真正写入磁盘
  - 第三，根据应用程序是否阻塞自身运行，可以把文件 I/O 分为阻塞 I/O 和非阻塞 I/O：
  - 第四，根据是否等待响应结果，可以把文件 I/O 分为同步和异步 I/O

- 你也应该可以理解，“Linux 一切皆文件”的深刻含义。无论是普通文件和块设备、还是网络套接字和管道等，它们都通过统一的 VFS 接口来访问。

- 性能观测

  - > 对文件系统来说，最常见的一个问题就是空间不足。用 df 命令，就能查看文件系统的磁盘空间使用情况
    > 	 $ df  -h /dev/sda1

  - 不过有时候，明明你碰到了空间不足的问题，可是用 df 查看磁盘空间后，却发现剩余空间还有很多。这是怎么回事呢？

    - 除了文件数据，索引节点也占用磁盘空间。你可以给 df 命令加上 -i 参数，查看索引节点的使用情况
    - 当你发现索引节点空间不足，但磁盘空间充足时，很可能就是过多小文件导致的。
    - 所以，一般来说，删除这些小文件，或者把它们移动到索引节点充足的其他磁盘中，就可以解决这个问题







## 磁盘I/O

- 通用块层

  - 为了减小不同块设备的差异带来的影响，Linux 通过一个统一的通用块层，来管理各种不同的块设备。
  - 通用块层，其实是处在文件系统和磁盘驱动中间的一个块设备抽象层。它主要有两个功能
    - 向上，为文件系统和应用程序，提供访问块设备的标准接口；向下，把各种异构的磁盘设备抽象为统一的块设备，并提供统一框架来管理这些设备的驱动程序
    - 对 I/O 请求排序的过程，也就是我们熟悉的 I/O 调度

- I/O 栈

  - 我们可以把 Linux 存储系统的 I/O 栈，由上到下分为三个层次，分别是文件系统层、通用块层和设备层

    - 文件系统层，包括虚拟文件系统和其他各种文件系统的具体实现。它为上层的应用程序，提供标准的文件访问接口；对下会通过通用块层，来存储和管理磁盘数据。

    - 通用块层，包括块设备 I/O 队列和 I/O 调度器。它会对文件系统的 I/O 请求进行排队，再通

      过重新排序和请求合并，然后才要发送给下一级的设备层。

    - 设备层，包括存储设备和相应的驱动程序，负责最终物理设备的 I/O 操作。

  - 存储系统的 I/O ，通常是整个系统中最慢的一环。所以， Linux 通过多种缓存机制来优化I/O 效率

    - 比方说，为了优化文件访问的性能，会使用页缓存、索引节点缓存、目录项缓存等多种缓存机制，以减少对下层块设备的直接调用。
    - 同样，为了优化块设备的访问效率，会使用缓冲区，来缓存块设备的数据

- 磁盘性能指标

  - 必须要提到五个常见指标，也就是我们经常用到的，使用率、饱和度、IOPS、吞吐量以及响应时间等。这五个指标，是衡量磁盘性能的基本指标。

    - 使用率，是指磁盘处理 I/O 的时间百分比。过高的使用率（比如超过 80%），通常意味着磁盘 I/O 存在性能瓶颈

      - 这里要注意的是，使用率只考虑有没有 I/O，而不考虑 I/O 的大小。换句话说，当使用率是100% 的时候，磁盘依然有可能接受新的 I/O 请求。

    - 饱和度，是指磁盘处理 I/O 的繁忙程度。过高的饱和度，意味着磁盘存在严重的性

      能瓶颈。当饱和度为 100% 时，磁盘无法接受新的 I/O 请求。

    - IOPS（Input/Output Per Second），是指每秒的 I/O 请求数。

    - 吞吐量，是指每秒的 I/O 请求大小。

    - 响应时间，是指 I/O 请求从发出到收到响应的间隔时间

- 磁盘 I/O 观测

  - iostat 是最常用的磁盘 I/O 性能观测工具，它提供了每个磁盘的使用率、IOPS、吞吐量等各种常见的性能指标，当然，这些指标实际上来自 /proc/diskstats。

  - > 1 # -d -x 表示显示所有磁盘 I/O 的指标
    > 2 $ iostat -d -x 1
    >
    > 
    >
    > %util ，就是我们前面提到的磁盘 I/O 使用率；
    > r/s+ w/s ，就是 IOPS；
    > rkB/s+wkB/s ，就是吞吐量；
    > r_await+w_await ，就是响应时间。

- 进程 I/O 观测

  - 要观察进程的 I/O 情况，你还可以使用 pidstat 和 iotop 这两个工具。

  - > $ pidstat -d 1

  - iotop。它是一个类似于 top 的工具，你可以按照 I/O大小对进程排序，然后找到 I/O 较大的那些进程。





## I/O瓶颈

- 我们可以先用 top ，来观察 CPU 和内存的使用情况；然后再用 iostat ，来观察磁盘的 I/O 情况。

- 观察 top 的输出，CPU0 的使用率非常高，它的系统 CPU 使用率（sys%）为6%，而 iowait 超过了 90%。这说明 CPU0 上，可能正在运行 I/O 密集型的进程

- 看内存的使用情况，总内存 8G，剩余内存只有 730 MB，而 Buffer/Cache 占用内存高达 6GB 之多，这说明内存主要被缓存占用。

- 到这一步，你基本可以判断出，CPU 使用率中的 iowait 是一个潜在瓶颈，而内存部分的缓存占比较大，那磁盘 I/O 又是怎么样的情况呢？

- 使用 pidstat 加上 -d 参数，就可以显示每个进程的 I/O 情况

- lsof

  - 它专门用来查看进程打开文件列表，不过，这里的“文件”不只有普通文件，还包括了目录、块设备、动态库、网络套接字等

  - -p 参数需要指定进程号

    - > -t 表示显示线程，-a 表示显示命令行参数
      >
      > $ pstree -t -a -p [pid]
      >
      > 找到了原因，lsof 的问题就容易解决了。把线程号换成进程号，继续执行 lsof 命令

  - > FD 表示文件描述符号，TYPE 表示文件类型，NAME 表示文件路径
    >
    > python 18940 root 3w REG 8,1 117944320 303 /tmp/logtest.txt
    >
    > 再看最后一行，这说明，这个进程打开了文件 /tmp/logtest.txt，并且它的文件描述符是 3号，而 3 后面的 w ，表示以写的方式打开







## 磁盘I/O延迟很高

- 随便执行一个命令，比如执行 df 命令，查看一下文件系统的使用情况。奇怪的是，这么简单的命令，居然也要等好久才有输出

  - 写文件是由子线程执行的，所以直接strace跟踪进程没有看到write系统调用，可以通过pstree查看进程的线程信息，再用strace跟踪。或者，通过strace -fp pid 跟踪所有线程。
  - 从 strace 中，你可以看到大量的 stat 系统调用，并且大都为 python 的文件，但是，请注意，这里并没有任何 write 系统调用。
  - 我们只好综合 strace、pidstat 和 iostat 这三个结果来分析了。很明显，你应该发现了这里的矛盾：iostat 已经证明磁盘 I/O 有性能瓶颈，而 pidstat 也证明了，这个瓶颈是由12280 号进程导致的，但 strace 跟踪这个进程，却没有找到任何 write 系统调用
  - 文件写，明明应该有相应的 write 系统调用，但用现有工具却找不到痕迹，这时就该想想换工具的问题了。怎样才能知道哪里在写文件呢？

- filetop

  - 它是 bcc 软件包的一部分，主要跟踪内核中文件的读写情况，并输出线程 ID（TID）、读写大小、读写类型以及文件名称。

  - > 1 # 切换到工具目录
    > 2 $ cd /usr/share/bcc/tools 
    > 34 # -C 选项表示输出新内容时不清空屏幕
    > 5 $ ./filetop -C
    >
    > 
    >
    > 多观察一会儿，你就会发现，每隔一段时间，线程号为 514 的 python 应用就会先写入大量的 txt 文件，再大量地读。

- opensnoop 

  - 它同属于 bcc 软件包，可以动态跟踪内核中的open 系统调用。这样，我们就可以找出这些 txt 文件的路径。
  - 这次，通过 opensnoop 的输出，你可以看到，这些 txt 路径位于 /tmp 目录下。你还能看到，它打开的文件数量，按照数字编号，从 0.txt 依次增大到 999.txt，这可远多于前面用filetop 看到的数量
  - 综合 filetop 和 opensnoop ，我们就可以进一步分析了。我们可以大胆猜测，案例应用在写入 1000 个 txt 文件后，又把这些内容读到内存中进行处理。
  - 结合前面的所有分析，我们基本可以判断，案例应用会动态生成一批文件，用来临时存储数据，用完就会删除它们。但不幸的是，正是这些文件读写，引发了 I/O 的性能瓶颈，导致整个处理过程非常慢

  





## SQL慢查询

- top、iostat、pidstat、strace
- lsof
  - 从输出中可以看到， mysqld 进程确实打开了大量文件，而根据文件描述符（FD）的编号，我们知道，描述符为 38 的是一个路径为/var/lib/mysql/test/products.MYD 的文件。这里注意， 38 后面的 u 表示， mysqld 以读写的方式访问文件。
    - MYD 文件，是 MyISAM 引擎用来存储表数据的文件；
    - 文件名就是数据表的名字；
    - 而这个文件的父目录，也就是数据库的名字。
    - 换句话说，这个文件告诉我们，mysqld 在读取数据库 test 中的 products 表。
- 既然已经找出了数据库和表，接下来要做的，就是弄清楚数据库中正在执行什么样的 SQL了







## Redis响应严重延迟

- top、iostat、pidstat、strace
- lsof
  - 结合磁盘写的现象，我们知道，只有 7 号普通文件才会产生磁盘写，而它操作的文件路径是 /data/appendonly.aof，相应的系统调用包括 write 和 fdatasync
  - 这对应着正是 Redis 持久化配置中的 appendonly 和 appendfsync 选项
- 查询 appendonly 和 appendfsync 的配置
  - 从这个结果你可以发现，appendfsync 配置的是 always，而 appendonly 配置的是yes。
  - appendfsync 配置的是 always，意味着每次写数据时，都会调用一次 fsync，从而造成比较大的磁盘 I/O 压力。
- iowait不代表磁盘I/O存在瓶颈，只是代表CPU上I/O操作的时间占用的百分比。假如这时候没有其他进程在运行，那么很小的I/O就会导致iowait升高
- 进程iowait高，磁盘iowait不高，说明是单个进程使用了一些blocking的磁盘打开方式，比如每次都fsync







## 如何分析出系统I/O的瓶颈

- 性能指标
  - ![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8yMTEwNTgwNi05ZGIzYmZmNTgyNmRmNDBmLnBuZw?x-oss-process=image/format,png)
  - **文件系统 I/O 性能指标**
    - 首先，最容易想到的是存储空间的使用情况，包括容量、使用量以及剩余空间等
      - 不过要注意，这些只是文件系统向外展示的空间使用，而非在磁盘空间的真实用量，因为文件系统的元数据也会占用磁盘空间。
      - 而且，如果你配置了 RAID，从文件系统看到的使用量跟实际磁盘的占用空间，也会因为RAID 级别的不同而不一样。比方说，配置RAID10 后，你从文件系统最多也只能看到所有磁盘容量的一半。
      - 除了数据本身的存储空间，还有一个容易忽略的是索引节点的使用情况，它也包括容量、使用量以及剩余量等三个指标。如果文件系统中存储过多的小文件，就可能碰到索引节点容量已满的问题
    - 其次，你应该想到的是前面多次提到过的缓存使用情况，包括页缓存、目录项缓存、索引节点缓存以及各个具体文件系统（如 ext4、XFS 等）的缓存
    - 除了以上这两点，文件 I/O 也是很重要的性能指标，包括 IOPS（包括 r/s 和 w/s）、响应时间（延迟）以及吞吐量（B/s）等
  - **磁盘 I/O 性能指标**
    - 四个核心的磁盘 I/O 指标。
      - **使用率**，是指磁盘忙处理 I/O 请求的百分比。过高的使用率（比如超过 60%）通常意味 着磁盘 I/O 存在性能瓶颈。 
      - **IOPS**（Input/Output Per Second），是指每秒的 I/O 请求数。 
      - **吞吐量**，是指每秒的 I/O 请求大小。
      - **响应时间**，是指从发出 I/O 请求到收到响应的间隔时间。 
    - 考察这些指标时，一定要注意综合 I/O 的具体场景来分析，比如读写类型（顺序还是随机）、读写比例、读写大小、存储类型（有无RAID 以及 RAID 级别、本地存储还是网络存储）等
    - 缓冲区（Buffer）也是要重点掌握的指标，它经常出现在内存和磁盘问题的分析中
- **性能工具**
  - 第一，在文件系统的原理中，我介绍了查看文件系统容量的工具 df。它既可以查看文件系统数据的空间容量，也可以查看索引节点的容量。至于文件系统缓存，我们通过 /proc/meminfo、/proc/slabinfo 以及 slabtop 等各种来源，观察页缓存、目录项缓存、索引节点缓存以及具体文件系统的缓存情况。
  - 第二，在磁盘 I/O 的原理中，我们分别用 iostat 和 pidstat 观察了磁盘和进程的 I/O 情况。它们都是最常用的 I/O 性能分析工具。通过 iostat ，我们可以得到磁盘的 I/O 使用 率、吞吐量、响应时间以及 IOPS 等性能指标；而通过 pidstat ，则可以观察到进程的 I/O吞吐量以及块设备 I/O 的延迟等。 
  - 第三，在狂打日志的案例中，我们先用 top 查看系统的 CPU 使用情况，发现 iowait 比较 高；然后，又用 iostat 发现了磁盘的 I/O 使用率瓶颈，并用 pidstat 找出了大量 I/O 的进程；最后，通过 strace 和 lsof，我们找出了问题进程正在读写的文件，并最终锁定性能问题的来源——原来是进程在狂打日志。 
  - 第四，在磁盘 I/O 延迟的单词热度案例中，我们同样先用 top、iostat ，发现磁盘有 I/O 瓶颈，并用 pidstat 找出了大量 I/O 的进程。可接下来，想要照搬上次操作的我们失败 了。在随后的 strace 命令中，我们居然没看到 write 系统调用。于是，我们换了一个思路，用新工具 filetop 和 opensnoop ，从内核中跟踪系统调用，最终找出瓶颈的来源。 
  - 最后，在 MySQL 和 Redis 的案例中，同样的思路，我们先用 top、iostat 以及 pidstat ， 确定并找出 I/O 性能问题的瓶颈来源，它们正是 mysqld 和 redis-server。随后，我们又用 strace+lsof 找出了它们正在读写的文件。 
  - 关于 MySQL 案例，根据 mysqld 正在读写的文件路径，再结合 MySQL 数据库引擎的原理，我们不仅找出了数据库和数据表的名称，还进一步发现了慢查询的问题，最终通过优化索引解决了性能瓶颈。
  - 至于 Redis 案例，根据 redis-server 读写的文件，以及正在进行网络通信的 TCPSocket，再结合 Redis 的工作原理，我们发现 Redis 持久化选项配置有问题；从 TCP Socket 通信的数据中，我们还发现了客户端的不合理行为。于是，我们修改 Redis 配置选 项，并优化了客户端使用 Redis 的方式，从而减少网络通信次数，解决性能问题

## **磁盘** **I/O** **性能优化的几个思路**

- **I/O** **基准测试**

  - 为了更客观合理地评估优化效果，我们首先应该对磁盘和文件系统进行基准测试，得到文件系统或者磁盘 I/O 的极限性能。 

  - fio（Flexible I/O Tester）正是最常用的文件系统和磁盘 I/O 性能基准测试工具。它提供 了大量的可定制化选项，可以用来测试，裸盘或者文件系统在各种场景下的 I/O 性能，包括了不同块大小、不同 I/O 引擎以及是否使用缓存等场景。

  - fio 的选项非常多， 我会通过几个常见场景的测试方法，介绍一些最常用的选项。这些常见场景包括随机读、随机写、顺序读以及顺序写等，你可以执行下面这些命令来测试：

    ```text
    #随机读
    fio -name=randread -direct=1 -iodepth=64 -rw=randread -ioengine=libaio -bs=4k -size=1G
    #随机写
    fio -name=randwrite -direct=1 -iodepth=64 -rw=randwrite -ioengine=libaio -bs=4k -size=1G
    #顺序读
    fio -name=read -direct=1 -iodepth=64 -rw=read -ioengine=libaio -bs=4k -size=1G -numjobs=
    #顺序写
    fio -name=write -direct=1 -iodepth=64 -rw=write -ioengine=libaio -bs=4k -size=1G -numjob
    ```

    在这其中，有几个参数需要你重点关注一下。

    - direct，表示是否跳过系统缓存。上面示例中，我设置的 1 ，就表示跳过系统缓存。

    - iodepth，表示使用异步 I/O（asynchronous I/O，简称 AIO）时，同时发出的 I/O 请求上限。在上面的示例中，我设置的是 64。

    - rw，表示 I/O 模式。我的示例中， read/write 分别表示顺序读 / 写，而randread/randwrite 则分别表示随机读 / 写。

    - ioengine，表示 I/O 引擎，它支持同步（sync）、异步（libaio）、内存映射（mmap）、网络（net）等各种 I/O 引擎。上面示例中，我设置的 libaio 表示使用异步I/O。

    - bs，表示 I/O 的大小。示例中，我设置成了 4K（这也是默认值）。

    - filename，表示文件路径，当然，它可以是磁盘路径（测试磁盘性能），也可以是文件路径（测试文件系统性能）。示例中，我把它设置成了磁盘 /dev/sdb。不过注意，用磁盘路径测试写，会破坏这个磁盘中的文件系统，所以在使用前，你一定要事先做好数据备份。

    - 这个报告中，需要我们重点关注的是， slat、clat、lat ，以及 bw 和 iops 这几行。

    - 先来看刚刚提到的前三个参数。事实上，slat、clat、lat 都是指 I/O 延迟（latency）。不同之处在于：

      - slat ，是指从 I/O 提交到实际执行 I/O 的时长（Submission latency）；
      - clat ，是指从 I/O 提交到 I/O 完成的时长（Completion latency）；
      - 而 lat ，指的是从 fio 创建 I/O 到 I/O 完成的总时长。

      这里需要注意的是，对同步 I/O 来说，由于 I/O 提交和 I/O 完成是一个动作，所以 slat 实际上就是 I/O 完成的时间，而 clat 是 0。而从示例可以看到，使用异步 I/O（libaio）时，lat 近似等于 slat + clat 之和。

      再来看 bw ，它代表吞吐量。在我上面的示例中，你可以看到，平均吞吐量大约是 16MB（17005 KiB/1024）。

      最后的 iops ，其实就是每秒 I/O 的次数，上面示例中的平均 IOPS 为 4250。

    - 幸运的是，fio 支持 I/O 的重放。借助前面提到过的 blktrace，再配合上 fio，就可以实现对应用程序 I/O 模式的基准测试。你需要先用 blktrace ，记录磁盘设备的 I/O 访问情况；然后使用 fio ，重放 blktrace 的记录。

      比如你可以运行下面的命令来操作：

      ```text
      #使用blktrace跟踪磁盘I/O，注意指定应用程序正在操作的磁盘
      $ blktrace /dev/sdb
      #查看blktrace记录的结果
      # ls
      sdb.blktrace.0  sdb.blktrace.1
      #将结果转化为二进制文件
      $ blkparse sdb -d sdb.bin
      #使用fio重放日志
      $ fio --name=replay --filename=/dev/sdb --direct=1 --read_iolog=sdb.bin
      ```

      这样，我们就通过 blktrace+fio 的组合使用，得到了应用程序 I/O 模式的基准测试报告。

- **I/O性能优化**

  - ![img](https://pic2.zhimg.com/80/v2-659237ee83559f10ff60837d591549fd_720w.jpg)

  - **应用程序优化**

    - 应用程序处于整个 I/O 栈的最上端，它可以通过系统调用，来调整 I/O 模式（如顺序还是随机、同步还是异步）， 同时，它也是 I/O 数据的最终来源。在我看来，可以有这么几种方式来优化应用程序的 I/O 性能。
    - 第一，可以用追加写代替随机写，减少寻址开销，加快 I/O 写的速度。
    - 第二，可以借助缓存 I/O ，充分利用系统缓存，降低实际 I/O 的次数。
    - 第三，可以在应用程序内部构建自己的缓存，或者用 Redis 这类外部缓存系统。这样，一方面，能在应用程序内部，控制缓存的数据和生命周期；另一方面，也能降低其他应用程序使用缓存对自身的影响。
      - 比如，在前面的 MySQL 案例中，我们已经见识过，只是因为一个干扰应用清理了系统缓存，就会导致 MySQL 查询有数百倍的性能差距（0.1s vs 15s）。
      - 再如， C 标准库提供的 fopen、fread 等库函数，都会利用标准库的缓存，减少磁盘的操作。而你直接使用 open、read 等系统调用时，就只能利用操作系统提供的页缓存和缓冲区等，而没有库函数的缓存可用。
    - 第四，在需要频繁读写同一块磁盘空间时，可以用 mmap 代替 read/write，减少内存的拷贝次数。
    - 第五，在需要同步写的场景中，尽量将写请求合并，而不是让每个请求都同步写入磁盘，即可以用 fsync() 取代 O_SYNC。
    - 第六，在多个应用程序共享相同磁盘时，为了保证 I/O 不被某个应用完全占用，推荐你使用 cgroups 的 I/O 子系统，来限制进程 / 进程组的 IOPS 以及吞吐量。
    - 最后，在使用 CFQ 调度器时，可以用 ionice 来调整进程的 I/O 调度优先级，特别是提高核心应用的 I/O 优先级。ionice 支持三个优先级类：Idle、Best-effort 和 Realtime。其中， Best-effort 和 Realtime 还分别支持 0-7 的级别，数值越小，则表示优先级别越高。

  - **文件系统优化**

    - 应用程序访问普通文件时，实际是由文件系统间接负责，文件在磁盘中的读写。所以，跟文件系统中相关的也有很多优化 I/O 性能的方式。
    - 第一，你可以根据实际负载场景的不同，选择最适合的文件系统。比如 Ubuntu 默认使用ext4 文件系统，而 CentOS 7 默认使用 xfs 文件系统。
      - 相比于 ext4 ，xfs 支持更大的磁盘分区和更大的文件数量，如 xfs 支持大于 16TB 的磁盘。但是 xfs 文件系统的缺点在于无法收缩，而 ext4 则可以。
    - 第二，在选好文件系统后，还可以进一步优化文件系统的配置选项，包括文件系统的特性（如 ext_attr、dir_index）、日志模式（如 journal、ordered、writeback）、挂载选项（如 noatime）等等。
      - 比如，使用 tune2fs 这个工具，可以调整文件系统的特性（tune2fs 也常用来查看文件系统超级块的内容）。 而通过 /etc/fstab ，或者 mount 命令行参数，我们可以调整文件系统的日志模式和挂载选项等。
    - 第三，可以优化文件系统的缓存。
      - 比如，你可以优化 pdflush 脏页的刷新频率（比如设置 dirty_expire_centisecs 和dirty_writeback_centisecs）以及脏页的限额（比如调整 dirty_background_ratio 和dirty_ratio 等）
      - 再如，你还可以优化内核回收目录项缓存和索引节点缓存的倾向，即调整vfs_cache_pressure（/proc/sys/vm/vfs_cache_pressure，默认值 100），数值越大，就表示越容易回收。
    - 最后，在不需要持久化时，你还可以用内存文件系统tmpfs，以获得更好的 I/O 性能 。tmpfs 把数据直接保存在内存中，而不是磁盘中。比如 /dev/shm/ ，就是大多数 Linux 默认配置的一个内存文件系统，它的大小默认为总内存的一半。

  - **磁盘优化**

    - 第一，最简单有效的优化方法，就是换用**性能更好的磁盘**，比如用 SSD 替代 HDD。

    - 第二，我们可以使用 **RAID** ，把多块磁盘组合成一个逻辑磁盘，构成冗余独立磁盘阵列。这样做既可以提高数据的可靠性，又可以提升数据的访问性能。

    - 第三，针对磁盘和应用程序 I/O 模式的特征，我们可以选择最适合的 **I/O 调度算法**。比方说，SSD 和虚拟机中的磁盘，通常用的是 noop 调度算法。而数据库应用，我更推荐使用deadline 算法。

    - 第四，我们可以对应用程序的数据，进行**磁盘级别的隔离**。比如，我们可以为日志、数据库等 I/O 压力比较重的应用，配置单独的磁盘。

    - 第五，**在顺序读比较多的场景中，我们可以增大磁盘的预读数据**，比如，你可以通过下面两种方法，调整 /dev/sdb 的预读大小。

      > 调整内核选项 /sys/block/sdb/queue/read_ahead_kb，默认大小是 128 KB，单位为KB。 使用 blockdev 工具设置，比如 blockdev --setra 8192 /dev/sdb，注意这里的单位是512B（0.5KB），所以它的数值总是 read_ahead_kb 的两倍。

    - 第六，我们可以**优化内核块设备 I/O 的选项**。比如，可以调整磁盘队列的长度/sys/block/sdb/queue/nr_requests，适当增大队列长度，可以提升磁盘的吞吐量（当然也会导致 I/O 延迟增大）。

    - 最后，要注意，**磁盘本身出现硬件错误**，也会导致 I/O 性能急剧下降，所以发现磁盘性能急剧下降时，你还需要确认，磁盘本身是不是出现了硬件错误。

      - 比如，你可以查看 dmesg 中是否有硬件 I/O 故障的日志。还可以使用 badblocks、smartctl 等工具，检测磁盘的硬件问题，或用 e2fsck 等来检测文件系统的错误。如果发现问题，你可以使用 fsck 等工具来修复。

    


