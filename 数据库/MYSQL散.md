



## distinct 和 group by 的性能

- 如果表 t 的字段 a 上没有索引，那么下面这两条语句：

  - > 1 select a from t group by a order by null;
    > 2 select distinct a from t;

  - 没有了 count(*) 以后，也就是不再需要执行“计算总数”的逻辑时，第一条语句的逻辑就变成是：按照字段 a 做分组，相同的 a 的值只返回一行。而这就是 distinct 的语义，所以不需要执行聚合函数时，distinct 和 group by 这两条语句的语义和执行流程是相同的，因此执行性能也相同。

- 这两条语句的执行流程是下面这样的

  - 创建一个临时表，临时表有一个字段 a，并且在这个字段 a 上创建一个唯一索引；
  - 遍历表 t，依次取数据插入临时表中：
    - 如果发现唯一键冲突，就跳过；
    - 否则插入成功
  - 遍历完成后，将临时表作为结果集返回给客户端。



## 

## count(*)

- 为什么 InnoDB 不跟 MyISAM 一样，也把数字存起来呢？

  - 由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的
    - 这和 InnoDB 的事务设计有关系，可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制
    - 每一行记录都要判断自己是否对这个会话可见，因此对于 count(*) 请求来说，InnoDB 只好把数据一行一行地读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。
  - 在执行 count(*) 操作的时候还是做了优化的。
    - InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。
    - 对于 count(*) 这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。

- 不同的 count 用法

  - count(1) 执行得要比 count(主键 id) 快。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。
    - 对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。
    - 对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。
  - 对于 count(字段) 来说
    - 如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；
    - 如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。
  - 按照效率排序的话，count(字段)<count(主键 id)<count(1)≈count(\*)，所以我建议你，尽量使用 count(*)。

- 从并发系统性能的角度考虑，在一个事务中应该先插入操作记录，再更新计数表。

  - 因为更新计数表涉及到行锁的竞争，先插入再更新能最大程度地减少了事务之间的锁等待，提升了并发度。

  





## order by

- 全字段排序

  - select city,name,age from t where city='杭州' order by name limit 1000 ;

  - > 1. 初始化 sort_buffer，确定放入 name、city、age 这三个字段；
    > 2. 从索引 city 找到第一个满足 city='杭州’条件的主键 id；
    > 3. 到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；
    > 4. 从索引 city 取下一个记录的主键 id；
    > 5. 重复步骤 3、4 直到 city 的值不满足查询条件为止，；
    > 6. 对 sort_buffer 中的数据按照字段 name 做快速排序；
    > 7. 按照排序结果取前 1000 行返回给客户端。

  - 按 name 排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。

  - sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。

- rowid 排序

  - SET max_length_for_sort_data=16;

    - max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。

  - 新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。

    - > 1. 初始化 sort_buffer，确定放入两个字段，即 name 和 id；
      > 2. 从索引 city 找到第一个满足 city='杭州’条件的主键 id；
      > 3. 到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中；
      > 4. 从索引 city 取下一个记录的主键 id；
      > 5. 重复步骤 3、4 直到不满足 city='杭州’条件为止；
      > 6. 对 sort_buffer 中的数据按照字段 name 进行排序；
      > 7. 遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。

  - rowid 排序多访问了一次表 t 的主键索引，就是步骤 7。

- 全字段排序 VS rowid 排序

  - 体现了 MySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。

  - 对于 InnoDB 表来说，rowid 排序会要求回表多造成磁盘读，因此不会被优先选择

  - MySQL 之所以需要生成临时表，并且在临时表上做排序操作，其原因是原来的数据都是无序的。

    - > 我们可以在这个市民表上创建一个 city 和 name 的联合索引，对应的 SQL 语句是：
      > 	alter table t add index city_user(city, name);
      >
      > 
      >
      > 1. 从索引 (city,name) 找到第一个满足 city='杭州’条件的主键 id；
      > 2. 到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回；
      > 3. 从索引 (city,name) 取下一个记录主键 id；
      > 4. 重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city='杭州’条件时循环结束。

  - 这个语句的执行流程有没有可能进一步简化呢

    - > 按照覆盖索引的概念，我们可以再优化一下这个查询语句的执行流程
      >
      > 针对这个查询，我们可以创建一个 city、name 和 age 的联合索引，对应的 SQL 语句就是：
      > 	alter table t add index city_user_age(city, name, age)
      >
      > 
      >
      > 1. 从索引 (city,name,age) 找到第一个满足 city='杭州’条件的记录，取出其中的 city、name 和 age 这三个字段的值，作为结果集的一部分直接返回；
      > 2. 从索引 (city,name,age) 取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回；
      > 3. 重复执行步骤 2，直到查到第 1000 条记录，或者是不满足 city='杭州’条件时循环结束

- mysql> select * from t where city in ('杭州'," 苏州 ") order by name limit 100;这个语句执行的时候会有排序过程吗，为什么？

  - 虽然有 (city,name) 联合索引，对于单个 city 内部，name 是递增的
  - 由于这条 SQL语句不是要单独地查一个 city 的值，而是同时查了"杭州"和" 苏州 "两个城市，因此所有满足条件的 name 就不是递增的了。也就是说，这条 SQL 语句需要排序。
  - 要用到 (city,name) 联合索引的特性，把这一条语句拆成两条语句







## join 的写法

- ![img](https://images2017.cnblogs.com/blog/1035967/201709/1035967-20170907174926054-907920122.jpg)

- 笛卡尔积：CROSS JOIN

  要理解各种JOIN首先要理解笛卡尔积。笛卡尔积就是将A表的每一条记录与B表的每一条记录强行拼在一起。所以，如果A表有n条记录，B表有m条记录，笛卡尔积产生的结果就会产生n*m条记录。下面的例子，t_blog有10条记录，t_type有5条记录，所有他们俩的笛卡尔积有50条记录。

- 内连接：INNER JOIN

  内连接INNER JOIN是最常用的连接操作。从数学的角度讲就是求两个表的交集，从笛卡尔积的角度讲就是从笛卡尔积中挑出ON子句条件成立的记录。有INNER JOIN，WHERE（等值连接），STRAIGHT_JOIN,JOIN(省略INNER)四种写法。

- 左连接：LEFT JOIN

  左连接LEFT JOIN的含义就是求两个表的交集外加左表剩下的数据。依旧从笛卡尔积的角度讲，就是先从笛卡尔积中挑出ON子句条件成立的记录，然后加上左表中剩余的记录（见最后三条）。

- 右连接：RIGHT JOIN

  同理右连接RIGHT JOIN就是求两个表的交集外加右表剩下的数据。再次从笛卡尔积的角度描述，右连接就是从笛卡尔积中挑出ON子句条件成立的记录，然后加上右表中剩余的记录

- 外连接：OUTER JOIN

  外连接就是求两个集合的并集。从笛卡尔积的角度讲就是从笛卡尔积中挑出ON子句条件成立的记录，然后加上左表中剩余的记录，最后加上右表中剩余的记录。另外MySQL不支持OUTER JOIN，但是我们可以对左连接和右连接的结果做UNION操作来实现。

- 构造两个表 a 和 b：

  - > 1 create table a(f1 int, f2 int, index(f1))engine=innodb;
    > 2 create table b(f1 int, f2 int)engine=innodb;
    > 3 insert into a values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6);
    > 4 insert into b values(3,3),(4,4),(5,5),(6,6),(7,7),(8,8);
    >
    > 
    >
    > 1 select * from a left join b on(a.f1=b.f1) and (a.f2=b.f2); /*Q1*/
    > 2 select * from a left join b on(a.f1=b.f1) where (a.f2=b.f2);/*Q2*/
    >
    > 
    >
    > 语句 Q1 返回的数据集是 6 行，表 a 中即使没有满足匹配条件的记录，查询结果中也会返回一行，并将表 b 的各个字段值填成 NULL。
    >
    > 语句 Q2 返回的是 4 行。从逻辑上可以这么理解，最后的两行，由于表 b 中没有匹配的字段，结果集里面 b.f2 的值是空，不满足 where 部分的条件判断，因此不能作为结果集的一部分。

  - Q1 的 explain 结果

    - 驱动表是表 a，被驱动表是表 b；
    - 由于表 b 的 f1 字段上没有索引，所以使用的是 Block Nexted Loop Join（简称 BNL）算法。

  - Q2 的 expain 结果

    - 以表 b 为驱动表的。而如果一条 join 语句的 Extra 字段什么都没写的话，就表示使用的是 Index Nested-Loop Join（简称 NLJ）算法。
    - 执行流程是这样的：顺序扫描表 b，每一行用 b.f1 到表 a 中去查，匹配到记录后判断 a.f2=b.f2 是否满足，满足条件的话就作为结果集的一部分返回。

  - 在 MySQL 里，NULL 跟任何值执行等值判断和不等值判断的结果，都是 NULL。这里包括， select NULL = NULL 的结果，也是返回 NULL

    - 语句 Q2 里面 where a.f2=b.f2 就表示，查询结果里面不会包含 b.f2 是 NULL 的行，这样这个 left join 的语义就是“找到这两个表里面，f1、f2 对应相同的行。对于表 a中存在，而表 b 中匹配不到的行，就放弃”。这样，这条语句虽然用的是 left join，但是语义跟 join 是一致的。
    - 优化器就把这条语句的 left join 改写成了 join，然后因为表 a 的 f1 上有索引，就把表 b 作为驱动表，这样就可以用上 NLJ 算法。在执行 explain 之后，你再执行 show warnings，就能看到这个改写的结果

  - 如果需要 left join 的语义，就不能把被驱动表的字段放在 where 条件里面做等值判断或不等值判断，必须都写在 on 里面。

  - join 将判断条件是否全部放在 on 部分就没有区别了。





## join

- 如果有两个大小不同的表做 join，应该用哪个表做驱动表呢？

  - t2 里插入了 1000 行数据，在 t1 里插入的是 100 行数据。
  - 两个表都有一个主键索引 id 和一个索引 a，字段 b 上无索引

- Index Nested-Loop Join

  - > select * from t1 straight_join t2 on (t1.a=t2.a);
    >
    > 对驱动表 t1 做了全表扫描，扫描 100 行
    > 对于每一行 R，根据 a 字段去表 t2 查找，走的是树搜索过程。构造的数据都是一一对应的，因此每次的搜索过程都只扫描一行，也是总共扫描 100 行；
    > 整个执行流程，总扫描行数是 200。

  - 怎么选择驱动表

    - 在这个 join 语句执行过程中，驱动表是走全表扫描，而被驱动表是走树搜索。

- Simple Nested-Loop Join

  - > select * from t1 straight_join t2 on (t1.a=t2.b);
    > 由于表 t2 的字段 b 上没有索引，因此每次到 t2 去匹配的时候，就要做一次全表扫描。

- Block Nested-Loop Join

  - 这时候，被驱动表上没有可用的索引，算法的流程是这样的

    - 把表 t1 的数据读入线程内存 join_buffer 中，由于我们这个语句中写的是 select *，因此是把整个表 t1 放入了内存；
    - 扫描表 t2，把表 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回。

  - 在这个过程中，对表 t1 和 t2 都做了一次全表扫描，因此总的扫描行数是1100。由于 join_buffer 是以无序数组的方式组织的，因此对表 t2 中的每一行，都要做100 次判断，总共需要在内存中做的判断次数是：100*1000=10 万次。

    - 如果使用 Simple Nested-Loop Join 算法进行查询，扫描行数也是 10 万行。因此，从时间复杂度上来说，这两个算法是一样的。但是，Block Nested-Loop Join算法的这 10 万次判断是内存操作，速度上会快很多，性能也更好。

  - join_buffer 的大小是由参数 join_buffer_size 设定的，默认值是 256k。如果放不下表 t1的所有数据话，策略很简单，就是分段放

    - > 扫描表 t1，顺序读取数据行放入 join_buffer 中，join_buffer 满了，继续第 2 步；
      > 扫描表 t2，把 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分
      > 清空 join_buffer；
      > 继续扫描表 t1，顺序读取最后的 12 行数据放入 join_buffer 中，继续执行第 2 步。
      > 这个流程才体现出了这个算法名字中“Block”的由来，表示“分块去 join”







## join语句优化

- Multi-Range Read 优化

  - Multi-RangeRead 优化 (MRR)。这个优化的主要目的是尽量使用顺序读盘。

  - 回表过程是一行行地查数据，还是批量地查数据？

    - 主键索引是一棵 B+ 树，在这棵树上，每次只能根据一个主键 id 查到一行数据。因此，回表肯定是一行行搜索主键索引的
    - 如果随着 a 的值递增顺序查询的话，id 的值就变成随机的，那么就会出现随机访问，性能相对较差。虽然“按行查”这个机制不能改，但是调整查询的顺序，还是能够加速的
    - 我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能
    - 这，就是 MRR 优化的设计思路

  - 执行流程

    - > 根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中 ;
      > 将 read_rnd_buffer 中的 id 进行递增排序；
      > 排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。

- BNL 算法的性能问题

  - BNL 算法对系统的影响主要包括三个方面
    - 可能会多次扫描被驱动表，占用磁盘 IO 资源；
    - 判断 join 条件需要执行 M*N 次对比（M、N 分别是两张表的行数），如果是大表就会占用非常多的 CPU 资源；
    - 可能会导致 Buffer Pool 的热数据被淘汰，影响内存命中率。
      - 如果一个使用 BNL 算法的 join 语句，多次扫描一个冷表，而且这个语句执行时间超过 1 秒，就会在再次扫描冷表的时候，把冷表的数据页移到 LRU 链表头部。
        - 这种情况对应的，是冷表的数据量小于整个 Buffer Pool 的 3/8，能够完全放入 old 区域的情况。
      - 如果这个冷表很大，就会出现另外一种情况：业务正常访问的数据页，没有机会进入young 区域。
        - 由于我们的 join 语句在循环读磁盘和淘汰内存页，进入 old 区域的数据页，很可能在 1 秒之内就被淘汰了。这样，就会导致这个 MySQL 实例的 Buffer Pool 在这段时间内，young 区域的数据页没有被合理地淘汰。
  - 如果确认优化器会使用 BNL 算法，就需要做优化。优化的常见做法是，给被驱动表的 join 字段加上索引，把 BNL 算法转成 BKA 算法。

- Batched Key Access

  - MySQL 在 5.6 版本后开始引入的 BatchedKey Access(BKA) 算法了。这个 BKA 算法，其实就是对 NLJ 算法的优化。

  - 把表 t1 的数据取出来一部分，先放到一个临时内存。这个临时内存就是 join_buffer。

  - > 如果要使用 BKA 优化算法的话，你需要在执行 SQL 语句之前，先设置
    > 	set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';
    > 	其中，前两个参数的作用是要启用 MRR。这么做的原因是，BKA 算法的优化要依赖于MRR。

- BNL 转 BKA

  - 一些情况下，我们可以直接在被驱动表上建索引，这时就可以直接转成 BKA 算法了

    - 有时候你确实会碰到一些不适合在被驱动表上建索引的情况

  - > 考虑使用临时表。使用临时表的大致思路是：
    > 	把表 t2 中满足条件的数据放在临时表 tmp_t 中；
    > 	为了让 join 使用 BKA 算法，给临时表 tmp_t 的字段 b 加上索引；
    > 	让表 t1 和 tmp_t 做 join 操作。

  - 不论是在原表上加索引，还是用有索引的临时表，我们的思路都是让 join 语句能够用上被驱动表上的索引，来触发 BKA 算法，提升查询性能。

  - 使用 BKA 算法的时候，并不是“先计算两个表 join 的结果，再跟第三个表 join”，而是直接嵌套查询的。





## InnoDB、Memory

- InnoDB 和 Memory 引擎的数据组织方式是不同的

  - InnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，我们称之为索引组织表（Index Organizied Table）。
  - 而 Memory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为堆组织表（Heap Organizied Table）。

- 这两个引擎的一些典型不同

  - InnoDB 表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的；
  - 当数据文件有空洞的时候，InnoDB 表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值；
  - 数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引；
  - InnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。
  - InnoDB 支持变长数据类型，不同记录的长度可能不同；内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。
  - 由于内存表的这些特性，每个数据行被删除以后，空出的这个位置都可以被接下来要插入的数据复用

- 为什么我不建议你在生产环境上使用内存表。这里的原因主要包括两个方面：

  - 锁粒度问题
    - 内存表不支持行锁，只支持表锁
  - 数据持久化问题
    - 数据库重启的时候，所有的内存表都会被清空。
    - 在高可用架构下，内存表的这个特点简直可以当做 bug 来看待了。


## **InnoDB和MyISAM**

**应用场景：**
1).MyISAM管理非事务表。它提供高速存储和检索，以及全文搜索能力。如果应用中需要执行大量的SELECT查询，那么MyISAM是更好的选择。

2).InnoDB用于事务处理应用程序，具有众多特性，包括ACID事务支持。如果应用中需要执行大量的INSERT或UPDATE操作，则应该使用InnoDB，这样可以提高多用户并发操作的性能。

**主要区别：**
1).MyISAM是非事务安全型的，而InnoDB是事务安全型的。
2).MyISAM锁的粒度是表级，而InnoDB支持行级锁定。
3).MyISAM支持全文类型索引，而InnoDB不支持全文索引。
4).MyISAM相对简单，所以在效率上要优于InnoDB，小型应用可以考虑使用MyISAM。
5).MyISAM表是保存成文件的形式，在跨平台的数据转移中使用MyISAM存储会省去不少的麻烦。
6).InnoDB表比MyISAM表更安全，可以在保证数据不会丢失的情况下，切换非事务表到事务表（alter table tablename type=innodb）。



## InnoDB

- InnoDB 主要包括了内存池、后台线程以及存储文件
  - 内存池又是由多个内存块组成的，主要包括缓存磁盘数据、redo log 缓冲等
  - 后台线程则包括了 Master Thread、IO Thread的Purge Thread 等
  - 由 InnoDB 存储引擎实现的表的存储结构文件一般包括表结构文件（.frm）、共享表空间文件（ibdata1）、独占表空间文件（ibd）以及日志文件（redo文件等）等。
- innoDB 逻辑存储结构
  - 分为表空间（Tablespace）、段 (Segment)、区 (Extent)、页(Page) 以及行 (row)。
    - InnoDB 提供了两种表空间存储数据的方式，一种是共享表空间，一种是独占表空间
    - 表空间是由各个段组成的，段一般分为数据段、索引段和回滚段等
    - 这里的索引段则是指的 B + 树的非叶子节点，而数据段则是 B + 树的叶子节点
    - MVCC 利用了回滚段实现了多版本查询数据。
    - 区是表空间的单元结构，每个区的大小为 1MB。而页是组成区的最小单元，页也是InnoDB 存储引擎磁盘管理的最小单元，每个页的大小默认为 16KB。为了保证页的连续性，InnoDB 存储引擎每次从磁盘申请 4-5 个区。
    - InnoDB 存储引擎是面向列的（row-oriented)，也就是说数据是按行进行存放的









## insert语句

- 主键索引，唯一索引这两类索引冲突加的都是 next-key lock。
- insert … select 是很常见的在两个表之间拷贝数据的方法。你需要注意，在可重复读隔离级别下，这个语句会给 select 的表里扫描到的记录和间隙加读锁
- 如果 insert 和 select 的对象是同一个表，则有可能会造成循环写入。这种情况下，我们需要引入用户临时表来做优化。
  - 这类一边遍历数据，一边更新数据的情况，如果读出来的数据直接写回原表，就可能在遍历过程中，读到刚刚插入的记录，新插入的记录如果参与计算逻辑，就跟语义不符。
- insert 语句如果出现唯一键冲突，会在冲突的唯一值上加共享的读锁。因此，碰到由于唯一键约束导致报错后，要尽快提交或回滚事务，避免加锁时间过长。
  - insert into … on duplicate key update 这个语义的逻辑是，插入一行数据，如果碰到唯一键约束，就执行后面的更新语句。
- 关于数据拷贝大表我建议采用pt-archiver,这个工具能自动控制频率和速度











## 执行计划explain

- explain + 查询SQL - 用于显示SQL执行信息参数，根据参考信息可以进行SQL优化

- **select_type：**SELECT类型。

  1. SIMPLE： 简单SELECT(不使用UNION或子查询)
  2. PRIMARY： 最外面的SELECT
  3. UNION：UNION中的第二个或后面的SELECT语句
  4. DEPENDENT UNION：UNION中的第二个或后面的SELECT语句，取决于外面的查询
  5. UNION RESULT：UNION的结果
  6. SUBQUERY：子查询中的第一个SELECT
  7. DEPENDENT SUBQUERY：子查询中的第一个SELECT，取决于外面的查询
  8. DERIVED：导出表的SELECT(FROM子句的子查询)

- type

  - 查询时的访问方式，性能：all < index < range < index_merge < ref_or_null < ref < eq_ref < systemconst

  - ```sql
        ALL             全表扫描，对于数据表从头到尾找一遍
                        select * from tb1;
                        特别的：如果有limit限制，则找到之后就不在继续向下扫描
                               select * from tb1 where email = 'seven@live.com'
                               select * from tb1 where email = 'seven@live.com' limit 1;
                               虽然上述两个语句都会进行全表扫描，第二句使用了limit，则找到一个后就不再继续扫描。
    
        INDEX           全索引扫描，对索引从头到尾找一遍
                        select nid from tb1;
    
        RANGE          对索引列进行范围查找
                        select *  from tb1 where name < 'alex';
                        PS:
                            between and
                            in
                            >   >=  <   <=  操作
                            注意：!= 和 \> 符号
    
        INDEX_MERGE     合并索引，使用多个单列索引搜索
                        select *  from tb1 where name = 'alex' or nid in (11,22,33);
    
        REF             根据索引查找一个或多个值
                        select *  from tb1 where name = 'seven';
    
        EQ_REF          连接时使用primary key 或 unique类型
                        select tb2.nid,tb1.name from tb2 left join tb1 on tb2.nid = tb1.nid;
    
        CONST           常量
                        表最多有一个匹配行,因为仅有一行,在这行的列值可被优化器剩余部分认为是常数,const表很快,因为它们只读取一次。
                        select nid from tb1 where nid = 2 ;
    
        SYSTEM          系统
                        表仅有一行(=系统表)。这是const联接类型的一个特例。
                        select * from (select nid from tb1 where nid = 1) as A;
    ```

- **Extra：**该列包含MySQL解决查询的详细信息。

  1. Distinct：MySQL发现第1个匹配行后，停止为当前的行组合搜索更多的行。
  2. Not exists：MySQL能够对查询进行LEFT JOIN优化，发现1个匹配LEFT JOIN标准的行后，不再为前面的的行组合在该表内检查更多的行。
  3. range checked for each record (index map: #)：MySQL没有发现好的可以使用的索引，但发现如果来自前面的表的列值已知，可能部分索引可以使用。对前面的表的每个行组合，MySQL检查是否可以使用range或index_merge访问方法来索取行。
  4. Using filesort：MySQL需要额外的一次传递，以找出如何按排序顺序检索行。通过根据联接类型浏览所有行并为所有匹配WHERE子句的行保存排序关键字和行的指针来完成排序。然后关键字被排序，并按排序顺序检索行。
  5. Using index：从只使用索引树中的信息而不需要进一步搜索读取实际的行来检索表中的列信息。当查询只使用作为单一索引一部分的列时，可以使用该策略。
  6. Using temporary：为了解决查询，MySQL需要创建一个临时表来容纳结果。典型情况如查询包含可以按不同情况列出列的GROUP BY和ORDER BY子句时。
  7. Using where：WHERE子句用于限制哪一个行匹配下一个表或发送到客户。除非你专门从表中索取或检查所有行，如果Extra值不为Using where并且表联接类型为ALL或index，查询可能会有一些错误。
  8. Using sort_union(...), Using union(...), Using intersect(...)：这些函数说明如何为index_merge联接类型合并索引扫描。
  9. Using index for group-by：类似于访问表的Using index方式，Using index for group-by表示MySQL发现了一个索引，可以用来查询GROUP BY或DISTINCT查询的所有列，而不要额外搜索硬盘访问实际的表。并且，按最有效的方式使用索引，以便对于每个组，只读取少量索引条目。



## MySQL语句执行顺序

- 写的顺序：select ... from... where.... group by... having... order by.. limit [offset,] 
- 顺序
  - from
  - on
  - join
  - where
  - group by
  - having
  - select
  - distinct
  - order by
  - limit



## 数据表中的键

- 超键：能唯一标识元组的属性集叫做超键。 

- 候选键：如果超键不包括多余的属性，那么这个超键就是候选键。 

- 主键：用户可以从候选键中选择一个作为主键。 

- 外键：如果数据表 R1 中的某属性集不是 R1 的主键，而是另一个数据表 R2 的主键，那么这个属性集就是数据表 R1 的外键。 

- 主属性：包含在任一候选键中的属性称为主属性。 

- 非主属性：与主属性相对，指的是不包含在任何一个候选键中的属性。

- 把的球员表（player）定义为包含球员编号、姓名、身份证号、年龄和球队编号；球队表（team）包含球队编号、主教练和球队所在地。 

  - 对于球员表来说，超键就是包括球员编号或者身份证号的任意组合，比如（球员编号）（球 

    员编号，姓名）（身份证号，年龄）等。 

  - 候选键就是最小的超键，对于球员表来说，候选键就是（球员编号）或者（身份证号）。 

  - 主键是我们自己选定，也就是从候选键中选择一个，比如（球员编号）。 

  - 在 player 表中，主属性是（球员编号）（身份证号），其他的属性（姓名）（年龄）（球 

    队编号）都是非主属性。





## 从 1NF 到 3NF

- **1NF 指的是数据库表中的任何属性都是原子性的，不可再分**

  - 我们在设计某 个字段的时候，对于字段 X 来说，就不能把字段 X 拆分成字段 X-1 和字段 X-2。事实上，任何的 DBMS 都会满足第一范式的要求，不会将字段进行拆分。 

- **2NF 指的数据表里的非主属性都要和这个数据表的候选键有完全依赖关系**

  - (球员编号, 比赛编号) → (姓名, 年龄, 比赛时间, 比赛场地，得分)

  - 但是这个数据表不满足第二范式，因为数据表中的字段之间还存在着如下的对应关系

    - > (球员编号) → (姓名，年龄) 
      >
      > (比赛编号) → (比赛时间, 比赛场地)
      >
      > 
      >
      > 知道球员的编号是可以知道球员信息的，但是比赛编号、比赛时间是无法来通过球员信息来确定的。这张表需要两个候选码（球员编号、比赛编号）才能确定一条记录的信息。类似于这样的关系我们称为「部分依赖」,消除后才能算「第二范式」。

  - 这样会产生怎样的问题呢

    - 数据冗余：如果一个球员可以参加 m 场比赛，那么球员的姓名和年龄就重复了 m-1 次。一个比赛也可能会有 n 个球员参加，比赛的时间和地点就重复了 n-1 次。 
    - 插入异常：如果我们想要添加一场新的比赛，但是这时还没有确定参加的球员都有谁， 那么就没法插入。 
    - 删除异常：如果我要删除某个球员编号，如果没有单独保存比赛表的话，就会同时把比 赛信息删除掉。 
    - 更新异常：如果我们调整了某个比赛的时间，那么数据表中所有这个比赛的时间都需要 进行调整，否则就会出现一场比赛时间不同的情况。 

  - 为了避免出现上述的情况，我们可以把球员比赛表设计为下面的三张表

    - 球员 player 表包含球员编号、姓名和年龄等属性；比赛 game 表包含比赛编号、比赛时间 和比赛场地等属性；球员比赛关系 player_game 表包含球员编号、比赛编号和得分等属性。 

  - 某种程度上 2NF 是 对 1NF 原子性的升级。1NF 告诉我们字段属性需要是原子性的，而 2NF 告诉我们一张表就是一个独立的对象，也就是说一张表只表达一个意思。 

- **3NF 在满足 2NF 的同时，对任何非主属性都不传递依赖于候选键**

  - 也就是说不能存在非主属性 A 依赖于非主属性 B，非主属性 B 依赖于候选键的情况
    - 球员 player 表中球员编号决定了球队名称，同时球队名称决定了球队主教练，非主属性球队主教练就会传递依赖于球员编号，因此不符合 3NF 的要求。 
  - 如果要达到 3NF 的要求，需要把数据表拆成下面这样
    - 球员表的属性包括球员编号、姓名和球队名称；球队表的属性包括球队名称、球队主教练。

- **2NF和3NF都强调非主属性对主属性的依赖关系，2N针对完全依赖，3NF针对直接依赖，都是为了保持表的原子性。**







## **反范式设计**

- **BCNF，也叫做巴斯 - 科德范式，它在 3NF 的基础上消除了主属性对候选键的部分依赖或者传递依赖关系**

- 我们在之前已经了解了越高阶的范式得到的数据表越多，数据冗余度越低。但有时候，我们 

  在设计数据表的时候，还需要为了性能和读取效率违反范式化的原则。反范式就是相对范式 

  化而言的，换句话说，就是允许少量的冗余，通过空间来换时间。





