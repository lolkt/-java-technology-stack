## 基础架构

- MySQL 可以分为 Server 层和存储引擎层两部分
  - Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能
  - 存储引擎层负责数据的存储和提取，最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。

## MySQL调优之事务：高并发场景下的数据库事务调优

- 并发事务带来的问题
  - 数据丢失
    - 由于事务A更新失败回滚，导致事务B更新的数据被覆盖掉，造成数据丢失
    - 未提交读（Read Uncommitted）
      - 在事务 B读取数据时，事务 A 读取和修改数据加了共享锁
      - 就是一个事务能够看到其他事务尚未提交的修改，这是最低的隔离水平，允许[脏读](https://en.wikipedia.org/wiki/Isolation_(database_systems)#Dirty_reads)出现。
  - 脏读
    - 由于事务A更新失败回滚，导致事务B读取的数据为脏数据
    - 已提交读（Read Committed）
      - 事务 B在读取数据时，事务 A 只能读取数据，不能修改。当事务B读取到数据后，事务 A才能修改。
      - 事务能够看到的数据都是其他事务已经提交的修改，也就是保证不会看到任何中间性状态，当然脏读也不会出现。读已提交仍然是比较低级别的隔离，并不保证再次读取时能够获取同样的数据，也就是允许其他事务并发修改数据，允许不可重复读和幻象读（Phantom Read）出现。
  - 不可重复读
    - 事务第一次读取与第二次读取的数据不一致
    - 可重复读（Repeatable Read）
      - 事务B 在没有结束事务时，事务 A 只能读取数据，不能修改。当事务 B结束事务，事务 A 才能修改
      - 保证同一个事务中多次读取的数据是一致的，这是 MySQL InnoDB 引擎的默认隔离级别，但是和一些其他数据库实现不同的是，可以简单认为 MySQL 在可重复读级别不会出现幻象读。
  - 幻读
    - 事务B读取数据时，事务A增加了一个新的字段，事务B更新完成后发现多了一个字段
- **InnoDB 是如何实现原子性、一致性和持久性的**
  - **事务的回滚机制 保证原子性**
  - **undo log + MVCC 保证一致性**
  - **binlog + redo log 两阶段提交保证持久性**
  - 事务一旦提交，就将该redolog中的操作，持久化到磁盘上，事务回滚，则执行undo log中记录的操作，恢复到执行前的状态。





## 事务隔离（MVCC）

- 在 MySQL中，事务支持是在引擎层实现的。

- SQL 标准的事务隔离级别

  - > 读未提交：别人改数据的事务尚未提交，我在我的事务中也能读到。
    > 读已提交：别人改数据的事务已经提交，我在我的事务中才能读到。
    > 可重复读：别人改数据的事务已经提交，我在我的事务中也不去读。

  - > 读未提交”：直接返回记录上的最新值
    > “读提交”：在每个 SQL 语句开始执行的时候创建
    > “可重复读”：在事务启动时创建的，整个事务存在期间都用这个视图

- 事务隔离的实现

  - 在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值
  - **同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）**
  - 建议你尽量不要使用长事务
    - 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。
    - 除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库

- 事务的启动方式

  - 在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。
  - set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接

- 如何避免长事务对业务的影响？

  - 确认是否使用了 set autocommit=0。MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认
  - 确认是否有不必要的只读事务
  - 通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。
  - 监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill；
  - 如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。





## 事务到底是隔离的还是不隔离的（MVCC 是怎么工作的）

- “快照”在 MVCC 里是怎么工作的？

  - 每个事务有一个唯一的事务 ID，叫作 transaction id，按申请顺序严格递增的。
  - 每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID
    - 也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 rowtrx_id。
    - 假设同一行数据的 4 个版本，当前最新版本是 V4，V1、V2、V3 并不是物理上真实存在的，而是每次需要的时候根据当前版本和 undo log 计算出来的。

- InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前启动了但还没提交的所有事务 ID

  - 数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1记为高水位。这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。

  - 已提交事务、未提交事务、未开始事务

  - 数据版本的可见性规则，就是基于数据的 row trx_id 和这个一致性视图的对比结果得到的。

  - > 版本未提交，不可见；
    >
    > 版本已提交，但是是在视图创建后提交的，不可见；
    >
    > 版本已提交，而且是在视图创建前提交的，可见。

- 一条规则：更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）

  - 其实，除了 update 语句外，select 语句如果加锁（lock in share mode 或 for update），也是当前读。

- 事务的可重复读的能力是怎么实现的

  - 可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。
  - 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；
  - 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。



## 日志系统（redo log 和 binlog ）

- 与查询流程不一样的是，更新流程还涉及两个重要的日志模块：redo log（重做日志）和 binlog（归档日志）。
- **redo log**
  - WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘
  - 当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面
  - 有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。
- **binlog**
  - Bin log 用于记录了完整的逻辑记录，所有的逻辑记录在 bin log 里都能找到，所以在备份恢复时，是以 bin log 为基础，通过其记录的完整逻辑操作，备份出一个和原库完整的数据。
  - 这两种日志有以下三点不同
    - redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
    - redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。
    - redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。
- 将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是"两阶段提交"。
  - 由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redolog 再写 binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。
  - update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况呢？
  -  先写 redo log 后写 binlog
    - redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来
    - 这时候 binlog 里面就没有记录这个语句，之后备份日志的时候，存起来的 binlog 里面就没有这条语句，恢复临时库的话，临时库就会少了这一次更新，恢复出来的这一行字段的值就是 0
  - 先写 binlog 后写 redo log
    - 由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0
    - 但是 binlog 里面已经记录了“把c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。
- 双1
  - redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。
  - sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。





## MySQL是怎么保证数据不丢的（redo log 和 binlog ）

- 只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复。

- binlog 的写入机制

  - 事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到binlog 文件中。

    - write，指的就是指把日志写入到文件系统的 binlog cache，并没有把数据持久化到磁盘，所以速度比较快。
    - fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。

  - write 和 fsync 的时机，是由参数 sync_binlog 控制的：

    - sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync；

    2. sync_binlog=1 的时候，表示每次提交事务都会执行 fsync；
    3. sync_binlog=N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才fsync。

  - 一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了 binlog cache 的保存问题。

    3. 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。

- redo log 的写入机制

  3. redo log buffer。事务在执行过程中，生成的 redo log 是要先写到 redo log buffer 的。

  - 事务还没提交的时候，redo log buffer 中的部分日志有没有可能被持久化到磁盘呢？答案是，确实会有。
  - 为了控制 redo log 的写入策略，InnoDB 提供了 innodb_flush_log_at_trx_commit 参数，它有三种可能取值：
    3. 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中
    4. 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；
    5. 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。

  3. InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。

  - 实际上，除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的redo log 写入到磁盘中。
    3. 一种是，redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘	由于这个事务并没有提交，所以这个写盘动作只是write，而没有调用 fsync，也就是只留在了文件系统的 page cache。
    4. 另一种是，并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘

- 时序上 redo log 先 prepare， 再写binlog，最后再把 redo log commit。

  - 如果把 innodb_flush_log_at_trx_commit 设置成 1，那么 redo log 在 prepare 阶段就要持久化一次，因为有一个崩溃恢复逻辑是要依赖于 prepare 的 redo log，再加上 binlog来恢复的。

- 组提交（group commit）机制

  - 日志逻辑序列号（log sequence number，LSN）

    - > 三个并发事务 (trx1, trx2, trx3) 在 prepare 阶段，都写完 redo log buffer，持久化到磁盘的过程，对应的 LSN 分别是 50、120 和 160。
      >
      > 1. trx1 是第一个到达的，会被选为这组的 leader；
      > 2. 等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN 也变成了160；
      > 3. trx1 去写盘的时候，带的就是 LSN=160，因此等 trx1 返回时所有 LSN 小于等于160 的 redo log，都已经被持久化到磁盘；
      > 4. 这时候 trx2 和 trx3 就可以直接返回了。

  - WAL 机制主要得益于两个方面：

    - redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快；
    - 组提交机制，可以大幅度降低磁盘的 IOPS 消耗。

- 如果你的 MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？

  - 设置 binlog_group_commit_sync_delay 和binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。可能会增加语句的响应时间，但没有丢失数据的风险
  - 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。
  - 将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。

- binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的

  - binlog 是不能“被打断的”，一个事务的 binlog必须连续写，因此要整个事务完成后，再一起写到文件里
  - redo log 并没有这个要求，中间有生成的日志可以写到 redo log buffer 中。redo log buffer 中的内容还能“搭便车”，其他事务提交的时候可以被一起写到磁盘中





## 日志和索引相关问题

- 在两阶段提交的不同瞬间，MySQL 如果发生异常重启，是怎么保证数据完整性的？
  - 由于此时 binlog 还没写，redo log 也还没提交，所以崩溃恢复的时候，这个事务会回滚。
  - 如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；
    - 如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：
      - a. 如果是，则提交事务；
      - b. 否则，回滚事务。
- MySQL 怎么知道 binlog 是完整的
  - 一个事务的 binlog 是有完整格式的：
    - statement 格式的 binlog，最后会有 COMMIT；
    - row 格式的 binlog，最后会有一个 XID event。
  - 在 MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog内容的正确性。
- redo log 和 binlog 是怎么关联起来的
  - 它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log
    - 如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；
    - 如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。
- 处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计
  - 数据与备份的一致性有关
    - 在时刻 B，binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库
      （或者用这个 binlog 恢复出来的库）使用
    - 所以，在主库上也要提交这个事务
    - 采用这个策略，主库和备库的数据就保证了一致性。
  - 如果这样的话，为什么还要两阶段提交呢？干脆先 redo log 写完，再写 binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？
    - 如果必须要举一个场景，来说明这么做的必要性的话，那就是事务的持久性问题。
    - 对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚。而如果 redo log 直接提交，然后 binlog 写入的时候失败，InnoDB 又回滚不了，数据和 binlog 日志又不一致了。
  - InnoDB 引擎使用的是 WAL 技术，执行事务的时候，写完内存和日志，事务就算完成了。如果之后崩溃，要依赖于日志来恢复数据页。
- binlog 有着 redo log 无法替代的功能。
  - 一个是归档。redo log 是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，
    - 一个就是 MySQL 系统依赖于 binlog
      - MySQL 系统高可用的基础，就是 binlog 复制。
      - 还有很多公司有异构系统（比如一些数据分析系统），这些系统就靠消费 MySQL 的binlog 来更新自己的数据。关掉 binlog 的话，这些下游系统就没法输入了。
- 正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的呢
  - 这里涉及到了，“redo log 里面到底是什么”的问题。
  - redo log 并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在“数据最终落盘，是由 redo log 更新过去”的情况。
  - 如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页
    - 最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与 redo log 毫无关系。
      在崩溃恢复场景中
  - InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态。



## MySQL是怎么保证主备一致的（binlog 的三种格式对比）

- binlog 可以用来归档，也可以用来做主备同步，但它的内容是什么样的呢？为什么备库执行了 binlog 就可以跟主库保持一致了呢

- MySQL 主备的基本原理

  - 备库设置成只读（readonly）模式。这样做，有以下几个考虑：

    - 有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作

    2. 防止切换逻辑有 bug，比如切换过程中出现双写，造成主备不一致；
    3. 可以用 readonly 状态，来判断节点的角色。

  - 主备流程

    3. 主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写 binlog。
    4. 备库 B 跟主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B的这个长连接。
    5. 备库 B  change master 命令
    6. 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是 io_thread和 sql_thread。其中 io_thread 负责与主库建立连接。
    7. 主库 A从本地读取 binlog，发给 B
    8. 备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。
    9. sql_thread 读取中转日志，解析出日志里的命令，并执行
    10. 后来由于多线程复制方案的引入，sql_thread 演化成为了多个线程

- binlog 的三种格式对比

  - statement

    - 当 binlog_format=statement 时，binlog 里面记录的就是 SQL 语句的原文。

    - 由于 statement 格式下，记录到 binlog 里的是语句原文，因此可能会出现这样一种情况：在主库执行这条 SQL 语句的时候，用的是索引 a；而在备库执行这条 SQL 语句的时候，却使用了索引 t_modified。因此，MySQL 认为这样写是有风险的

    - > delete from t  where a>=4 and t_modified<='2018-11-10' limit 1;
      >
      > 
      >
      > 如果 delete 语句使用的是索引 a，那么会根据索引 a 找到第一个满足条件的行，也就是说删除的是 a=4 这一行；
      >
      > 但如果使用的是索引 t_modified，那么删除的就是 t_modified='2018-11-09’也就是a=5 这一行。

  - row

    - row 格式的 binlog 里没有了 SQL 语句的原文，而是替换成了两个 event：Table_map 和 Delete_rows。
    - 借助 mysqlbinlog 工具  解析和查看 binlog 中的内容。 mysqlbinlog -vv data/master.000001 --start-position=8900;
    - 你可以看到，当 binlog_format 使用 row 格式的时候，binlog 里面记录了真实删除行的主键 id，这样 binlog 传到备库去的时候，就肯定会删除 id=4 的行，不会有主备删除不同行的问题。

  - mixed

    - 有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。
    - row 格式的缺点是，很占空间
      - 比如你用一个 delete 语句删掉 10 万行数据，用statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中

  - 现在越来越多的场景要求把 MySQL 的 binlog 格式设置成 row。这么做的理由有很多，一个可以直接看出来的好处：恢复数据。

- 循环复制问题

  - binlog 的特性确保了在备库执行相同的 binlog，可以得到与主库相同的状态。因此，我们可以认为正常情况下主备的数据是一致的。
  - 双 M 结构（各为主备）还有一个问题需要解决。
    - MySQL 在 binlog 中记录了这个命令第一次执行时所在实例的server id。因此，我们可以用下面的逻辑，来解决两个节点间的循环复制的问题：
      - 规定两个库的 server id 必须不同
      - 一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的binlog；
      - 每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。







## MySQL是怎么保证高可用的

- 正常情况下，只要主库执行更新生成的所有 binlog，都可以传到备库并被正确地执行，备库就能达到跟主库一致的状态，这就是最终一致性。

  - 你可以在备库上执行 show slave status 命令，它的返回结果里面会显示seconds_behind_master，用于表示当前备库延迟了多少秒。
  - 主备延迟最直接的表现是，备库消费中转日志（relay log）的速度，比主库生产binlog 的速度要慢。

- 主备延迟的来源

  - 备库的压力大	
    - 一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。
    - 其中，一主多从的方式大都会被采用。因为作为数据库系统，还必须保证有定期全量备份的能力。而从库，就很适合用来做备份。
  - 大事务
  - 还有一个大方向的原因，就是备库的并行复制能力

- 可靠性优先策略

  - 双 M 结构下
  - 判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止；
  - 这个切换流程中是有不可用时间的

- 可用性优先策略

  - 直接切换
  - 使用 row 格式的 binlog 时，数据不一致的问题更容易被发现。而使用 mixed 或者statement 格式的 binlog 时，数据很可能悄悄地就不一致了
    - 因为 row 格式在记录 binlog 的时候，会记录新插入的行的所有字段值，所以最后只会有一行不一致。而且，两边的主备同步的应用线程会报错 duplicate key error 并停止。也就是说，这种情况下，备库 B 的 (5,4) 和主库 A 的 (5,5) 这两行数据，都不会被对方执行
  - 有没有哪种情况数据的可用性优先级更高呢
    - 有一个库的作用是记录操作日志。这时候，如果数据不一致可以通过 binlog 来修补，而这个短暂的不一致也不会引发业务问题。同时，业务系统依赖于这个日志写入逻辑，如果这个库不可写，会导致线上的业务操作无法执行。这时候，你可能就需要选择先强行切换，事后再补数据的策略。
    - 改进措施
      - 让业务逻辑不要依赖于这类日志的写入。也就是说，日志写入这个逻辑模块应该可以降级，比如写到本地文件，或者写到另外一个临时库里面。

- 什么情况下双 M 结构会出现循环复制

  - 在一个主库更新事务后，用命令 set global server_id=x 修改了 server_id。等日志再传回来的时候，发现 server_id 跟自己的 server_id 不同

  - 三节点复制的场景，做数据库迁移的时候会出现。

    - 有三个节点的时候，trx1 是在节点 B 执行的，因此 binlog上的 server_id 就是 B，binlog 传给节点 A，然后 A 和 A’搭建了双 M 结构，就会出现循环复制。

    - > 如果出现了循环复制，可以在 A 或者 A’上，执行如下命令：
      > 1 stop slave； 
      >
      > 2 CHANGE MASTER TO IGNORE_SERVER_IDS=(server_id_of_B);
      >
      > 3 start slave;
      >
      > 
      >
      > 这样这个节点收到日志后就不会再执行。过一段时间后，再执行下面的命令把这个值改回来。
      > 1 stop slave；
      > 2 CHANGE MASTER TO IGNORE_SERVER_IDS=();
      > 3 start slave;



## MySQL会“抖”一下（刷脏页）

- MySQL 偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。
  - 什么情况会引发数据库的 flush 过程呢？
    - redo log满了
    - 系统内存不足
      - InnoDB 用缓冲池（buffer pool）管理内存，InnoDB 需要有控制脏页比例的机制，来尽量避免这种情况。
    - MySQL 认为系统“空闲”的时候
    - MySQL 正常关闭的情况
- InnoDB 刷脏页的控制策略
  - innodb_io_capacity 
    - 告诉 InnoDB 你的磁盘能力。这个值我建议你设置成磁盘的 IOPS。磁盘的 IOPS 可以通过 fio 这个工具来测试
  - InnoDB 的刷盘速度就是要参考两个因素：一个是脏页比例，一个是 redo log 写盘速度。
    - 平时要多关注脏页比例，不要让它经常接近 75%。





## 备库为什么会延迟好几个小时（主从复制）

- 备库并行复制能力

  - coordinator 就是原来的 sql_thread, 不过现在它不再直接更新数据了，只负责读取中转日志和分发事务
  - 真正更新日志的，变成了 worker 线程。而 work 线程的个数，就是由参数 slave_parallel_workers 决定的
  - coordinator 在分发的时候，需要满足以下这两个基本要求：
    - 更新同一行的两个事务，必须被分发到同一个 worker中。
    - 同一个事务不能被拆开，必须放到同一个 worker 中。

- MariaDB 的并行复制策略

  - > 1. 在一组里面一起提交的事务，有一个相同的 commit_id，下一组就是 commit_id+1；
    > 2. commit_id 直接写到 binlog 里面；
    > 3. 传到备库应用的时候，相同 commit_id 的事务分发到多个 worker 执行；
    > 4. 这一组全部执行完成后，coordinator 再去取下一批。

  - 这个方案很容易被大事务拖后腿。假设 trx2 是一个超大事务，那么在备库应用的时候，trx1 和 trx3 执行完成后，就只能等 trx2 完全执行完成，下一组才能开始执行。

- MySQL 5.7 的并行复制策略

  - 由参数slave-parallel-type 来控制并行复制策略
  - MySQL 5.7 并行复制策略的思想是
    - 更新同一行的事务是不可能同时进入 commit 状态的
    - 同时处于 prepare 状态的事务，在备库执行时是可以并行的；
    - 处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的。
  - 这两个参数是用于故意拉长 binlog 从 write 到 fsync 的时间，以此减少 binlog 的写盘次数。在 MySQL 5.7 的并行复制策略里，它们可以用来制造更多的“同时处于 prepare 阶段的事务”。这样就增加了备库复制的并行度。
    - binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;.
    - binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用fsync。

- MySQL 5.7.22 的并行复制策略

  - 新增了一个参数 binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。

    - COMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。

    - WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。

    - WRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先

      后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。

    - 当然为了唯一标识，这个 hash 值是通过“库名 + 表名 + 索引名 + 值”计算出来的。如果一个表上除了有主键索引外，还有其他唯一索引，那么对于每个唯一索引，insert 语句对应的 writeset 就要多增加一个 hash 值







## MYSQL读写分离(判断主备无延迟方案)

- 判断主备无延迟方案

  - 第一种

    - show slave status 结果里的seconds_behind_master 参数的值，可以用来衡量主备延迟时间的长短。
    - 每次从库执行查询请求前，先判断seconds_behind_master 是否已经等于 0。如果还不等于 0 ，那就必须等到这个参数变为0 才能执行查询请求。

  - 第二种

    - > 对比位点确保主备无延迟：
      > Master_Log_File 和 Read_Master_Log_Pos，表示的是读到的主库的最新位点；
      > Relay_Master_Log_File 和 Exec_Master_Log_Pos，表示的是备库执行的最新位点。

  - 第三种

    - > 对比 GTID 集合确保主备无延迟：
      > Auto_Position=1 ，表示这对主备关系使用了 GTID 协议。
      > Retrieved_Gtid_Set，是备库收到的所有日志的 GTID 集合；
      > Executed_Gtid_Set，是备库所有已经执行完成的 GTID 集合。
      > 如果这两个集合相同，也表示备库接收到的日志都已经同步完成。

- semi-sync （半同步复制）方案

  - semi-sync 做了这样的设计：

    > 1. 事务提交的时候，主库把 binlog 发给从库；
    > 2. 从库收到 binlog 以后，发回给主库一个 ack，表示收到了；
    > 3. 主库收到这个 ack 以后，才能给客户端返回“事务完成”的确认。

  - 判断同步位点的方案还有另外一个潜在的问题，即：如果在业务更新的高峰期，主库的位点或者 GTID 集合更新很快，那么上面的两个位点等值判断就会一直不成立，很可能出现从库上迟迟无法响应查询请求的情况。

    - 备库 B 一直都和主库 A 存在延迟，如果用上面必须等到无延迟才能查询的方案，select 语句一直都不能被执行。
    - 其实客户端是在发完 trx1 更新后发起的 select 语句，我们只需要确保 trx1 已经执行完成就可以执行 select 语句了

  - semi-sync 配合判断主备无延迟的方案，存在两个问题：

    - 一主多从的时候，在某些从库执行查询请求会存在过期读的现象；
      - semi-sync+ 位点判断的方案，只对一主一备的场景是成立的。在一主多从场景中，主库只要等到一个从库的 ack，就开始给客户端返回确认。
    - 在持续延迟的情况下，可能出现过度等待的问题。

- 等主库位点方案

  - > select master_pos_wait(file, pos[, timeout])
    >
    > ```
    > 1. 它是在从库执行的；
    > ```
    >
    > 2. 参数 file 和 pos 指的是主库上的文件名和位置；
    > 3. timeout 可选，设置为正整数 N 表示这个函数最多等待 N 秒。
    >    这个命令正常返回的结果是一个正整数 M，表示从命令开始执行，到应用完 file 和 pos 表示的 binlog 位置，执行了多少事务。

  - 对于先执行 trx1，再执行一个查询请求的逻辑，要保证能够查到正确的数据，我们可以使用这个逻辑：

    - > 1. trx1 事务更新完成后，马上执行 show master status 得到当前主库执行到的 File 和Position；
      > 2. 选定一个从库执行查询语句；
      > 3. 在从库上执行 select master_pos_wait(File, Position, 1)；
      > 4. 如果返回值是 >=0 的正整数，则在这个从库执行查询语句；
      > 5. 否则，到主库执行查询语句。

    - 这里我们假设，这条 select 查询最多在从库上等待 1 秒。那么，如果 1 秒内master_pos_wait 返回一个大于等于 0 的整数，就确保了从库上执行的这个查询结果一定包含了 trx1 的数据。

- 等 GTID 方案

  - > select wait_for_executed_gtid_set(gtid_set, 1);
    >
    > 1. 等待，直到这个库执行的事务中包含传入的 gtid_set，返回 0；
    > 2. 超时返回 1。

  - 这时，等 GTID 的执行流程就变成了：

    - > 1. trx1 事务更新完成后，从返回包直接获取这个事务的 GTID，记为 gtid1；
      > 2. 选定一个从库执行查询语句；
      > 3. 在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)；
      > 4. 如果返回值是 0，则在这个从库执行查询语句；
      > 5. 否则，到主库执行查询语句。

  - MySQL 5.7.6 版本开始，允许在执行完更新类事务后，把这个事务的 GTID 返回给客户端，这样等 GTID 的方案就可以减少一次查询。

    - 问题是，怎么能够让 MySQL 在执行事务后，返回包中带上 GTID 呢？
      - 你只需要将参数 session_track_gtids 设置为 OWN_GTID，然后通过 API 接口mysql_session_track_get_first 从返回包解析出 GTID 的值即可。

  



## 什么时候需要分表分库

- 如何分表分库？

  - 一种常见的路由策略如下：

    - > １、中间变量　＝ user_id%（库数量*每个库的表数量）;
      >
      > ２、库序号　＝　取整（中间变量／每个库的表数量）;
      >
      > ３、表序号　＝　中间变量％每个库的表数量;

  - 分表分库分为垂直切分和水平切分两种。

    - 垂直分库是指根据业务来分库
      - 垂直分表则是指根据一张表中的字段，规则就是将一些不经常使用的字段拆分到另一张表中
    - 水平分表则是将表中的某一列作为切分的条件，按照某种规则（Range 或 Hash 取模）来切分为更小的表。
      - 水平分表只是在一个库中，如果存在连接数、I/O 读写以及网络吞吐等瓶颈，考虑将水平切换的表分布到不同机器的库中，这就是水平分库分表了。

  - 结合以上垂直切分和水平切分，我们一般可以将数据库分为：单库单表 - 单库多表 - 多库多表。

  

- 分表分库之后面临的问题

  - 分布式事务问题
  - 跨节点 JOIN 查询问题
    - 冗余表或冗余字段
  - 跨节点分页查询问题
    - 通常我们建议使用两套数据来解决跨节点分页查询问题，一套是基于分库分表的用户单条或多条查询数据，一套则是基于 Elasticsearch、Solr 存储的订单数据，主要用于运营人员根据其它字段进行分页查询。为了不影响提交订单的业务性能，我们一般使用异步消息来实现Elasticsearch、Solr 订单数据的新增和修改。
  - 全局主键 ID 问题
    - 在分库分表后，主键将无法使用自增长来实现了，在不同的表中我们需要统一全局主键ID。
    - 我们也可以基于 Redis 分布式锁实现一个递增的主键 ID
    - 我们还可以基于 Twitter 开源的分布式 ID 生产算法——snowflake 解决全局主键 ID 问题
  - 扩容问题







## 索引

- ```sql
CREATE TABLE projectfile (
  	id INT AUTO_INCREMENT COMMENT '附件id',
	fileuploadercode VARCHAR(128) COMMENT '附件上传者code',
  	projectid INT COMMENT '项目id;此列受project表中的id列约束',
	filename VARCHAR (512) COMMENT '附件名',
  	fileurl VARCHAR (512) COMMENT '附件下载地址',
  	filesize BIGINT COMMENT '附件大小，单位Byte',
  	-- 主键本身也是一种索引（注:也可以在上面的创建字段时使该字段主键自增）
          PRIMARY KEY (id),
  	-- 主外键约束（注:project表中的id字段约束了此表中的projectid字段）
  	FOREIGN KEY (projectid) REFERENCES project (id),
  	-- 给projectid字段创建了唯一索引(注:也可以在上面的创建字段时使用unique来创建唯一索引)
  	UNIQUE INDEX (projectid),
  	-- 给fileuploadercode字段创建普通索引
  	INDEX (fileuploadercode)
  	-- 指定使用INNODB存储引擎(该引擎支持事务)、utf8字符编码
  ) ENGINE = INNODB DEFAULT CHARSET = utf8 COMMENT '项目附件表';
  ```
  
- 建表后创建：

  ALTER TABLE 表名 ADD [UNIQUE | FULLTEXT | SPATIAL]  INDEX | KEY  [索引名] (字段名1 [(长度)] [ASC | DESC]) [USING 索引方法]；

  或

  CREATE  [UNIQUE | FULLTEXT | SPATIAL]  INDEX  索引名 ON  表名(字段名) [USING 索引方法]；

  示例一：

  ```sql
  -- 假设建表时fileuploadercode字段没创建索引(注:同一个字段可以创建多个索引，但一般情况下意义不大)
  -- 给projectfile表中的fileuploadercode创建索引
  ALTER TABLE projectfile ADD UNIQUE INDEX (fileuploadercode);
  ```

  示例二：

  ```sql
  ALTER TABLE projectfile ADD INDEX (fileuploadercode, projectid);
  ```

  示例三：

  ```sql
  -- 将id列设置为主键
  ALTER TABLE index_demo ADD PRIMARY KEY(id) ;
  -- 将id列设置为自增
  ALTER TABLE index_demo MODIFY id INT auto_increment;  
  ```

  

- **索引的出现是为了提高查询效率**

  - 三种常见、也比较简单的数据结构，它们分别是哈希表、有序数组和搜索树
    - 有序数组在等值查询和范围查询场景中的性能就都非常优秀,有序数组索引只适用于静态存储引擎
    - 哈希表这种结构适用于只有等值查询的场景
  - **在 MySQL 中，索引是在存储引擎层实现的**，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。而即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。由于 InnoDB 存储引擎在 MySQL 数据库中使用最为广泛

- **优点：**

  1. 通过创建唯一性索引，可以保证数据库表中的每一行数据的唯一性。
  2. 可以加快数据的检索速度
  3. 可以加速表与表之间的连接
  4. 在使用分组和排序进行检索的时候，可以减少查询中分组和排序的时间 

- **缺点**

  1. 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。
  2. 索引需要占用物理空间，数据量越大，占用空间越大
  3. 会降低表的增删改的效率，因为每次增删改索引，都需要进行动态维护

- **什么时候需要创建索引**

  1.  主键自动建立唯一索引
  2.  频繁作为查询条件的字段应该创建索引
  3.  查询中排序的字段创建索引将大大提高排序的速度（索引就是排序加快速查找
  4.  查询中统计或者分组的字段；

- **什么时候不需要创建索引**

  1. 频繁更新的字段不适合创建索引，因为每次更新不单单是更新记录，还会更新索引，保存索引文件
  2. where条件里用不到的字段，不创建索引；
  3. 表记录太少，不需要创建索引；
  4. 经常增删改的表；
  5. 数据重复且分布平均的字段，因此为经常查询的和经常排序的字段建立索引。注意某些数据包含大量重复数据，因此他建立索引就没有太大的效果，例如性别字段，只有男女，不适合建立索引。

**注意点：小表使用全表扫描更快，中大表才使用索引。超级大表索引基本无效。**

- 索引从实现上说，分成 2 种：聚集索引和辅助索引（也叫二级索引或者非聚集索引）

- 从功能上说，分为 6 种：普通索引，唯一索引，主键索引，复合索引，外键索引，全文索引。

  **详细说说 6 种索引：**

  1. 普通索引：最基本的索引，没有任何约束。

2. 唯一索引：索引列的值必须唯一，且不能为空，如果是组合索引，则列值的组合必须唯一。

   1. **唯一索引 与 主键**

      唯一索引是在表上**一个或者多个字段**组合建立的索引，这个（或这几个）字段的值组合起来在表中**不可以重复**。一张表可以建立**任意多个唯一索引**，但一般只建立一个。

      **主键是一种特殊的唯一索引**，区别在于，唯一索引列允许null值，而主键列不允许为null值。一张表**最多建立一个主键，也可以不建立主键。**

      1. 可转到下面介绍自增主键

     2. **聚簇索引 与 唯一索引**

        严格来说，**聚簇索引不一定是唯一索引**，聚簇索引的索引值并不要求是唯一的，**唯一聚簇索引**才是！在一个有聚簇索引的列上是可以插入两个或多个相同值的，这些相同值在硬盘上的物理排序与聚簇索引的排序相同，仅此而已。

  3. 主键索引：**特殊的唯一索引，不允许有空值**。唯一的标识一条记录，不能为空，一般用primary key来约束。

4. 复合索引：在多个字段上建立索引，能够加速查询到速度

  5. 外键索引：只有InnoDB类型的表才可以使用外键索引，保证数据的一致性、完整性和实现级联操作。

6. 全文索引：MySQL 自带的全文索引只能用于 InnoDB、MyISAM ，并且只能对英文进行全文检索，一般使用全文索引引擎（ES，Solr）。

  > ```
  > 注意：主键就是唯一索引，但是唯一索引不一定是主键，唯一索引可以为空，但是空值只能有一个，主键不能为空。
  > ```

  另外，InnoDB 通过主键聚簇数据，如果没有定义主键且没有定义聚集索引， MySql 会选择一个唯一的非空索引代替，如果没有这样的索引，会隐式定义个 6 字节的主键作为聚簇索引，用户不能查看或访问。

- **聚簇索引**的叶子节点就是数据节点，而**非聚簇索引**的叶子节点仍然是索引节点，只不过有指向对应数据块的指针。

- **聚簇索引的优势**

  看上去聚簇索引的效率明显要低于非聚簇索引，因为每次使用辅助索引检索都要经过两次B+树查找

  - **聚簇索引将索引和数据行保存在同一个B-Tree中，查询通过聚簇索引可以直接获取数据**，相比非聚簇索引需要第二次查询（非覆盖索引的情况下）效率要高。
  - **聚簇索引适合用在排序的场合**，非聚簇索引不适合
  - **聚簇索引对于范围查询的效率很高**，因为其数据是按照大小排列的
  - **聚簇索引性能最好**，因为一旦具有第一个索引值的记录被找到，具有连续索引值的记录也一定物理地紧跟其后。一张表只能有一个聚簇索引，所以非常珍贵，必须慎重设置，一般要根据这个表最常用的SQL查询方式选择某个（或多个）字段作为聚簇索引（**或复合聚簇索引**）。
  - **二级索引需要两次索引查找，而不是一次才能取到数据**，因为存储引擎第一次需要通过二级索引找到索引的叶子节点，从而找到数据的主键，然后在聚簇索引中用主键再次查找索引，再找到数据
  - 可以把相关数据保存在一起。例如实现电子邮箱时，可以根据用户 ID 来聚集数据，这样只需要从磁盘读取少数的数据页就能获取某个用户的全部邮件。如果没有使用聚簇索引，则每封邮件都可能导致一次磁盘 I/O。
  - 一张表**只允许存在一个**聚簇索引，因为真实数据的物理顺序只能有一种。如果一张表上还没有聚簇索引，为它新创建聚簇索引时，就需要对已有数据重新进行排序，所以对表进行修改速度较慢是聚簇索引的缺点，对于**经常更新的列不宜建立聚簇索引**。
  - **聚簇索引默认是主键**，如果表中没有定义主键，InnoDB[[1\]](https://www.zhihu.com/search?type=content&q=聚簇索引#ref_1)会选择一个**唯一的非空索引**代替（“唯一的非空索引”是指列不能出现null值的唯一索引，跟主键性质一样）。如果没有这样的索引，InnoDB会隐式地定义一个主键来作为聚簇索引。
  
- **聚簇索引的劣势**
  
  - **维护索引很昂贵**，特别是插入新行或者主键被更新导至要分页(page split)的时候。建议在大量插入新行后，选在负载较低的时间段，通过OPTIMIZE TABLE优化表，因为必须被移动的行数据可能造成碎片。使用独享表空间可以弱化碎片
  - **表因为使用UUId（随机ID）作为主键，使数据存储稀疏，这就会出现聚簇索引有可能有比全表扫面更慢**，所以建议使用int的auto_increment作为主键
  - **主键的值是顺序的，所以 InnoDB 把每一条记录都存储在上一条记录的后面。**当达到页的最大填充因子时（InnoDB 默认的最大填充因子是页大小的 15/16，留出部分空间用于以后修改），下一条记录就会写入新的页中。一旦数据按照这种顺序的方式加载，主键页就会近似于被顺序的记录填满（二级索引页可能是不一样的）
  
- **如果主键比较大的话，那辅助索引将会变的更大**，因为辅助索引的叶子存储的是主键值；过长的主键值，会导致非叶子节点占用占用更多的物理空间
  
- **为什么主键通常建议使用自增id**

  - **聚簇索引的数据的物理存放顺序与索引顺序是一致的**，即：只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上的。如果主键不是自增id，那么可以想 象，它会干些什么，不断地调整数据的物理地址、分页，当然也有其他一些措施来减少这些操作，但却无法彻底避免。但，如果是自增的，那就简单了，它只需要一 页一页地写，索引结构相对紧凑，磁盘碎片少，效率也高。

  - 因为MyISAM的主索引并非聚簇索引，那么他的数据的物理地址必然是凌乱的，拿到这些物理地址，按照合适的算法进行I/O读取，于是开始不停的寻道不停的旋转。聚簇索引则只需一次I/O。（强烈的对比）

  - 不过，如果涉及到大数据量的排序、全表扫描、count之类的操作的话，还是MyISAM占优势些，因为索引所占空间小，这些操作是需要在内存中完成的。

- mysql中聚簇索引的设定

  聚簇索引默认是主键，如果表中没有定义主键，InnoDB 会选择一个唯一的非空索引代替。如果没有这样的索引，InnoDB 会隐式定义一个主键来作为聚簇索引。InnoDB 只聚集在同一个页面中的记录。包含相邻健值的页面可能相距甚远。

- **简单点说：**
  - 设置主键时，会自动生成一个唯一索引，如果**之前**没有聚集索引，那么主键就是聚集索引。

  - 没有设置主键时，会选择一个不为空的唯一索引作为聚集索引，如果还没有，那就生成一个隐式的 6 字节的索引。

  - 索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。

  - > alter table T engine=InnoDB。

  

- **覆盖索引**

  - 如果执行的语句是 select ID from T where k between 3 and 5，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引
  - 需要注意的是，在引擎内部使用覆盖索引在索引 k 上其实读了三个记录，R3~R5，对于 MySQL 的 Server 层来说，它就是找引擎拿到了两条记录，因此 MySQL 认为扫描行数是 2。

- **最左前缀原则**

  - 在MySQL建立联合索引时会遵守最左前缀匹配原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。
  - **之所以会有最左前缀匹配原则和联合索引的索引构建方式及存储结构是有关系的。**
    - 因为根据a->b->c排序的时候，a相同的值都放在一起，c相同的值都不在一起，所以没办法走索引。
    - 假设组合索引为：a,b,c的话；那么当SQL中对应有：a或a，b或a，b，c的时候，可称为完全满足最左原则；当SQL中查询条件对应只有a，c的时候，可称为部分满足最左原则；当SQL中没有a的时候，可称为不满足最左原则
  - InnoDB会把主键字段放到索引定义字段后面，当然同时也会去重。所以，当主键是(a,b)的时候，定义为c的索引，实际上是（c,a,b);定义为(c,a)的索引，实际上是(c,a,b)你看着加是相同的
  - 利用最左前缀：Mysql会一直向右查找直到遇到范围操作（>，<，like、between）就停止匹配。比如a=1 and b=2 and c>3 and d=6；此时如果建立了（a,b,c,d）索引，那么后面的d索引是完全没有用到，当换成了（a,b,d,c）就可以用到。
  - MySQL5.7开始，会自动优化，如：会把c，b，a优化为a，b，c使之完全遵循最左原则；会把c，a优化为a，c使之部分遵循最左原则。即：SQL语句中的对应条件的先后顺序无关。

- **前缀索引**

  - 使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。

    - 我们在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少

    - > 首先，你可以使用下面这个语句，算出这个列上有多少个不同的值：
      >
      > mysql> select count(distinct email) as L from SUser;
      >
      > 
      >
      > 依次选取不同长度的前缀来看这个值，比如我们要看一下 4~7 个字节的前缀索引，可以用这个语句：
      > 1 mysql> select 
      > 2 count(distinct left(email,4)）as L4,
      > 3 count(distinct left(email,5)）as L5,
      > 4 count(distinct left(email,6)）as L6,
      > 5 count(distinct left(email,7)）as L7,
      > 6 from SUser;

  - 使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素。

- 遇到前缀的区分度不够好的情况时，我们要怎么办呢？

  - 第一种方式是使用倒序存储。如果你存储身份证号的时候把它倒过来存
  - 第二种方式是使用 hash 字段。你可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。




## 联合索引在B+树上的存储结构及数据查找方式

- 首先，表T1有字段a,b,c,d,e，其中a是主键，除e为varchar其余为int类型，并创建了一个联合索引idx_t1_bcd(b,c,d)，然后b、c、d三列作为联合索引

  - InnoDB会使用主键索引在B+树维护索引和数据文件，然后我们创建了一个`联合索引（b，c，d）`也会生成一个索引树，同样是B+树的结构，只不过它的data部分存储的是联合索引所在行的主键值
  - 对于联合索引来说只不过比单值索引多了几列，而这些索引列全都出现在索引树上。对于联合索引，存储引擎会首先根据第一个索引列排序，如果第一列相等则再根据第二列排序

- bcd联合索引在B+树上的结构图：

  ![img](https://user-gold-cdn.xitu.io/2020/2/27/170867cb6af0a72d?imageslim)

- 联合索引的查找方式
  
  - 当我们的SQL语言可以应用到索引的时候，比如`select * from T1 where b = 12 and c = 14 and d = 3;` 也就是T1表中a列为4的这条记录。存储引擎首先从根节点（一般常驻内存）开始查找，第一个索引的第一个索引列为1,12大于1，第二个索引的第一个索引列为56,12小于56，于是从这俩索引的中间读到下一个节点的磁盘文件地址，从磁盘上Load这个节点，通常伴随一次磁盘IO，然后在内存里去查找。
  - 当Load叶子节点的第二个节点时又是一次磁盘IO，比较第一个元素，b=12,c=14,d=3完全符合，于是找到该索引下的data元素即ID值，再从主键索引树上找到最终数据。

![img](https://user-gold-cdn.xitu.io/2020/2/27/170867e984dd5594?imageslim)

- 最左前缀

  - **之所以会有最左前缀匹配原则和联合索引的索引构建方式及存储结构是有关系的。**
    - 之所以会有最左原则，是因为联合索引的B+Tree是按照第一个关键字进行索引排列的
  - 首先我们创建的`index_bcd(b,c,d)`索引，相当于创建了(b)、（b、c）（b、c、d）三个索引，看完下面你就知道为什么相当于创建了三个索引。
    - 我们看，**联合索引是首先使用多列索引的第一列构建的索引**树，用上面idx_t1_bcd(b,c,d)的例子就是优先使用b列构建，当b列值相等时再以c列排序，若c列的值也相等则以d列排序。
    - 索引的第一列也就是b列可以说是从左到右单调递增的，但我们看c列和d列并没有这个特性，它们只能在b列值相等的情况下这个小范围内递增，如第一叶子节点的第1、2个元素和第二个叶子节点的后三个元素。  **由于联合索引是上述那样的索引构建方式及存储结构，所以联合索引只能从多列索引的第一列开始查找。所以如果你的查找条件不包含b列如（c,d）、(c）、(d)是无法应用缓存的，以及跨列也是无法完全用到索引如(b,d)，只会用到b列索引。**

- 如下列举一些SQL的索引使用情况

  ```sql
  select * from T1 where b = 12 and c = 14 and d = 3;-- 全值索引匹配 三列都用到
  select * from T1 where b = 12 and c = 14 and e = 'xml';-- 应用到两列索引
  select * from T1 where b = 12 and e = 'xml';-- 应用到一列索引
  select * from T1 where b = 12  and c >= 14 and e = 'xml';-- 应用到bc两列列索引及索引条件下推优化
  select * from T1 where b = 12  and d = 3;-- 应用到一列索引  因为不能跨列使用索引 没有c列 连不上
  select * from T1 where c = 14  and d = 3;-- 无法应用索引，违背最左匹配原则
  ```





## hash索引和B+tree索引区别



索引是帮助mysql获取数据的数据结构。最常见的索引是Btree索引和Hash索引。

不同的引擎对于索引有不同的支持：Innodb和MyISAM默认的索引是Btree索引；而Mermory默认的索引是Hash索引。

我们在mysql中常用两种索引算法BTree和Hash，两种算法检索方式不一样，对查询的作用也不一样。 

一、BTree 

BTree索引是最常用的mysql数据库索引算法，因为它不仅可以被用在=,>,>=,<,<=和between这些比较操作符上，而且还可以用于like操作符，只要它的查询条件是一个不以通配符开头的常量，例如： 

select * from user where name like ‘jack%’; 

select * from user where name like ‘jac%k%’; 

如果一通配符开头，或者没有使用常量，则不会使用索引，例如： 

select * from user where name like ‘%jack’; 

select * from user where name like simply_name; 

二、Hash 

Hash索引只能用于对等比较，例如=,<=>（相当于=）操作符。由于是一次定位数据，不像BTree索引需要从根节点到枝节点，最后才能访问到页节点这样多次IO访问，所以检索效率远高于BTree索引。 

但为什么我们使用BTree比使用Hash多呢？主要Hash本身由于其特殊性，也带来了很多限制和弊端： 

1. Hash索引仅仅能满足“=”,“IN”,“<=>”查询，不能使用范围查询。 

2. 联合索引中，Hash索引不能利用部分索引键查询。 

对于联合索引中的多个列，Hash是要么全部使用，要么全部不使用，并不支持BTree支持的联合索引的最优前缀，也就是联合索引的前面一个或几个索引键进行查询时，Hash索引无法被利用。 

3. Hash索引无法避免数据的排序操作 

由于Hash索引中存放的是经过Hash计算之后的Hash值，而且Hash值的大小关系并不一定和Hash运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算。 

4. Hash索引任何时候都不能避免表扫描 

Hash索引是将索引键通过Hash运算之后，将Hash运算结果的Hash值和所对应的行指针信息存放于一个Hash表中，由于不同索引键存在相同Hash值，所以即使满足某个Hash键值的数据的记录条数，也无法从Hash索引中直接完成查询，还是要通过访问表中的实际数据进行比较，并得到相应的结果。 

5. Hash索引遇到大量Hash值相等的情况后性能并不一定会比BTree高 

对于选择性比较低的索引键，如果创建Hash索引，那么将会存在大量记录指针信息存于同一个Hash值相关联。这样要定位某一条记录时就会非常麻烦，会浪费多次表数据访问，而造成整体性能底下。



## 普通索引和唯一索引查询过程

- 查询过程

  - InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。

- 更新过程

  - 如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 changebuffer 中
    - 在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作
    - 虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。
  - 将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。
  - 将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。changebuffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。

- change buffer

  - 对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。
  - change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。
  - 对于写多读少的业务来说，change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。
  - 如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。

- change buffer 和 redo log

  - > mysql> insert into t(id,k) values(id1,k1),(id2,k2);
    >
    > 
    >
    > 查找到位置后，k1 所在的数据页在内存 (InnoDBbuffer pool) 中，k2 所在的数据页不在内存中
    >
    > 
    >
    > Page 1 在内存中，直接更新内存；
    > Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息中
    > 将上述两个动作记入 redo log 

  - 那在这之后的读请求，要怎么处理呢？

  - > 读 Page 1 的时候，直接从内存返回,虽然磁盘上还是之前的数据，但是这里直接从内存返回结果
    > 要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果
    > 可以看到，直到需要读 Page 2 的时候，这个数据页才会被读入内存。

  - redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。

- change buffer 一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致 change buffer 丢失呢

  - change buffer有一部分在内存，有一部分在ibdata做merge操作，会把change buffer里相应的数据持久化到ibdata
    - merge 的执行流程
      - 从磁盘读入数据页到内存（老版本的数据页）
      - 从 change buffer 里找出这个数据页的 change buffer 记录，依次应用，得到新版数据页；
      - 写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。
      - 这时候，数据页和内存中 change buffer 对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了。
  - 虽然是只更新内存，但是在事务提交的时候，我们把 change buffer 的操作也记录到 redo log 里了，所以崩溃恢复的时候，change buffer 也能找回来。
  - change buffer中分两部分，一部分是本次写入未写完的，一部分是已经写入完成的。
    - 针对未写完的，此部分操作，还未写入redo log，因此事务还未提交，所以没影响。
    - 针对已经写完成的，可以通过redo log来进行恢复



## BTree索引

- 数据库的操作
  - 除了这些功能性需求之外，这种问题往往还会涉及一些非功能性需求，比如安全、性能、用户体验等等。限于专栏要讨论的主要是数据结构和算法，对于非功能性需求，我们着重考虑**性能方面**的需求。性能方面的需求，我们主要考察时间和空间两方面，也就是**执行效率和存储空间**。
  - 在执行效率方面，我们希望通过索引，查询数据的效率尽可能的高；在存储空间方面，我们希望索引不要消耗太多的内存空间。
    - 我们先来看**散列表**。散列表的查询性能很好，时间复杂度是 O(1)。但是，散列表不能支持按照区间快速查找数据。所以，散列表不能满足我们的需求。
    - 我们再来看**平衡二叉查找树**。尽管平衡二叉查找树查询的性能也很高，时间复杂度是 O(logn)。而且，对树进行中序遍历，我们还可以得到一个从小到大有序的数据序列，但这仍然不足以支持按照区间快速查找数据。
    - 我们再来看**跳表**。跳表是在链表之上加上多层索引构成的。它支持快速地插入、查找、删除数据，对应的时间复杂度是 O(logn)。并且，跳表也支持按照区间快速地查找数据。我们只需要定位到区间起点值对应在链表中的结点，然后从这个结点开始，顺序遍历链表，直到区间终点对应的结点为止，这期间遍历得到的数据就是满足区间值的数据。
  
- B-Tree
  - 数据结构
    - d为大于1的一个正整数，称为B-Tree的度。
    - h为一个正整数，称为B-Tree的高度。
    - 每个非叶子节点由n-1个key和n个指针组成，其中d<=n<=2d。
    - 每个叶子节点最少包含一个key和两个指针，最多包含2d-1个key和2d个指针，叶节点的指针均为null 。
    - 所有叶节点具有相同的深度，等于树高h。
    - key和指针互相间隔，节点两端是指针。
    - 一个节点中的key从左到右非递减排列。
  
- B+Tree
  - 它是通过二叉查找树演化过来的
    - 树中的节点并不存储数据本身，而是只是作为索引。除此之外，我们把每个叶子节点串在一条链表上，链表中的数据是从小到大有序的。
    - 比如，我们给一亿个数据构建二叉查找树索引，那索引中会包含大约 1 亿个节点，每个节点假设占用 16 个字节，那就需要大约 1GB 的内存空间。给一张表建立索引，我们需要 1GB 的内存空间。如果我们要给 10 张表建立索引，那对内存的需求是无法满足的。如何解决这个索引占用太多内存的问题呢？
    - 我们可以借助时间换空间的思路，把索引存储在硬盘中，而非内存中。二叉查找树，经过改造之后，支持区间查找的功能就实现了。不过，为了节省内存，如果把树存储在硬盘中，那么每个节点的读取（或者访问），都对应一次磁盘 IO 操作。树的高度就等于每次查询数据时磁盘 IO 操作的次数。
    - 不管是内存中的数据，还是磁盘中的数据，操作系统都是按页（一页大小通常是 4KB，这个值可以通过 getconfig PAGE_SIZE 命令查看）来读取的，一次会读一页的数据。如果要读取的数据量超过一页的大小，就会触发多次 IO 操作。所以，我们在选择 m 大小的时候，要尽量让每个节点的大小等于一个页的大小。读取一个节点，只需要一次磁盘 IO 操作。
    - 数据的写入过程，会涉及索引的更新，这是索引导致写入变慢的主要原因。
  - 特点：
    - 每个节点中子节点的个数不能超过 m，也不能小于 m/2；
    - 根节点的子节点个数可以不超过 m/2，这是一个例外；
    - m 叉树只存储索引，并不真正存储数据，这个有点儿类似跳表；
    - 通过链表将叶子节点串联在一起，这样可以方便按区间查找；
    - 一般情况，根节点会被存储在内存中，其他节点存储在磁盘中。
  - 内节点不存储data，只存储key；叶子节点不存储指针
  - 虽然B-Tree中不同节点存放的key和指针可能数量不一致，但是每个节点的域和上限是一致的，所以在实现中B-Tree往往对每个节点申请同等大小的空间
    - B+ 树中的节点不存储数据，只是索引，而 B 树中的节点存储数据；
    - B 树中的叶子节点并不需要链表来串联。
  
- 为什么使用B-Tree（B+Tree）
  - **局部性原理与磁盘预读**
    
    - 当一个数据被用到时，其附近的数据也通常会马上被使用
    - 预读的长度一般为页（page）的整倍数
    
  - **B+的磁盘读写代价更低**
  
    B+的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对B树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。
  
  - **B+-tree的查询效率更加稳定**
  
    由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。
    
  - B树大量应用在数据库和文件系统当中。
  
    - 红黑树往往出现由于树的深度过大而造成磁盘IO读写过于频繁，进而导致效率低下的情况在数据较小，可以完全放到内存中时，红黑树的时间复杂度比B树低。
    - 如linux中进程的调度用的是红黑树。
      反之，数据量较大，外存中占主要部分时，B树因其读磁盘次数少，而具有更快的速度。
  
- B-/+Tree索引的性能分析
  - 一次检索最多需要h-1次I/O
    - 一般实际应用中，出度d是非常大的数字，通常超过100，因此h非常小（通常不超过3）
  - **B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能**
  - 因为MySQL存储的数据结构用的是B+树。B+树和B树（多路平衡查找树）的主要区别是B+树所有的数据都是存储在叶子节点的。**通常B+树的层级都是很少的，单个非根节点会存储很多的数据，这样可以减少读取索引的次数。因为机械磁盘擅长的是大块地顺序读写，一次性读到越多的数据越有利于快速查找**，而且**B+树有个好处，所有的叶子节点都是指针相连的，可以快速地进行全表便利**。所以是个特别适合数据库的数据结构。
  
- 使用自增字段作为主键则是一个很好的选择
  
  - 如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页
  
- java中linkedHashMap就是链表链表+HashMap的组合，用于实现缓存的lru算法比较方便，不过要支持区间查询需要在插入时维持链表的有序性，复杂度O(n).效率比跳表和b+tree差

-  **MySQL 默认的存储引擎选择 B+ 树而不是哈希或者 B 树的原因：**

  - 哈希虽然能够提供 `O(1)` 的单数据行操作性能，但是对于范围查询和排序却无法很好地支持，最终导致全表扫描；
  - B 树能够在非叶节点中存储数据，但是这也导致在查询连续数据时可能会带来更多的随机 I/O，而 B+ 树的所有叶节点可以通过指针相互连接，能够减少顺序遍历时产生的额外随机 I/O；

- InnoDB的一棵B+树可以存放多少行数据？
  - 答案：**约2千万**
  - **怎么得到InnoDB主键索引B+树的高度？**
    - 上面通过推断得出B+树的高度通常是1-3
  - https://www.zhihu.com/search?type=content&q=mysql%E7%B4%A2%E5%BC%95%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E7%94%A8%E7%BA%A2%E9%BB%91%E6%A0%91



## 自增主键

- **什么是主键**

  - 数据库主键，指的是一个列或多列的组合，其值能唯一地标识表中的每一行，通过它可强制表的实体完整性。主键主要是用于其他表的外键关联，以及本记录的修改与删除。
  - 主键是能确定一条记录的唯一标识，主键字段必须唯一，必须非空，一个表中只能有一个主键，主键可以包含一个或多个字段。

- **什么是外键**

  - 如果[公共关键字](https://baike.baidu.com/item/公共关键字)在一个关系中是[主关键字](https://baike.baidu.com/item/主关键字/1239455)，那么这个公共关键字被称为另一个关系的外键。由此可见，外键表示了两个关系之间的相关联系。以另一个关系的外键作主关键字的表被称为主表，具有此外键的表被称为主表的从表。外键又称作[外关键字](https://baike.baidu.com/item/外关键字)。
  - 外键表示了两个关系之间的相关联系。以另一个关系的外键作主关键字的表被称为主表，具有此外键的表被称为主表的从表。外键又称作[外关键字](https://baike.baidu.com/item/外关键字)。外键用于与另一张表的关联。是能确定另一张表记录的字段，保持数据的一致性、完整性。

- 概述

  - 自增主键可以让主键索引尽量地保持递增顺序插入，避免了页分裂，因此索引更紧凑。
  - 自增主键不能保证连续递增。

- 自增值保存在哪

  - show create table +表
    - 表定义里面出现了一个 AUTO_INCREMENT=2，表示下一次插入数据时，如果需要自动生成自增值，会生成 id=2。
    - 表的结构定义存放在后缀名为.frm 的文件中，但是并不会保存自增值。
  - 不同的引擎对于自增值的保存策略不同。
    - MyISAM 引擎的自增值保存在数据文件中。
    - InnoDB 引擎的自增值，其实是保存在了内存里，并且到了 MySQL 8.0 版本后，才有了“自增值持久化”的能力，也就是才实现了“如果发生重启，表的自增值可以恢复为MySQL 重启前的值”
    - 在 MySQL 8.0 版本，将自增值的变更记录在了 redo log 中，重启的时候依靠 redo log 恢复重启之前的值。

- 自增值修改机制

  - 在 MySQL 里面，如果字段 id 被定义为 AUTO_INCREMENT
    - 某次要插入的值是 X，当前的自增值是 Y。
    - 如果 X<Y，那么这个表的自增值不变；
    - 如果 X≥Y，就需要把当前自增值修改为新的自增值。
  - auto_increment_offset 和 auto_increment_increment 是两个系统参数，分别用来表示自增的初始值和步长，默认值都是 1。
    - 新的自增值生成算法是：从auto_increment_offset 开始，以auto_increment_increment 为步长，持续叠加，直到找到第一个大于 X 的值，作为新的自增值。
    - 在一些场景下，使用的就不全是默认值。比如，双 M 的主备结构里要求双写的时候，我们就可能会设置成 auto_increment_increment=2，让一个库的自增 id 都是奇数，另一个库的自增 id 都是偶数，避免两个库生成的主键发生冲突

- 在这两个参数都设置为 1 的时候，自增主键 id 却不能保证是连续的

  - 唯一键冲突是导致自增主键 id 不连续的第一种原因。

    - 假设，表 t 里面已经有了 (1,1,1) 这条记录，这时我再执行一条插入数据命令（insert into t values(null, 1, 1)）：

      - > 这个语句的执行流程就是：
        > 	传入的这一行的值是 (0,1,1)
        > 	 InnoDB 发现用户没有指定自增 id 的值，获取表 t 当前的自增值 2
        > 	将传入的行的值改成 (2,1,1);
        > 	将表的自增值改成 3；
        > 	 继续执行插入数据操作，由于已经存在 c=1 （c 是唯一索引）的记录，所以报 Duplicate key error，语句返回。

    - 这个表的自增值改成 3，是在真正执行插入数据的操作之前。这个语句真正执行的时候，因为碰到唯一键 c 冲突，所以 id=2 这一行并没有插入成功，但也没有将自增值再改回去。

    - 在这之后，再插入新的数据行时，拿到的自增 id 就是 3。也就是说，出现了自增主键不连续的情况

  - 事务回滚也会产生类似的现象，这就是第二种原因

    - 语句执行失败也不回退自增 id。也正是因为这样，所以才只保证了自增 id 是递增的，但不保证是连续的。

  - 主键 id 出现自增 id 不连续的第三种原因。

    - > 对于批量插入数据的语句，MySQL 有一个批量申请自增 id 的策略：
      > 	语句执行过程中，第一次申请自增 id，会分配 1 个；
      > 	1 个用完以后，这个语句第二次申请自增 id，会分配 2 个；
      > 	 2 个用完以后，还是这个语句，第三次申请自增 id，会分配 4 个；
      > 	依此类推，同一个语句去申请自增 id，每次申请到的自增 id 个数都是上一次的两倍。
      >
      > 
      >
      > insert…select，实际上往表 t2 中插入了 4 行数据。但是，这四行数据是分三次申请的自增id，第一次申请到了 id=1，第二次被分配了 id=2 和 id=3， 第三次被分配到 id=4 到id=7。
      >
      > 
      >
      > 由于这条语句实际只用上了 4 个 id，所以 id=5 到 id=7 就被浪费掉了。之后，再执行insert into t2 values(null, 5,5)，实际上插入的数据就是（8,5,5)。

- 自增锁的优化

  - 自增 id 锁并不是一个事务锁，而是每次申请完就马上释放，以便允许别的事务再申请。

  - 在 binlog 里面把插入数据的操作都如实记录进来，到备库执行的时候，不再依赖于自增主键去生成。

    - innodb_autoinc_lock_mode 设置为2（设置为 2 时，所有的申请自增主键的动作都是申请后就释放锁），同时 binlog_format 设置为 row。

    - 因为insert … select中insert 生成的 id 不连续。这个不连续的 id，用statement 格式的 binlog 来串行执行，是执行不出来的。

      

  







## 为什么表数据删掉一半，表文件大小不变

- 一个 InnoDB 表包含两部分，即：表结构定义和数据。

- innodb_file_per_table参数 

  - 表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数innodb_file_per_table 控制的
    - 这个参数设置为 OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；
    - 这个参数设置为 ON 表示的是，每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中。
      从 MySQL 5.6.6 版本开始，它的默认值就是 ON 了。
  - 一个表单独存储为一个文件更容易管理，在你不需要这个表的时候，通过 drop table 命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。

- 数据删除流程

  - 如果我们用 delete 命令把整个表的数据删除呢？结果就是，所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小。
    - delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过 delete 命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。
  - 更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。经过大量增删改的表，都是可能是存在空洞的。
    - 所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。重建表，就可以达到这样的目的

- Online DDL

  - 在重建表中使用

  - > 1. 建立一个临时文件，扫描表 A 主键的所有数据页；
    > 2. 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；
    > 3. 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；
    > 4. 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；
    > 5. 用临时文件替换表 A 的数据文件。

  - 由于日志文件记录和重放操作这个功能的存在，这个方案在重建表的过程中，允许对表 A 做增删改操作。这也就是 Online DDL 名字的来源。

  - alter 语句在启动的时候需要获取 MDL 写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了。为什么要退化呢？为了实现 Online，MDL 读锁不会阻塞增删改操作。

    - 对于一个大表来说，Online DDL 最耗时的过程就是拷贝数据到临时表的过程，这个步骤的执行期间可以接受增删改操作。所以，相对于整个 DDL 过程来说，锁的时间非常短。对业务来说，就可以认为是 Online 的。





## 幻读

- 幻读是什么？

  - 幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。幻读仅专指“新插入的行”（我们给所有行加锁的时候，id=1 这一行还不存在，不存在也就加不上锁。）。
  - 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。

- 数据一致性的问题

  - 锁的设计是为了保证数据的一致性。而这个一致性，不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性。

  - update 的加锁语义和 select …for update 是一致的

  - > T1时刻session A给（d=1，id=0）加锁，T2时刻session B update d=1 where id=1，T3时刻session A提交
    >
    > id=0 和 id=1 这两行，发生了数据不一致。这个问题很严重，是不行的。

  - > 由于 session A 把所有的行都加了写锁，所以 session B 在执行第一个 update 语句的时候就被锁住了。
    >
    > 
    >
    > insert into t values(1,1,5); /*(1,1,5)*/
    > update t set c=5 where id=1; /*(1,5,5)*/
    > update t set d=100 where d=5;/* 所有 d=5 的行，d 改成 100*/
    >
    > 
    >
    > 也就是说，即使把所有的记录都加上锁，还是阻止不了新插入的记录，这也是为什么“幻读”会被单独拿出来解决的原因。

- 如何解决幻读？

  - 产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。
  - 跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。
  - 间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。
  - 间隙锁是在可重复读隔离级别下才会生效的
  - 间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间







## 间隙锁

- 加锁规则里面，包含了两个“原则”、两个“优化”

  - 原则1：加锁的基本单位是 next-key lock

  - 原则2：查找过程中访问到的对象才会加锁。

    - > 查询使用覆盖索引，并不需要访问主键索引，所以主键索引上没有加任何锁，这就是为什么的 update 语句可以执行完成。
      >
      > update set d=d+1 where id =5;

    - lock in share mode 只锁覆盖索引，但是如果是 for update就不一样了。 执行 for update 时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁。

    - 如果你要用 lock in share mode 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段。比如，将 session  的查询语句改成 select d from t wherec=5 lock in share mode

  - 优化1：索引上的等值查询，给唯一索引、主键索引也算加锁的时候，next-key lock 退化为行锁

  - 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。

- 锁是加在索引上的

- 案例一：等值查询间隙锁

- 案例二：非唯一索引等值锁

- 案例三：主键索引范围锁

- 案例四：非唯一索引范围锁

- 案例六：非唯一索引上存在"等值"的例子

- 案例七：limit 语句加锁

  - 在删除数据的时候尽量加 limit。这样不仅可以控制删除数据的条数，让操作更安全，还可以减小加锁的范围。

- 案例八：一个死锁的例子

  - session  A的“加 next-key lock(5,10] ”操作，实际上分成了两步，先是加 (5,10) 的间隙锁，加锁成功；然后加 c=10 的行锁，这时候才被锁住的。
    - 也就是说，我们在分析加锁规则的时候可以用 next-key lock 来分析。但是要知道，具体执行的时候，是要分成间隙锁和行锁两段来执行的。

- 共享锁 (lock in share mode)、排他锁 (for update)







## 全局锁和表锁

- 全局锁的典型使用场景是，做全库逻辑备份。

  - 官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。

- 表级锁

  - 业务的更新不只是增删改数据（DML)，还有可能是加字段等修改表结构的操作（DDL）。

  - MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。

    - MDL 不需要显式使用，在访问一个表的时候会被自动加上。
      - MDL作用是防止DDL和DML并发的冲突
      - 当对一个表做增删改查操作的时候，加 MDL读锁；当要对表做结构变更操作的时候，加 MDL 写锁。
      - 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。读写锁之间、写锁之间是互斥的

  - online ddl

    - Online DDL的过程是这样的：1. 拿MDL写锁2. 降级成MDL读锁3. 真正做DDL4. 升级成MDL写锁5. 释放MDL锁

      

## Mysql各种锁

### 表锁

表锁被大部分的mysql引擎支持，MyISAM和InnoDB都支持表级锁。

MyISAM只是支持表锁，因此性能相对Innodb来说相对降低，而Innodb也支持表锁，但是默认的行锁，而且只有在查询或者其他SQL语句通过索引才会使用行锁。



### **行锁**

行锁的是mysql锁中粒度最小的一种锁，因为锁的粒度很小，所以发生资源争抢的概率也最小，并发性能最大，但是也会造成死锁，每次加锁和释放锁的开销也会变大。目前主要是Innodb使用行锁，Innodb也是mysql在5.5.5版本之后默认使用的存储引擎。

> 行锁按照使用方式也氛围共享锁（S锁或者读锁）和排它锁（X锁或者写锁）

### **共享锁（S锁，读锁）**

使用说明：若事务A对数据对象1加上S锁，则事务A可以读数据对象1但不能修改，其他事务只能再对数据对象1加S锁，而不能加X锁，直到事务A释放数据对象1上的S锁。这保证了其他事务可以读数据对象1，但在事务A释放数据对象1上的S锁之前不能对数据对象1做任何修改。

用法：

```java
select ... lock in share mode;
----共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改。
```

### **排它锁（X锁，写锁）**

使用说明：若事务A对数据对象1加上X锁，事务A可以读数据对象1也可以修改数据对象1，其他事务不能再对数据对象1加任何锁，直到事务A释放数据对象1上的锁。这保证了其他事务在事务A释放数据对象1上的锁之前不能再读取和修改数据对象1。

```java
select ... for update
----排他锁就是不能与其他所并存，如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁
```

### **意向共享锁（IS）和意向排它锁（IX）**

释义：

```text
意向共享锁（IS）：事务想要在获得表中某些记录的共享锁，需要在表上先加意向共享锁。
意向互斥锁（IX）：事务想要在获得表中某些记录的互斥锁，需要在表上先加意向互斥锁。
```

意向共享锁和意向排它锁总称为意向锁。意向锁的出现是为了支持Innodb支持多粒度锁。

首先，意向锁是表级别锁。

理由:当我们需要给一个加表锁的时候，我们需要根据意向锁去判断表中有没有数据行被锁定，以确定是否能加成功。如果意向锁是行锁，那么我们就得遍历表中所有数据行来判断。如果意向锁是表锁，则我们直接判断一次就知道表中是否有数据行被锁定了。所以说将意向锁设置成表级别的锁的性能比行锁高的多。

有了意向锁之后，前面例子中的事务A在申请行锁（写锁）之前，数据库会自动先给事务A申请表的意向排他锁。当事务B去申请表的写锁时就会失败，因为表上有意向排他锁之后事务B申请表的写锁时会被阻塞。

所以，意向锁的作用就是：

当一个事务在需要获取资源的锁定时，如果该资源已经被排他锁占用，则数据库会自动给该事务申请一个该表的意向锁。如果自己需要一个共享锁定，就申请一个意向共享锁。如果需要的是某行（或者某些行）的排他锁定，则申请一个意向排他锁。

### **乐观锁**

> 乐观锁不是数据库自带的，需要我们自己去实现。乐观锁是指操作数据库时(更新操作)，想法很乐观，认为这次的操作不会导致冲突，在操作数据时，并不进行任何其他的特殊处理（也就是不加锁），而在进行更新后，再去判断是否有冲突了。
>
> 通常实现是这样的：在表中的数据进行操作时(更新)，先给数据表加一个版本(version)字段，每操作一次，将那条记录的版本号加1。也就是先查询出那条记录，获取出version字段,如果要对那条记录进行操作(更新),则先判断此刻version的值是否与刚刚查询出来时的version的值相等，如果相等，则说明这段期间，没有其他程序对其进行操作，则可以执行更新，将version字段的值加1；如果更新时发现此刻的version值与刚刚获取出来的version的值不相等，则说明这段期间已经有其他程序对其进行操作了，则不进行更新操作。

使用实例：

```java
1. SELECT data AS old_data, version AS old_version FROM …;
2. 根据获取的数据进行业务操作，得到new_data和new_version
3. UPDATE SET data = new_data, version = new_version WHERE version = old_version
if (updated row > 0) {
// 乐观锁获取成功，操作完成
} else {
// 乐观锁获取失败，回滚并重试
}
```

> 优点：从上面的例子可以看出，乐观锁机制避免了长事务中的数据库加锁开销，大大提升了大并发量下的系统整体性能表现。
> 缺点：乐观锁机制往往基于系统中的数据存储逻辑，因此也具备一定的局限性，如在上例中，由于乐观锁机制是在我们的系统中实现，来自外部系统的更新操作不受我们系统的控制，因此可能会造成脏数据被更新到数据库中。在系统设计阶段，应该充分考虑到这些情况出现的可能性，并进行相应调整（如将乐观锁策略在数据库存储过程中实现，对外只开放基于此存储过程的数据更新途径，而不是将数据库表直接对外公开）。
> 总结：读用乐观锁，写用悲观锁。

- **悲观锁和乐观锁**
  - 反映到 MySQL 数据库应用开发中，悲观锁一般就是利用类似 SELECT … FOR UPDATE 这样的语句，对数据加锁，避免其他事务意外修改数据。乐观锁则与 Java 并发包中的 AtomicFieldUpdater 类似，也是利用 CAS 机制，并不会对数据加锁，而是通过对比数据的时间戳或者版本号，来实现乐观锁需要的版本判断。
  - 我认为前面提到的 MVCC，其本质就可以看作是种乐观锁机制，而排他性**的读写锁、双阶段锁等则是悲观锁的实现。**
- **锁具体实现算法**
  - 行锁的具体实现算法有三种：record lock、gap lock 以及 next-key lock
  - 只在可重复读或以上隔离级别下的特定操作才会取得 gap lock 或 next-key lock，在Select 、Update 和 Delete 时，除了基于唯一索引的查询之外，其他索引查询时都会获取gap lock 或 next-key lock，即锁住其扫描的范围。



### **悲观锁**

> 悲观锁介绍（引自百科）：
> 悲观锁，正如其名，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）

悲观锁的实现：首先实现悲观锁时，我们必须先使用set autocommit=0; 关闭mysql的autoCommit属性。因为我们查询出数据之后就要将该数据锁定。

关闭自动提交后，我们需要手动开启事务。

```java
//1.开始事务
begin; 或者 start transaction;
//2.查询出商品信息，然后通过for update锁定数据防止其他事务修改
select status from t_goods where id=1 for update;
//3.根据商品信息生成订单
insert into t_orders (id,goods_id) values (null,1);
//4.修改商品status为2
update t_goods set status=2;
//4.提交事务
commit; --执行完毕，提交事务
```

上述就实现了悲观锁，悲观锁就是悲观主义者，它会认为我们在事务A中操作数据1的时候，一定会有事务B来修改数据1,所以，在第2步我们将数据查询出来后直接加上排它锁（X）锁，防止别的事务来修改事务1，直到我们commit后，才释放了排它锁。

> 优点：保证了数据处理时的安全性。缺点：加锁造成了开销增加，并且增加了死锁的机会。降低了并发性。

乐观锁更新有可能会失败，甚至是更新几次都失败，这是有风险的。所以如果写入居多，对吞吐要求不高，可使用悲观锁。

> 下面三种锁都是innodb的行锁，前面我们说过行锁是基于索引实现的，一旦加锁操作没有操作在索引上，就会退化成表锁。

### **间隙锁（Next-Key锁）**

间隙锁，作用于非唯一索引上，主要目的，就是为了防止其他事务在间隔中插入数据，以导致“不可重复读”。

如果把事务的隔离级别降级为读提交(Read Committed, RC)，间隙锁则会自动失效。

![img](https://pic3.zhimg.com/v2-8a05333a63d9c19e088a1b3fcd41df7b_b.jpg)

如图：（1，4），（4，7），（7，11），（11，∞）即为间隙锁要锁定的位置。

举例说明：

```java
SELECT * FROM table WHERE id = 8 FOR UPDATE;
----此时，（7,11）就会被锁定
SELECT * FROM table WHERE id BETWEN 2 AND 5 FOR UPDATE;
----此时，（1,4）和（4,7）就会被锁定
```

### **死锁**

> 释义：死锁是指两个或两个以上事务在执行过程中因争抢锁资源而造成的互相等待的现象



![img](https://pic4.zhimg.com/v2-288aa3a016bbb183c34c14cdc0da652f_b.jpg)

上图所示，即为死锁产生的常规情景。

**那么如何解决死锁？**

1.等待事务超时，主动回滚。

2.进行死锁检查，主动回滚某条事务，让别的事务能继续走下去。

下面提供一种方法，解决死锁的状态:

```java
SELECT * FROM INFORMATION_SCHEMA.INNODB_TRX;--查看正在被锁的事务
```



![img](https://picb.zhimg.com/v2-18b5068bd063c0e7ecd1ffa94ff66188_b.png)



```java
kill trx_mysql_thread_id；--（上图trx_mysql_thread_id列的值）
```

死锁是一个很复杂的话题，此处只能简而言之，后续会写一篇专门讲解死锁的文章。



### 死锁排查

这个事务的逻辑过程

- 首先会开启一个会话，查询table_a 表里面根据(goods_id,offline_id)查询是否存在对应的记录，如果存在执行第二步，如果不存在执行第三步
- 另外开启一个事务，执行select * from table_a where goods_id=xx and offline_id=yy for update,然后update table_b 表对应(goods_id,offline_id,sku_id)的记录，然后再次更新table_a 表的记录（根据ID）
- 另外开启一个事务，执行select * from table_a where goods_id=xx and offline_id=yy ,如果存在，则update table_b 表对应(goods_id,offline_id,sku_id)的记录+update table_a(根据ID），否则执行插入table_b 的操作+插入table_a 的操作

整个执行过程应该如下：

![img](https://pic3.zhimg.com/v2-cce038463e21236140b0db92224dcefd_b.jpg)

@t4 的Sess 1 在等待 @t3 的Sess2， @t5的Sess 2 在等待 @t2 的Sess1，形成典型的交叉等待。其中 Sess2 没有执行FOR UPDATE。

整个业务逻辑就是：

- Sess 2 查询发现没有记录，开启一个事务
- Sess 1 查询发现有记录（其他会话插入），开启一个事务，执行FOR UPDATE
- Sess 2 执行表B 的update操作
- Sess 1 执行表A 的update 操作 ... 那么如何避免这种典型的死锁呢？
- 修改业务逻辑，在第一次查询A表的时候，如果查到记录，可以传个FLAG，到事务中，那么事务中就执行执行插入操作，如果已经存在记录，就报错
- 修改SQL执行顺序，那么首先 A表 for update，然后更新A表，再更新B表，整个执行逻辑总是A表现操作，在操作B表，不会形成因为执行顺序不相同的死锁





## 行锁（死锁）

- MySQL 的行锁是在引擎层由各个引擎自己实现的。

  - InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。
  - 在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。

- 死锁和死锁检测

  - 当出现死锁以后，有两种策略：

    - 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout 来设置。

    - 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。

    - 正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且

      innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。

  - 怎么解决由这种热点行更新导致的性能问题呢？问题的症结在于，死锁检测要耗费大量的 CPU 资源。

    - 你可以考虑通过将一行改成逻辑上的多行来减少锁冲突



## 如何避免死锁？

- 为什么 SELECT 要加 for update 排他锁，而不是使用共享锁呢
  - 如果是两个订单号一样的请求同时进来，就有可能出现幻读
  - 一开始事务A 中的查询没有该订单号，后来事务 B 新增了一个该订单号的记录，此时事务 A 再新增一条该订单号记录，就会创建重复的订单记录。面对这种情况，我们可以使用锁间隙算法来防止幻读。
- 除了基于唯一索引的查询之外，其它索引查询时都会获取gap lock 或 next-key lock，即锁住其扫描的范围。主键索引也属于唯一索引，所以主键索引是不会使用 gap lock 或 next-key lock
- 死锁的四个必要条件
  - 互斥条件：一个资源每次只能被一个进程使用
  - 请求与保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源 已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。
  - 不可剥夺条件:进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能 由获得该资源的进程自己来释放（只能是主动释放)。
  - 循环等待条件: 若干进程间形成首尾相接循环等待资源的关系
- **解决死锁的最佳方式当然就是预防死锁的发生了**，我们平时编程中，可以通过以下一些常规手段来预防死锁的发生
  - 在编程中尽量按照固定的顺序来处理数据库记录，假设有两个更新操作，分别更新两条相同的记录，但更新顺序不一样，有可能导致死锁；
  
  - 在允许幻读和不可重复读的情况下，尽量使用 RC 事务隔离级别，可以避免 gap lock 导致的死锁问题；
  
  - 更新表时，尽量使用主键更新；
  
  - 避免长事务
  
    - 这个问题，我们可以从应用开发端和数据库端来看。
  
      首先，从应用开发端来看：
  
      1 确认是否使用了 set autocommit=0。这个确认工作可以在测试环境中开展，把MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。
  
      2确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。
  
      3业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。（为什么会意外？在后续的文章中会提到这类案例）
  
      其次，从数据库端来看：
  
      1监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill；
  
      2Percona 的 pt-kill 这个工具不错，推荐使用；
  
      3在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；
  
      4如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或
  
      更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。
  
  - 设置锁等待超时参数
    - 除了设置 innodb_lock_wait_timeout 参数来避免已经产生死锁的 SQL 长时间等待，你还知道其它方法来解决类似问题吗？
      - MySQL默认开启了死锁检测机制，当检测到死锁后会选择一个最小(锁定资源最少得事务)的事务进行回滚
      - Innodb提供了wait-for graph算法来主动进行死锁检测，我们可以通过innodb_deadlock_detect = on 打开死锁检测。













## 如何判断一个数据库是不是出问题了（可用性）

- select 1 判断
  - 通常情况下，我们建议把 innodb_thread_concurrency 设置为 64~128 之间的值
    - 实际上，在线程进入锁等待以后，并发线程的计数会减一，也就是说等行锁（也包括间隙锁）的线程是不算在 128 里面的。
  - 在 show processlist 的结果里，看到的几千个连接，指的就是并发连接。而“当前正在执行”的语句，才是我们所说的并发查询。
    - 并发连接数达到几千个影响并不大，就是多占一些内存而已。我们应该关注的是并发查询，因为并发查询太高才是 CPU 杀手。
  - 同时在执行的语句超过了设置的 innodb_thread_concurrency 的值，这时候系统其实已经不行了，但是通过 select 1 来检测系统，会认为系统还是正常的。
- 查表判断
  - 为了能够检测 InnoDB 并发线程数过多导致的系统不可用情况，我们需要找一个访问InnoDB 的场景。一般的做法是，在系统库（mysql 库）里创建一个表，比如命名为health_check，里面只放一行数据，然后定期执行：
  - 空间满了以后，这种方法又会变得不好使
  - 我们知道，更新事务要写 binlog，而一旦 binlog 所在磁盘的空间占用率达到 100%，那么所有的更新语句和事务提交的 commit 语句就都会被堵住。但是，系统这时候还是可以正常读数据的。
- 更新判断
  - 节点可用性的检测都应该包含主库和备库。如果用更新来检测主库的话，那么备库也要进行更新检测。
    - 但，备库的检测也是要写 binlog 的。由于我们一般会把数据库 A 和 B 的主备关系设计为双 M 结构，所以在备库 B 上执行的检测命令，也要发回给主库 A。
    - 为了让主备之间的更新不产生冲突，我们可以在 mysql.health_check 表上存入多行数据，并用 A、B 的 server_id 做主键。
    - 由于 MySQL 规定了主库和备库的 server_id 必须不同（否则创建主备关系的时候就会报错），这样就可以保证主、备库各自的检测命令不会发生冲突。
  - 更新语句，如果失败或者超时，就可以发起主备切换了，为什么还会有判定慢的问题呢？
    - 你可以设想一个日志盘的 IO 利用率已经是 100% 的场景。这时候，整个系统响应非常慢，已经需要做主备切换了。
    - 但是你要知道，IO 利用率 100% 表示系统的 IO 是在工作的，每个请求都有机会获得 IO资源，执行自己的任务。而我们的检测使用的 update 命令，需要的资源很少，所以可能在拿到 IO 资源的时候就可以提交成功，并且在超时时间 N 秒未到达之前就返回给了检测系统。
    - 检测系统一看，update 命令没有超时，于是就得到了“系统正常”的结论。
    - 之所以会出现这个现象，根本原因是我们上面说的所有方法，都是基于外部检测的。外部检测天然有一个问题，就是随机性。
- 内部统计
  - MySQL 5.6 版本以后提供的 performance_schema 库，就在file_summary_by_event_name 表里统计了每次 IO 请求的时间。
  - file_summary_by_event_name 表里有很多行数据，我们先来看看event_name='wait/io/file/innodb/innodb_log_file’这一行。
    - 这一行表示统计的是 redo log 的写入时间
    - 第一组五列，是所有 IO 类型的统计
    - 第二组六列，是读操作的统计
    - 第三组六列，统计的是写操作。
    - 最后的第四组数据，是对其他类型数据的统计。在 redo log 里，你可以认为它们就是对fsync 的统计。
  - 在 performance_schema 库的 file_summary_by_event_name 表里，binlog 对应的是event_name = "wait/io/file/sql/binlog"这一行。各个字段的统计逻辑，与 redo log 的各个字段完全相同。
- 个人比较倾向的方案，是优先考虑 update 系统表，然后再配合增加检测performance_schema 的信息。







## 误删数据（delete等）

- 误删行

  - 如果是使用 delete 语句误删了数据行，可以用 Flashback 工具通过闪回把数据恢复回来。
  - Flashback 恢复数据的原理，是修改 binlog 的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保 binlog_format=row 和 binlog_row_image=FULL
  - 我们不止要说误删数据的事后处理办法，更重要是要做到事前预防
    - 把 sql_safe_updates 参数设置为 on。这样一来，如果我们忘记在 delete 或者 update语句中写 where 条件，或者 where 条件里面没有包含索引字段的话，这条语句的执行就会报错。
    - 代码上线前，必须经过 SQL 审计。
  - 使用 delete 命令删除的数据，你还可以用 Flashback 来恢复。而使用 truncate /drop table 和 drop database 命令删除的数据，就没办法通过 Flashback 来恢复了。为什么呢？
    - 这是因为，即使我们配置了 binlog_format=row，执行这三个命令时，记录的 binlog 还是 statement 格式。binlog 里面就只有一个 truncate/drop 语句，这些信息是恢复不出数据的。

- 误删库 / 表

  - 这种情况下，要想恢复数据，就需要使用全量备份，加增量日志的方式了。这个方案要求线上有定期的全量备份，并且实时备份 binlog

  - 假如有人中午 12 点误删了一个库，恢复数据的流程如下

    > 1. 取最近一次全量备份，假设这个库是一天一备，上次备份是当天 0 点；
    > 2. 用备份恢复出一个临时库；
    > 3. 从日志备份里面，取出凌晨 0 点之后的日志；
    > 4. 把这些日志，除了误删除数据的语句外，全部应用到临时库。

  - 为了加速数据恢复，如果这个临时库上有多个数据库，你可以在使用 mysqlbinlog 命令时，加上一个–database 参数，用来指定误删表所在的库。这样，就避免了在恢复数据时还要应用其他库日志的情况

  - 在应用日志的时候，需要跳过 12 点误操作的那个语句的 binlog：

    - 如果原实例没有使用 GTID 模式，只能在应用到包含 12 点的 binlog 文件的时候，先用–stop-position 参数执行到误操作之前的日志，然后再用–start-position 从误操作之后的日志继续执行；
    - 如果实例使用了 GTID 模式，就方便多了。假设误操作命令的 GTID 是 gtid1，那么只需要执行 set gtid_next=gtid1;begin;commit; 先把这个 GTID 加到临时实例的 GTID集合，之后按顺序执行 binlog 的时候，就会自动跳过误操作的语句。

  - 使用 mysqlbinlog 方法恢复数据还是不够快，主要原因有两个

    - 如果是误删表，最好就是只恢复出这张表，也就是只重放这张表的操作，但是mysqlbinlog 工具并不能指定只解析一个表的日志；
    - 用 mysqlbinlog 解析出日志应用，应用日志的过程就只能是单线程。

- 延迟复制备库

  - 延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N 命令，可以指定这个备库持续保持跟主库有 N 秒的延迟。
  - 比如你把 N 设置为 3600，这就代表了如果主库上有数据被误删了，并且在 1 小时内发现了这个误操作命令，这个命令就还没有在这个延迟复制的备库执行。这时候到这个备库上执行 stop slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据

  

  

  

  

  

## 查这么多数据，会不会把数据库内存打爆（全表扫描）

- **全表扫描对 server 层的影响**

  - 取数据和发数据的流程是这样的：

    - > ​	获取一行，写到 net_buffer 中。这块内存的大小是由参数 net_buffer_length 定义的，默认是 16k。
      > ​	重复获取行，直到 net_buffer 写满，调用网络接口发出去。
      > ​	如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。
      > ​	如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送。

  - 也就是说，MySQL 是“边读边发的”，这个概念很重要。这就意味着，如果客户端接收得慢，会导致 MySQL 服务端由于结果发不出去，这个事务的执行时间变长。

    - 仅当一个线程处于“等待客户端接收结果”的状态，才会显示"Sending toclient"；而如果显示成“Sending data”，它的意思只是“正在执行”。

  - 现在你知道了，查询的结果是分段发给客户端的，因此扫描全表，查询返回大量的数据，并不会把内存打爆。

- **全表扫描对 InnoDB 的影响**

  - 内存的数据页是在 Buffer Pool (BP) 中管理的，在 WAL 里 Buffer Pool 起到了加速更新的作用。而实际上，Buffer Pool 还有一个更重要的作用，就是加速查询。
    - InnoDB Buffer Pool 的大小是由参数 innodb_buffer_pool_size 确定的，一般建议设置成可用物理内存的 60%~80%。
  - InnoDB 内存管理用的是最近最少使用 (Least Recently Used, LRU) 算法，这个算法的核心就是淘汰最久未使用的数据。
    - 在 InnoDB 实现上，按照 5:3 的比例把整个 LRU 链表分成了 young 区域和 old 区域
    - 处于 old 区域的数据页，每次被访问的时候都要做下面这个判断：
      - 存在的时间超过了 1 秒，就把它移动到链表头部；
      - 存在的时间短于 1 秒，位置保持不变
      - 1 秒这个时间，是由参数 innodb_old_blocks_time 控制的。
  - 可以看到，这个策略最大的收益，就是在扫描这个大表的过程中，虽然也用到了 BufferPool，但是对 young 区域完全没有影响，从而保证了 Buffer Pool 响应正常业务的查询命中率。
    - Buffer Pool 对查询的加速效果，依赖于一个重要的指标，即：内存命中率。你可以在 show engine innodb status 结果中，查看一个系统当前的 BP 命中率	
    - “Buffer pool hit rate”字样，显示的就是当前的命中率

- “长事务”

  - 如果前面的语句有更新，意味着它们在占用着行锁，会导致别的语句更新被锁住；
  - 读的事务也有问题，会导致 undo log 不能被回收，导致回滚段空间膨胀。





























